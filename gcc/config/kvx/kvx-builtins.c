/* Builtin support for the KVX architecture.
   Copyright (C) 2011-2022 Free Software Foundation, Inc.
   Contributed by Kalray SA (bddinechin@kalray.eu).

   This file is part of GCC.

   GCC is free software; you can redistribute it and/or modify it
   under the terms of the GNU General Public License as published by
   the Free Software Foundation; either version 3, or (at your option)
   any later version.

   GCC is distributed in the hope that it will be useful, but
   WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
   General Public License for more details.

   You should have received a copy of the GNU General Public License
   along with GCC; see the file COPYING3.  If not see
   <http://www.gnu.org/licenses/>.  */

#define IN_TARGET_CODE 1

#include "config.h"
#include "system.h"
#include "coretypes.h"
#include "tm.h"
#include "function.h"
#include "basic-block.h"
#include "rtl.h"
#include "tree.h"
#include "gimple.h"
#include "memmodel.h"
#include "tm_p.h"
#include "expmed.h"
#include "optabs.h"
#include "recog.h"
#include "diagnostic-core.h"
#include "fold-const.h"
#include "stor-layout.h"
#include "explow.h"
#include "expr.h"
#include "langhooks.h"
#include "gimple-iterator.h"
#include "case-cfn-macros.h"
#include "emit-rtl.h"

enum kvx_builtin
{
  KVX_BUILTIN_ADDCD,
  KVX_BUILTIN_SBFCD,

  KVX_BUILTIN_ADDBO,
  KVX_BUILTIN_ADDBX,
  KVX_BUILTIN_ADDBV,
  KVX_BUILTIN_ADDHQ,
  KVX_BUILTIN_ADDHO,
  KVX_BUILTIN_ADDHX,
  KVX_BUILTIN_ADDW,
  KVX_BUILTIN_ADDWP,
  KVX_BUILTIN_ADDWQ,
  KVX_BUILTIN_ADDWO,
  KVX_BUILTIN_ADDD,
  KVX_BUILTIN_ADDDP,
  KVX_BUILTIN_ADDDQ,

  KVX_BUILTIN_SBFBO,
  KVX_BUILTIN_SBFBX,
  KVX_BUILTIN_SBFBV,
  KVX_BUILTIN_SBFHQ,
  KVX_BUILTIN_SBFHO,
  KVX_BUILTIN_SBFHX,
  KVX_BUILTIN_SBFW,
  KVX_BUILTIN_SBFWP,
  KVX_BUILTIN_SBFWQ,
  KVX_BUILTIN_SBFWO,
  KVX_BUILTIN_SBFD,
  KVX_BUILTIN_SBFDP,
  KVX_BUILTIN_SBFDQ,

  KVX_BUILTIN_NEGBO,
  KVX_BUILTIN_NEGBX,
  KVX_BUILTIN_NEGBV,
  KVX_BUILTIN_NEGHQ,
  KVX_BUILTIN_NEGHO,
  KVX_BUILTIN_NEGHX,
  KVX_BUILTIN_NEGW,
  KVX_BUILTIN_NEGWP,
  KVX_BUILTIN_NEGWQ,
  KVX_BUILTIN_NEGWO,
  KVX_BUILTIN_NEGD,
  KVX_BUILTIN_NEGDP,
  KVX_BUILTIN_NEGDQ,

  KVX_BUILTIN_ABSBO,
  KVX_BUILTIN_ABSBX,
  KVX_BUILTIN_ABSBV,
  KVX_BUILTIN_ABSHQ,
  KVX_BUILTIN_ABSHO,
  KVX_BUILTIN_ABSHX,
  KVX_BUILTIN_ABSW,
  KVX_BUILTIN_ABSWP,
  KVX_BUILTIN_ABSWQ,
  KVX_BUILTIN_ABSWO,
  KVX_BUILTIN_ABSD,
  KVX_BUILTIN_ABSDP,
  KVX_BUILTIN_ABSDQ,

  KVX_BUILTIN_ABDBO,
  KVX_BUILTIN_ABDBX,
  KVX_BUILTIN_ABDBV,
  KVX_BUILTIN_ABDHQ,
  KVX_BUILTIN_ABDHO,
  KVX_BUILTIN_ABDHX,
  KVX_BUILTIN_ABDW,
  KVX_BUILTIN_ABDWP,
  KVX_BUILTIN_ABDWQ,
  KVX_BUILTIN_ABDWO,
  KVX_BUILTIN_ABDD,
  KVX_BUILTIN_ABDDP,
  KVX_BUILTIN_ABDDQ,

  KVX_BUILTIN_AVGBO,
  KVX_BUILTIN_AVGBX,
  KVX_BUILTIN_AVGBV,
  KVX_BUILTIN_AVGHQ,
  KVX_BUILTIN_AVGHO,
  KVX_BUILTIN_AVGHX,
  KVX_BUILTIN_AVGW,
  KVX_BUILTIN_AVGWP,
  KVX_BUILTIN_AVGWQ,
  KVX_BUILTIN_AVGWO,

  KVX_BUILTIN_MULXHWQ,
  KVX_BUILTIN_MULXHWO,
  KVX_BUILTIN_MULXWDP,
  KVX_BUILTIN_MULXWDQ,

  KVX_BUILTIN_MADDXHWQ,
  KVX_BUILTIN_MADDXHWO,
  KVX_BUILTIN_MADDXWDP,
  KVX_BUILTIN_MADDXWDQ,

  KVX_BUILTIN_MSBFXHWQ,
  KVX_BUILTIN_MSBFXHWO,
  KVX_BUILTIN_MSBFXWDP,
  KVX_BUILTIN_MSBFXWDQ,

  KVX_BUILTIN_MINBO,
  KVX_BUILTIN_MINBX,
  KVX_BUILTIN_MINBV,
  KVX_BUILTIN_MINHQ,
  KVX_BUILTIN_MINHO,
  KVX_BUILTIN_MINHX,
  KVX_BUILTIN_MINW,
  KVX_BUILTIN_MINWP,
  KVX_BUILTIN_MINWQ,
  KVX_BUILTIN_MINWO,
  KVX_BUILTIN_MIND,
  KVX_BUILTIN_MINDP,
  KVX_BUILTIN_MINDQ,

  KVX_BUILTIN_MAXBO,
  KVX_BUILTIN_MAXBX,
  KVX_BUILTIN_MAXBV,
  KVX_BUILTIN_MAXHQ,
  KVX_BUILTIN_MAXHO,
  KVX_BUILTIN_MAXHX,
  KVX_BUILTIN_MAXW,
  KVX_BUILTIN_MAXWP,
  KVX_BUILTIN_MAXWQ,
  KVX_BUILTIN_MAXWO,
  KVX_BUILTIN_MAXD,
  KVX_BUILTIN_MAXDP,
  KVX_BUILTIN_MAXDQ,

  KVX_BUILTIN_MINUBO,
  KVX_BUILTIN_MINUBX,
  KVX_BUILTIN_MINUBV,
  KVX_BUILTIN_MINUHQ,
  KVX_BUILTIN_MINUHO,
  KVX_BUILTIN_MINUHX,
  KVX_BUILTIN_MINUW,
  KVX_BUILTIN_MINUWP,
  KVX_BUILTIN_MINUWQ,
  KVX_BUILTIN_MINUWO,
  KVX_BUILTIN_MINUD,
  KVX_BUILTIN_MINUDP,
  KVX_BUILTIN_MINUDQ,

  KVX_BUILTIN_MAXUBO,
  KVX_BUILTIN_MAXUBX,
  KVX_BUILTIN_MAXUBV,
  KVX_BUILTIN_MAXUHQ,
  KVX_BUILTIN_MAXUHO,
  KVX_BUILTIN_MAXUHX,
  KVX_BUILTIN_MAXUW,
  KVX_BUILTIN_MAXUWP,
  KVX_BUILTIN_MAXUWQ,
  KVX_BUILTIN_MAXUWO,
  KVX_BUILTIN_MAXUD,
  KVX_BUILTIN_MAXUDP,
  KVX_BUILTIN_MAXUDQ,

  KVX_BUILTIN_SHLBOS,
  KVX_BUILTIN_SHLBXS,
  KVX_BUILTIN_SHLBVS,
  KVX_BUILTIN_SHLHQS,
  KVX_BUILTIN_SHLHOS,
  KVX_BUILTIN_SHLHXS,
  KVX_BUILTIN_SHLW,
  KVX_BUILTIN_SHLWPS,
  KVX_BUILTIN_SHLWQS,
  KVX_BUILTIN_SHLWOS,
  KVX_BUILTIN_SHLD,
  KVX_BUILTIN_SHLDPS,
  KVX_BUILTIN_SHLDQS,

  KVX_BUILTIN_SHRBOS,
  KVX_BUILTIN_SHRBXS,
  KVX_BUILTIN_SHRBVS,
  KVX_BUILTIN_SHRHQS,
  KVX_BUILTIN_SHRHOS,
  KVX_BUILTIN_SHRHXS,
  KVX_BUILTIN_SHRW,
  KVX_BUILTIN_SHRWPS,
  KVX_BUILTIN_SHRWQS,
  KVX_BUILTIN_SHRWOS,
  KVX_BUILTIN_SHRD,
  KVX_BUILTIN_SHRDPS,
  KVX_BUILTIN_SHRDQS,

  KVX_BUILTIN_CLZW,
  KVX_BUILTIN_CLZD,
  KVX_BUILTIN_CTZW,
  KVX_BUILTIN_CTZD,
  KVX_BUILTIN_CBSW,
  KVX_BUILTIN_CBSD,

  KVX_BUILTIN_BITCNTW,
  KVX_BUILTIN_BITCNTWP,
  KVX_BUILTIN_BITCNTWQ,
  KVX_BUILTIN_BITCNTWO,
  KVX_BUILTIN_BITCNTD,
  KVX_BUILTIN_BITCNTDP,
  KVX_BUILTIN_BITCNTDQ,

  KVX_BUILTIN_WIDENBHO,
  KVX_BUILTIN_WIDENBHX,
  KVX_BUILTIN_WIDENHWQ,
  KVX_BUILTIN_WIDENHWO,
  KVX_BUILTIN_WIDENWDP,
  KVX_BUILTIN_WIDENWDQ,

  KVX_BUILTIN_NARROWHBO,
  KVX_BUILTIN_NARROWHBX,
  KVX_BUILTIN_NARROWWHQ,
  KVX_BUILTIN_NARROWWHO,
  KVX_BUILTIN_NARROWDWP,
  KVX_BUILTIN_NARROWDWQ,

  KVX_BUILTIN_SHIFTBO,
  KVX_BUILTIN_SHIFTBX,
  KVX_BUILTIN_SHIFTBV,
  KVX_BUILTIN_SHIFTHQ,
  KVX_BUILTIN_SHIFTHO,
  KVX_BUILTIN_SHIFTHX,
  KVX_BUILTIN_SHIFTWP,
  KVX_BUILTIN_SHIFTWQ,
  KVX_BUILTIN_SHIFTWO,
  KVX_BUILTIN_SHIFTDP,
  KVX_BUILTIN_SHIFTDQ,
  KVX_BUILTIN_SHIFTFHQ,
  KVX_BUILTIN_SHIFTFHO,
  KVX_BUILTIN_SHIFTFHX,
  KVX_BUILTIN_SHIFTFWP,
  KVX_BUILTIN_SHIFTFWQ,
  KVX_BUILTIN_SHIFTFWO,
  KVX_BUILTIN_SHIFTFDP,
  KVX_BUILTIN_SHIFTFDQ,

  KVX_BUILTIN_AWAIT,
  KVX_BUILTIN_BARRIER,
  KVX_BUILTIN_ACSWAPW,
  KVX_BUILTIN_ACSWAPD,
  KVX_BUILTIN_ALADDD,
  KVX_BUILTIN_ALADDW,
  KVX_BUILTIN_ALCLRD,
  KVX_BUILTIN_ALCLRW,
  KVX_BUILTIN_DINVAL,
  KVX_BUILTIN_DINVALL,
  KVX_BUILTIN_DTOUCHL,
  KVX_BUILTIN_DZEROL,
  KVX_BUILTIN_FENCE,

  KVX_BUILTIN_CATBX,
  KVX_BUILTIN_CATBV,
  KVX_BUILTIN_CATHO,
  KVX_BUILTIN_CATHX,
  KVX_BUILTIN_CATWP,
  KVX_BUILTIN_CATWQ,
  KVX_BUILTIN_CATWO,
  KVX_BUILTIN_CATDP,
  KVX_BUILTIN_CATDQ,
  KVX_BUILTIN_CATFHO,
  KVX_BUILTIN_CATFHX,
  KVX_BUILTIN_CATFWP,
  KVX_BUILTIN_CATFWQ,
  KVX_BUILTIN_CATFWO,
  KVX_BUILTIN_CATFDP,
  KVX_BUILTIN_CATFDQ,

  KVX_BUILTIN_SELECTBO,
  KVX_BUILTIN_SELECTBX,
  KVX_BUILTIN_SELECTBV,
  KVX_BUILTIN_SELECTHQ,
  KVX_BUILTIN_SELECTHO,
  KVX_BUILTIN_SELECTHX,
  KVX_BUILTIN_SELECTWP,
  KVX_BUILTIN_SELECTWQ,
  KVX_BUILTIN_SELECTWO,
  KVX_BUILTIN_SELECTDP,
  KVX_BUILTIN_SELECTDQ,
  KVX_BUILTIN_SELECTFHQ,
  KVX_BUILTIN_SELECTFHO,
  KVX_BUILTIN_SELECTFHX,
  KVX_BUILTIN_SELECTFWP,
  KVX_BUILTIN_SELECTFWQ,
  KVX_BUILTIN_SELECTFWO,
  KVX_BUILTIN_SELECTFDP,
  KVX_BUILTIN_SELECTFDQ,

  KVX_BUILTIN_COPYSIGNH,
  KVX_BUILTIN_COPYSIGNHQ,
  KVX_BUILTIN_COPYSIGNHO,
  KVX_BUILTIN_COPYSIGNHX,
  KVX_BUILTIN_COPYSIGNW,
  KVX_BUILTIN_COPYSIGNWP,
  KVX_BUILTIN_COPYSIGNWQ,
  KVX_BUILTIN_COPYSIGNWO,
  KVX_BUILTIN_COPYSIGND,
  KVX_BUILTIN_COPYSIGNDP,
  KVX_BUILTIN_COPYSIGNDQ,

  KVX_BUILTIN_FMINH,
  KVX_BUILTIN_FMINHQ,
  KVX_BUILTIN_FMINHO,
  KVX_BUILTIN_FMINHX,
  KVX_BUILTIN_FMINW,
  KVX_BUILTIN_FMINWP,
  KVX_BUILTIN_FMINWQ,
  KVX_BUILTIN_FMINWO,
  KVX_BUILTIN_FMIND,
  KVX_BUILTIN_FMINDP,
  KVX_BUILTIN_FMINDQ,

  KVX_BUILTIN_FMAXH,
  KVX_BUILTIN_FMAXHQ,
  KVX_BUILTIN_FMAXHO,
  KVX_BUILTIN_FMAXHX,
  KVX_BUILTIN_FMAXW,
  KVX_BUILTIN_FMAXWP,
  KVX_BUILTIN_FMAXWQ,
  KVX_BUILTIN_FMAXWO,
  KVX_BUILTIN_FMAXD,
  KVX_BUILTIN_FMAXDP,
  KVX_BUILTIN_FMAXDQ,

  KVX_BUILTIN_FNEGH,
  KVX_BUILTIN_FNEGHQ,
  KVX_BUILTIN_FNEGHO,
  KVX_BUILTIN_FNEGHX,
  KVX_BUILTIN_FNEGW,
  KVX_BUILTIN_FNEGWP,
  KVX_BUILTIN_FNEGWQ,
  KVX_BUILTIN_FNEGWO,
  KVX_BUILTIN_FNEGD,
  KVX_BUILTIN_FNEGDP,
  KVX_BUILTIN_FNEGDQ,

  KVX_BUILTIN_FABSH,
  KVX_BUILTIN_FABSHQ,
  KVX_BUILTIN_FABSHO,
  KVX_BUILTIN_FABSHX,
  KVX_BUILTIN_FABSW,
  KVX_BUILTIN_FABSWP,
  KVX_BUILTIN_FABSWQ,
  KVX_BUILTIN_FABSWO,
  KVX_BUILTIN_FABSD,
  KVX_BUILTIN_FABSDP,
  KVX_BUILTIN_FABSDQ,

  KVX_BUILTIN_FRECW,
  KVX_BUILTIN_FRECWP,
  KVX_BUILTIN_FRECWQ,
  KVX_BUILTIN_FRECWO,

  KVX_BUILTIN_FRSRW,
  KVX_BUILTIN_FRSRWP,
  KVX_BUILTIN_FRSRWQ,
  KVX_BUILTIN_FRSRWO,

  KVX_BUILTIN_FADDH,
  KVX_BUILTIN_FADDHQ,
  KVX_BUILTIN_FADDHO,
  KVX_BUILTIN_FADDHX,
  KVX_BUILTIN_FADDW,
  KVX_BUILTIN_FADDWP,
  KVX_BUILTIN_FADDWQ,
  KVX_BUILTIN_FADDWO,
  KVX_BUILTIN_FADDD,
  KVX_BUILTIN_FADDDP,
  KVX_BUILTIN_FADDDQ,

  KVX_BUILTIN_FSBFH,
  KVX_BUILTIN_FSBFHQ,
  KVX_BUILTIN_FSBFHO,
  KVX_BUILTIN_FSBFHX,
  KVX_BUILTIN_FSBFW,
  KVX_BUILTIN_FSBFWP,
  KVX_BUILTIN_FSBFWQ,
  KVX_BUILTIN_FSBFWO,
  KVX_BUILTIN_FSBFD,
  KVX_BUILTIN_FSBFDP,
  KVX_BUILTIN_FSBFDQ,

  KVX_BUILTIN_FMULH,
  KVX_BUILTIN_FMULHQ,
  KVX_BUILTIN_FMULHO,
  KVX_BUILTIN_FMULHX,
  KVX_BUILTIN_FMULW,
  KVX_BUILTIN_FMULWP,
  KVX_BUILTIN_FMULWQ,
  KVX_BUILTIN_FMULWO,
  KVX_BUILTIN_FMULD,
  KVX_BUILTIN_FMULDP,
  KVX_BUILTIN_FMULDQ,

  KVX_BUILTIN_FMULXHW,
  KVX_BUILTIN_FMULXHWQ,
  KVX_BUILTIN_FMULXHWO,
  KVX_BUILTIN_FMULXWD,
  KVX_BUILTIN_FMULXWDP,
  KVX_BUILTIN_FMULXWDQ,
  KVX_BUILTIN_FMULWC,
  KVX_BUILTIN_FMULWCP,
  KVX_BUILTIN_FMULWCQ,
  KVX_BUILTIN_FMULDC,
  KVX_BUILTIN_FMULDCP,

  KVX_BUILTIN_FFMAH,
  KVX_BUILTIN_FFMAHQ,
  KVX_BUILTIN_FFMAHO,
  KVX_BUILTIN_FFMAHX,
  KVX_BUILTIN_FFMAW,
  KVX_BUILTIN_FFMAWP,
  KVX_BUILTIN_FFMAWQ,
  KVX_BUILTIN_FFMAWO,
  KVX_BUILTIN_FFMAD,
  KVX_BUILTIN_FFMADP,
  KVX_BUILTIN_FFMADQ,

  KVX_BUILTIN_FFMAXHW,
  KVX_BUILTIN_FFMAXHWQ,
  KVX_BUILTIN_FFMAXHWO,
  KVX_BUILTIN_FFMAXWD,
  KVX_BUILTIN_FFMAXWDP,
  KVX_BUILTIN_FFMAXWDQ,
  KVX_BUILTIN_FFMAWC,
  KVX_BUILTIN_FFMAWCP,
  KVX_BUILTIN_FFMAWCQ,
  KVX_BUILTIN_FFMADC,
  KVX_BUILTIN_FFMADCP,

  KVX_BUILTIN_FFMSH,
  KVX_BUILTIN_FFMSHQ,
  KVX_BUILTIN_FFMSHO,
  KVX_BUILTIN_FFMSHX,
  KVX_BUILTIN_FFMSW,
  KVX_BUILTIN_FFMSWP,
  KVX_BUILTIN_FFMSWQ,
  KVX_BUILTIN_FFMSWO,
  KVX_BUILTIN_FFMSD,
  KVX_BUILTIN_FFMSDP,
  KVX_BUILTIN_FFMSDQ,

  KVX_BUILTIN_FFMSXHW,
  KVX_BUILTIN_FFMSXHWQ,
  KVX_BUILTIN_FFMSXHWO,
  KVX_BUILTIN_FFMSXWD,
  KVX_BUILTIN_FFMSXWDP,
  KVX_BUILTIN_FFMSXWDQ,
  KVX_BUILTIN_FFMSWC,
  KVX_BUILTIN_FFMSWCP,
  KVX_BUILTIN_FFMSWCQ,
  KVX_BUILTIN_FFMSDC,
  KVX_BUILTIN_FFMSDCP,

  KVX_BUILTIN_FMM212W,
  KVX_BUILTIN_FMM222W,
  KVX_BUILTIN_FMMA212W,
  KVX_BUILTIN_FMMA222W,
  KVX_BUILTIN_FMMS212W,
  KVX_BUILTIN_FMMS222W,

  KVX_BUILTIN_FFDMAW,
  KVX_BUILTIN_FFDMAWP,
  KVX_BUILTIN_FFDMAWQ,

  KVX_BUILTIN_FFDMSW,
  KVX_BUILTIN_FFDMSWP,
  KVX_BUILTIN_FFDMSWQ,

  KVX_BUILTIN_FFDMDAW,
  KVX_BUILTIN_FFDMDAWP,
  KVX_BUILTIN_FFDMDAWQ,

  KVX_BUILTIN_FFDMSAW,
  KVX_BUILTIN_FFDMSAWP,
  KVX_BUILTIN_FFDMSAWQ,

  KVX_BUILTIN_FFDMDSW,
  KVX_BUILTIN_FFDMDSWP,
  KVX_BUILTIN_FFDMDSWQ,

  KVX_BUILTIN_FFDMASW,
  KVX_BUILTIN_FFDMASWP,
  KVX_BUILTIN_FFDMASWQ,

  KVX_BUILTIN_FLOATW,
  KVX_BUILTIN_FLOATWP,
  KVX_BUILTIN_FLOATWQ,
  KVX_BUILTIN_FLOATWO,
  KVX_BUILTIN_FLOATD,
  KVX_BUILTIN_FLOATDP,
  KVX_BUILTIN_FLOATDQ,

  KVX_BUILTIN_FLOATUW,
  KVX_BUILTIN_FLOATUWP,
  KVX_BUILTIN_FLOATUWQ,
  KVX_BUILTIN_FLOATUWO,
  KVX_BUILTIN_FLOATUD,
  KVX_BUILTIN_FLOATUDP,
  KVX_BUILTIN_FLOATUDQ,

  KVX_BUILTIN_FIXEDW,
  KVX_BUILTIN_FIXEDWP,
  KVX_BUILTIN_FIXEDWQ,
  KVX_BUILTIN_FIXEDWO,
  KVX_BUILTIN_FIXEDD,
  KVX_BUILTIN_FIXEDDP,
  KVX_BUILTIN_FIXEDDQ,

  KVX_BUILTIN_FIXEDUW,
  KVX_BUILTIN_FIXEDUWP,
  KVX_BUILTIN_FIXEDUWQ,
  KVX_BUILTIN_FIXEDUWO,
  KVX_BUILTIN_FIXEDUD,
  KVX_BUILTIN_FIXEDUDP,
  KVX_BUILTIN_FIXEDUDQ,

  KVX_BUILTIN_FWIDENHW,
  KVX_BUILTIN_FWIDENHWQ,
  KVX_BUILTIN_FWIDENHWO,
  KVX_BUILTIN_FWIDENWD,
  KVX_BUILTIN_FWIDENWDP,
  KVX_BUILTIN_FWIDENWDQ,

  KVX_BUILTIN_FNARROWWH,
  KVX_BUILTIN_FNARROWWHQ,
  KVX_BUILTIN_FNARROWWHO,
  KVX_BUILTIN_FNARROWDW,
  KVX_BUILTIN_FNARROWDWP,
  KVX_BUILTIN_FNARROWDWQ,

  KVX_BUILTIN_FCONJWC,
  KVX_BUILTIN_FCONJWCP,
  KVX_BUILTIN_FCONJWCQ,
  KVX_BUILTIN_FCONJDC,
  KVX_BUILTIN_FCONJDCP,

  KVX_BUILTIN_FCDIVW,
  KVX_BUILTIN_FCDIVWP,
  KVX_BUILTIN_FCDIVWQ,
  KVX_BUILTIN_FCDIVWO,
  KVX_BUILTIN_FCDIVD,
  KVX_BUILTIN_FCDIVDP,
  KVX_BUILTIN_FCDIVDQ,

  KVX_BUILTIN_FSDIVW,
  KVX_BUILTIN_FSDIVWP,
  KVX_BUILTIN_FSDIVWQ,
  KVX_BUILTIN_FSDIVWO,
  KVX_BUILTIN_FSDIVD,
  KVX_BUILTIN_FSDIVDP,
  KVX_BUILTIN_FSDIVDQ,

  KVX_BUILTIN_FSRECW,
  KVX_BUILTIN_FSRECWP,
  KVX_BUILTIN_FSRECWQ,
  KVX_BUILTIN_FSRECWO,
  KVX_BUILTIN_FSRECD,
  KVX_BUILTIN_FSRECDP,
  KVX_BUILTIN_FSRECDQ,

  KVX_BUILTIN_FSRSRW,
  KVX_BUILTIN_FSRSRWP,
  KVX_BUILTIN_FSRSRWQ,
  KVX_BUILTIN_FSRSRWO,
  KVX_BUILTIN_FSRSRD,
  KVX_BUILTIN_FSRSRDP,
  KVX_BUILTIN_FSRSRDQ,

  KVX_BUILTIN_GET,
  KVX_BUILTIN_WFXL,
  KVX_BUILTIN_WFXM,
  KVX_BUILTIN_IINVAL,
  KVX_BUILTIN_IINVALS,
  KVX_BUILTIN_LBSU,
  KVX_BUILTIN_LBZU,
  KVX_BUILTIN_LHSU,
  KVX_BUILTIN_LHZU,
  KVX_BUILTIN_LDU,
  KVX_BUILTIN_LWZU,
  KVX_BUILTIN_SET,
  KVX_BUILTIN_SLEEP,
  KVX_BUILTIN_STOP,
  KVX_BUILTIN_SYNCGROUP,
  KVX_BUILTIN_TLBDINVAL,
  KVX_BUILTIN_TLBIINVAL,
  KVX_BUILTIN_TLBPROBE,
  KVX_BUILTIN_TLBREAD,
  KVX_BUILTIN_TLBWRITE,
  KVX_BUILTIN_WAITIT,

  KVX_BUILTIN_SATD,
  KVX_BUILTIN_SATUD,
  KVX_BUILTIN_STSUW,
  KVX_BUILTIN_STSUD,
  KVX_BUILTIN_STSUDP,
  KVX_BUILTIN_SBMM8,
  KVX_BUILTIN_SBMMT8,

  KVX_BUILTIN_LBZ,
  KVX_BUILTIN_LBS,
  KVX_BUILTIN_LHZ,
  KVX_BUILTIN_LHS,
  KVX_BUILTIN_LWZ,
  KVX_BUILTIN_LWS,
  KVX_BUILTIN_LD,
  KVX_BUILTIN_LQ,
  KVX_BUILTIN_LHF,
  KVX_BUILTIN_LWF,
  KVX_BUILTIN_LDF,

  KVX_BUILTIN_LBO,
  KVX_BUILTIN_LBX,
  KVX_BUILTIN_LBV,
  KVX_BUILTIN_LHQ,
  KVX_BUILTIN_LHO,
  KVX_BUILTIN_LHX,
  KVX_BUILTIN_LWP,
  KVX_BUILTIN_LWO,
  KVX_BUILTIN_LWQ,
  KVX_BUILTIN_LDP,
  KVX_BUILTIN_LDQ,

  KVX_BUILTIN_SBO,
  KVX_BUILTIN_SBX,
  KVX_BUILTIN_SBV,
  KVX_BUILTIN_SHQ,
  KVX_BUILTIN_SHO,
  KVX_BUILTIN_SHX,
  KVX_BUILTIN_SWP,
  KVX_BUILTIN_SWQ,
  KVX_BUILTIN_SWO,
  KVX_BUILTIN_SDP,
  KVX_BUILTIN_SDQ,

  KVX_BUILTIN_LOADBZ,
  KVX_BUILTIN_LOADHZ,
  KVX_BUILTIN_LOADWZ,
  KVX_BUILTIN_LOADD,
  KVX_BUILTIN_LOADQ,
  KVX_BUILTIN_LOAD64,
  KVX_BUILTIN_LOAD128,
  KVX_BUILTIN_LOAD256,
  KVX_BUILTIN_XLOAD256,

  KVX_BUILTIN_LOADCBZ,
  KVX_BUILTIN_LOADCHZ,
  KVX_BUILTIN_LOADCWZ,
  KVX_BUILTIN_LOADCD,
  KVX_BUILTIN_LOADCQ,
  KVX_BUILTIN_LOADC64,
  KVX_BUILTIN_LOADC128,
  KVX_BUILTIN_LOADC256,
  KVX_BUILTIN_XLOADC256,

  KVX_BUILTIN_STOREB,
  KVX_BUILTIN_STOREH,
  KVX_BUILTIN_STOREW,
  KVX_BUILTIN_STORED,
  KVX_BUILTIN_STOREQ,
  KVX_BUILTIN_STORE64,
  KVX_BUILTIN_STORE128,
  KVX_BUILTIN_STORE256,
  KVX_BUILTIN_XSTORE256,

  KVX_BUILTIN_STORECB,
  KVX_BUILTIN_STORECH,
  KVX_BUILTIN_STORECW,
  KVX_BUILTIN_STORECD,
  KVX_BUILTIN_STORECQ,
  KVX_BUILTIN_STOREC64,
  KVX_BUILTIN_STOREC128,
  KVX_BUILTIN_STOREC256,
  KVX_BUILTIN_XSTOREC256,

  KVX_BUILTIN_XLOAD256Q0,
  KVX_BUILTIN_XLOAD256Q1,
  KVX_BUILTIN_XLOAD256Q2,
  KVX_BUILTIN_XLOAD256Q3,

  KVX_BUILTIN_XLOADC256Q0,
  KVX_BUILTIN_XLOADC256Q1,
  KVX_BUILTIN_XLOADC256Q2,
  KVX_BUILTIN_XLOADC256Q3,

  KVX_BUILTIN_XSWAP256,
  KVX_BUILTIN_XMT44D,

  KVX_BUILTIN_XMMA484BW,

  KVX_BUILTIN__COUNT
};

static tree builtin_fndecls[KVX_BUILTIN__COUNT];

void
kvx_init_builtins (void)
{

#define VOID void_type_node
#define VPTR ptr_type_node
#define CVPTR const_ptr_type_node
#define BOOL boolean_type_node

#define INT8 intQI_type_node
#define INT16 intHI_type_node
#define INT32 intSI_type_node
#define INT64 intDI_type_node
#define INT128 intTI_type_node

#define UINT8 unsigned_intQI_type_node
#define UINT16 unsigned_intHI_type_node
#define UINT32 unsigned_intSI_type_node
#define UINT64 unsigned_intDI_type_node
#define UINT128 unsigned_intTI_type_node

#define FLOAT16 float16_type_node
#define FLOAT32 float_type_node
#define FLOAT64 double_type_node
#define COMPLEX64 complex_float_type_node
#define COMPLEX128 complex_double_type_node

  tree STRING = build_pointer_type (
    build_qualified_type (char_type_node, TYPE_QUAL_CONST));

  tree V8QI = build_opaque_vector_type (INT8, 8);
  tree V16QI = build_opaque_vector_type (INT8, 16);
  tree V32QI = build_opaque_vector_type (INT8, 32);
  tree V4HI = build_opaque_vector_type (INT16, 4);
  tree V8HI = build_opaque_vector_type (INT16, 8);
  tree V16HI = build_opaque_vector_type (INT16, 16);
  tree V2SI = build_opaque_vector_type (INT32, 2);
  tree V4SI = build_opaque_vector_type (INT32, 4);
  tree V8SI = build_opaque_vector_type (INT32, 8);
  tree V2DI = build_opaque_vector_type (INT64, 2);
  tree V4DI = build_opaque_vector_type (INT64, 4);
  tree V4HF = build_opaque_vector_type (FLOAT16, 4);
  tree V8HF = build_opaque_vector_type (FLOAT16, 8);
  tree V16HF = build_opaque_vector_type (FLOAT16, 16);
  tree V2SF = build_opaque_vector_type (FLOAT32, 2);
  tree V4SF = build_opaque_vector_type (FLOAT32, 4);
  tree V8SF = build_opaque_vector_type (FLOAT32, 8);
  tree V2DF = build_opaque_vector_type (FLOAT64, 2);
  tree V4DF = build_opaque_vector_type (FLOAT64, 4);

  add_builtin_type ("__kvx_v8qi", V8QI);
  add_builtin_type ("__kvx_v16qi", V16QI);
  add_builtin_type ("__kvx_v32qi", V32QI);
  add_builtin_type ("__kvx_v4hi", V4HI);
  add_builtin_type ("__kvx_v8hi", V8HI);
  add_builtin_type ("__kvx_v16hi", V16HI);
  add_builtin_type ("__kvx_v2si", V2SI);
  add_builtin_type ("__kvx_v4si", V4SI);
  add_builtin_type ("__kvx_v8si", V8SI);
  add_builtin_type ("__kvx_v2di", V2DI);
  add_builtin_type ("__kvx_v4di", V4DI);
  add_builtin_type ("__kvx_v4hf", V4HF);
  add_builtin_type ("__kvx_v8hf", V8HF);
  add_builtin_type ("__kvx_v16hf", V16HF);
  add_builtin_type ("__kvx_v2sf", V2SF);
  add_builtin_type ("__kvx_v4sf", V4SF);
  add_builtin_type ("__kvx_v8sf", V8SF);
  add_builtin_type ("__kvx_v2df", V2DF);
  add_builtin_type ("__kvx_v4df", V4DF);

  tree OI = make_signed_type (256);
  tree X256 = build_opaque_vector_type (OI, 1);
  tree X512 = build_opaque_vector_type (OI, 2);
  tree X1024 = build_opaque_vector_type (OI, 4);
  tree _X256 = build_pointer_type (X256);

  add_builtin_type ("__kvx_x256", X256);
  add_builtin_type ("__kvx_x512", X512);
  add_builtin_type ("__kvx_x1024", X1024);

#define ADD_KVX_BUILTIN_VARAGS(UC_NAME, LC_NAME, ...)                          \
  builtin_fndecls[KVX_BUILTIN_##UC_NAME]                                       \
    = add_builtin_function ("__builtin_kvx_" LC_NAME,                          \
			    build_varargs_function_type_list (__VA_ARGS__,     \
							      NULL_TREE),      \
			    KVX_BUILTIN_##UC_NAME, BUILT_IN_MD, NULL,          \
			    NULL_TREE)

#define ADD_KVX_BUILTIN(UC_NAME, LC_NAME, ...)                                 \
  builtin_fndecls[KVX_BUILTIN_##UC_NAME]                                       \
    = add_builtin_function ("__builtin_kvx_" LC_NAME,                          \
			    build_function_type_list (__VA_ARGS__, NULL_TREE), \
			    KVX_BUILTIN_##UC_NAME, BUILT_IN_MD, NULL,          \
			    NULL_TREE)

#define CARRY STRING
#define AVERAGE STRING
#define SATURATE STRING
#define SIGNEDSAT STRING
#define EXTENDMUL STRING
#define WIDENINT STRING
#define NARROWINT STRING
#define SHIFTLEFT STRING
#define SHIFTRIGHT STRING
#define COUNTING STRING
#define SIMDCOND STRING
#define FLOATINGS STRING
#define CONJUGATE STRING
#define TRANSPOSE STRING
#define SILENT STRING
#define VARIANT STRING
#define VOLATILE STRING
#define LOADCOND STRING
#define STORECOND STRING
#define XMATMUL STRING
#define UNUSED STRING

  ADD_KVX_BUILTIN (ADDCD, "addcd", UINT64, UINT64, UINT64, CARRY); // Scalar
  ADD_KVX_BUILTIN (SBFCD, "sbfcd", UINT64, UINT64, UINT64, CARRY); // Scalar

  ADD_KVX_BUILTIN (ADDBO, "addbo", V8QI, V8QI, V8QI, SATURATE); // Vector
  ADD_KVX_BUILTIN (ADDBX, "addbx", V16QI, V16QI, V16QI, SATURATE); // Vector
  ADD_KVX_BUILTIN (ADDBV, "addbv", V32QI, V32QI, V32QI, SATURATE); // Vector
  ADD_KVX_BUILTIN (ADDHQ, "addhq", V4HI, V4HI, V4HI, SATURATE); // Vector
  ADD_KVX_BUILTIN (ADDHO, "addho", V8HI, V8HI, V8HI, SATURATE); // Vector
  ADD_KVX_BUILTIN (ADDHX, "addhx", V16HI, V16HI, V16HI, SATURATE); // Vector
  ADD_KVX_BUILTIN (ADDW, "addw", INT32, INT32, INT32, SATURATE); // Scalar
  ADD_KVX_BUILTIN (ADDWP, "addwp", V2SI, V2SI, V2SI, SATURATE); // Vector
  ADD_KVX_BUILTIN (ADDWQ, "addwq", V4SI, V4SI, V4SI, SATURATE); // Vector
  ADD_KVX_BUILTIN (ADDWO, "addwo", V8SI, V8SI, V8SI, SATURATE); // Vector
  ADD_KVX_BUILTIN (ADDD, "addd", INT64, INT64, INT64, SATURATE); // Scalar
  ADD_KVX_BUILTIN (ADDDP, "adddp", V2DI, V2DI, V2DI, SATURATE); // Vector
  ADD_KVX_BUILTIN (ADDDQ, "adddq", V4DI, V4DI, V4DI, SATURATE); // Vector

  ADD_KVX_BUILTIN (SBFBO, "sbfbo", V8QI, V8QI, V8QI, SATURATE); // Vector
  ADD_KVX_BUILTIN (SBFBX, "sbfbx", V16QI, V16QI, V16QI, SATURATE); // Vector
  ADD_KVX_BUILTIN (SBFBV, "sbfbv", V32QI, V32QI, V32QI, SATURATE); // Vector
  ADD_KVX_BUILTIN (SBFHQ, "sbfhq", V4HI, V4HI, V4HI, SATURATE); // Vector
  ADD_KVX_BUILTIN (SBFHO, "sbfho", V8HI, V8HI, V8HI, SATURATE); // Vector
  ADD_KVX_BUILTIN (SBFHX, "sbfhx", V16HI, V16HI, V16HI, SATURATE); // Vector
  ADD_KVX_BUILTIN (SBFW, "sbfw", INT32, INT32, INT32, SATURATE); // Scalar
  ADD_KVX_BUILTIN (SBFWP, "sbfwp", V2SI, V2SI, V2SI, SATURATE); // Vector
  ADD_KVX_BUILTIN (SBFWQ, "sbfwq", V4SI, V4SI, V4SI, SATURATE); // Vector
  ADD_KVX_BUILTIN (SBFWO, "sbfwo", V8SI, V8SI, V8SI, SATURATE); // Vector
  ADD_KVX_BUILTIN (SBFD, "sbfd", INT64, INT64, INT64, SATURATE); // Scalar
  ADD_KVX_BUILTIN (SBFDP, "sbfdp", V2DI, V2DI, V2DI, SATURATE); // Vector
  ADD_KVX_BUILTIN (SBFDQ, "sbfdq", V4DI, V4DI, V4DI, SATURATE); // Vector

  ADD_KVX_BUILTIN (NEGBO, "negbo", V8QI, V8QI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (NEGBX, "negbx", V16QI, V16QI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (NEGBV, "negbv", V32QI, V32QI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (NEGHQ, "neghq", V4HI, V4HI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (NEGHO, "negho", V8HI, V8HI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (NEGHX, "neghx", V16HI, V16HI, SIGNEDSAT); // Vector
  ADD_KVX_BUILTIN (NEGW, "negw", INT32, INT32, SIGNEDSAT); // Scalar
  ADD_KVX_BUILTIN (NEGWP, "negwp", V2SI, V2SI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (NEGWQ, "negwq", V4SI, V4SI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (NEGWO, "negwo", V8SI, V8SI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (NEGD, "negd", INT64, INT64, SIGNEDSAT); // Scalar
  ADD_KVX_BUILTIN (NEGDP, "negdp", V2DI, V2DI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (NEGDQ, "negdq", V4DI, V4DI, SIGNEDSAT);	// Vector

  ADD_KVX_BUILTIN (ABSBO, "absbo", V8QI, V8QI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (ABSBX, "absbx", V16QI, V16QI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (ABSBV, "absbv", V32QI, V32QI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (ABSHQ, "abshq", V4HI, V4HI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (ABSHO, "absho", V8HI, V8HI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (ABSHX, "abshx", V16HI, V16HI, SIGNEDSAT); // Vector
  ADD_KVX_BUILTIN (ABSW, "absw", INT32, INT32, SIGNEDSAT); // Scalar
  ADD_KVX_BUILTIN (ABSWP, "abswp", V2SI, V2SI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (ABSWQ, "abswq", V4SI, V4SI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (ABSWO, "abswo", V8SI, V8SI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (ABSD, "absd", INT64, INT64, SIGNEDSAT); // Scalar
  ADD_KVX_BUILTIN (ABSDP, "absdp", V2DI, V2DI, SIGNEDSAT);	// Vector
  ADD_KVX_BUILTIN (ABSDQ, "absdq", V4DI, V4DI, SIGNEDSAT);	// Vector

  ADD_KVX_BUILTIN (ABDBO, "abdbo", V8QI, V8QI, V8QI, SIGNEDSAT); // Vector
  ADD_KVX_BUILTIN (ABDBX, "abdbx", V16QI, V16QI, V16QI, SIGNEDSAT); // Vector
  ADD_KVX_BUILTIN (ABDBV, "abdbv", V32QI, V32QI, V32QI, SIGNEDSAT); // Vector
  ADD_KVX_BUILTIN (ABDHQ, "abdhq", V4HI, V4HI, V4HI, SIGNEDSAT); // Vector
  ADD_KVX_BUILTIN (ABDHO, "abdho", V8HI, V8HI, V8HI, SIGNEDSAT); // Vector
  ADD_KVX_BUILTIN (ABDHX, "abdhx", V16HI, V16HI, V16HI, SIGNEDSAT); // Vector
  ADD_KVX_BUILTIN (ABDW, "abdw", INT32, INT32, INT32, SIGNEDSAT); // Scalar
  ADD_KVX_BUILTIN (ABDWP, "abdwp", V2SI, V2SI, V2SI, SIGNEDSAT); // Vector
  ADD_KVX_BUILTIN (ABDWQ, "abdwq", V4SI, V4SI, V4SI, SIGNEDSAT); // Vector
  ADD_KVX_BUILTIN (ABDWO, "abdwo", V8SI, V8SI, V8SI, SIGNEDSAT); // Vector
  ADD_KVX_BUILTIN (ABDD, "abdd", INT64, INT64, INT64, SIGNEDSAT); // Scalar
  ADD_KVX_BUILTIN (ABDDP, "abddp", V2DI, V2DI, V2DI, SIGNEDSAT); // Vector
  ADD_KVX_BUILTIN (ABDDQ, "abddq", V4DI, V4DI, V4DI, SIGNEDSAT); // Vector

  ADD_KVX_BUILTIN (AVGBO, "avgbo", V8QI, V8QI, V8QI, AVERAGE); // Vector
  ADD_KVX_BUILTIN (AVGBX, "avgbx", V16QI, V16QI, V16QI, AVERAGE); // Vector
  ADD_KVX_BUILTIN (AVGBV, "avgbv", V32QI, V32QI, V32QI, AVERAGE); // Vector
  ADD_KVX_BUILTIN (AVGHQ, "avghq", V4HI, V4HI, V4HI, AVERAGE); // Vector
  ADD_KVX_BUILTIN (AVGHO, "avgho", V8HI, V8HI, V8HI, AVERAGE); // Vector
  ADD_KVX_BUILTIN (AVGHX, "avghx", V16HI, V16HI, V16HI, AVERAGE); // Vector
  ADD_KVX_BUILTIN (AVGW, "avgw", INT32, INT32, INT32, AVERAGE); // Scalar
  ADD_KVX_BUILTIN (AVGWP, "avgwp", V2SI, V2SI, V2SI, AVERAGE); // Vector
  ADD_KVX_BUILTIN (AVGWQ, "avgwq", V4SI, V4SI, V4SI, AVERAGE); // Vector
  ADD_KVX_BUILTIN (AVGWO, "avgwo", V8SI, V8SI, V8SI, AVERAGE); // Vector

  ADD_KVX_BUILTIN (MULXHWQ, "mulxhwq", V4SI, V4HI, V4HI, EXTENDMUL); // Vector
  ADD_KVX_BUILTIN (MULXHWO, "mulxhwo", V8SI, V8HI, V8HI, EXTENDMUL); // Vector
  ADD_KVX_BUILTIN (MULXWDP, "mulxwdp", V2DI, V2SI, V2SI, EXTENDMUL); // Vector
  ADD_KVX_BUILTIN (MULXWDQ, "mulxwdq", V4DI, V4SI, V4SI, EXTENDMUL); // Vector

  ADD_KVX_BUILTIN (MADDXHWQ, "maddxhwq", V4SI, V4HI, V4HI, V4SI, EXTENDMUL); // Vector
  ADD_KVX_BUILTIN (MADDXHWO, "maddxhwo", V8SI, V8HI, V8HI, V8SI, EXTENDMUL); // Vector
  ADD_KVX_BUILTIN (MADDXWDP, "maddxwdp", V2DI, V2SI, V2SI, V2DI, EXTENDMUL); // Vector
  ADD_KVX_BUILTIN (MADDXWDQ, "maddxwdq", V4DI, V4SI, V4SI, V4DI, EXTENDMUL); // Vector

  ADD_KVX_BUILTIN (MSBFXHWQ, "msbfxhwq", V4SI, V4HI, V4HI, V4SI, EXTENDMUL); // Vector
  ADD_KVX_BUILTIN (MSBFXHWO, "msbfxhwo", V8SI, V8HI, V8HI, V8SI, EXTENDMUL); // Vector
  ADD_KVX_BUILTIN (MSBFXWDP, "msbfxwdp", V2DI, V2SI, V2SI, V2DI, EXTENDMUL); // Vector
  ADD_KVX_BUILTIN (MSBFXWDQ, "msbfxwdq", V4DI, V4SI, V4SI, V4DI, EXTENDMUL); // Vector

  ADD_KVX_BUILTIN (MINBO, "minbo", V8QI, V8QI, V8QI); // Vector
  ADD_KVX_BUILTIN (MINBX, "minbx", V16QI, V16QI, V16QI); // Vector
  ADD_KVX_BUILTIN (MINBV, "minbv", V32QI, V32QI, V32QI); // Vector
  ADD_KVX_BUILTIN (MINHQ, "minhq", V4HI, V4HI, V4HI); // Vector
  ADD_KVX_BUILTIN (MINHO, "minho", V8HI, V8HI, V8HI); // Vector
  ADD_KVX_BUILTIN (MINHX, "minhx", V16HI, V16HI, V16HI); // Vector
  ADD_KVX_BUILTIN (MINW, "minw", INT32, INT32, INT32); // Scalar
  ADD_KVX_BUILTIN (MINWP, "minwp", V2SI, V2SI, V2SI); // Vector
  ADD_KVX_BUILTIN (MINWQ, "minwq", V4SI, V4SI, V4SI); // Vector
  ADD_KVX_BUILTIN (MINWO, "minwo", V8SI, V8SI, V8SI); // Vector
  ADD_KVX_BUILTIN (MIND, "mind", INT64, INT64, INT64); // Scalar
  ADD_KVX_BUILTIN (MINDP, "mindp", V2DI, V2DI, V2DI); // Vector
  ADD_KVX_BUILTIN (MINDQ, "mindq", V4DI, V4DI, V4DI); // Vector

  ADD_KVX_BUILTIN (MAXBO, "maxbo", V8QI, V8QI, V8QI); // Vector
  ADD_KVX_BUILTIN (MAXBX, "maxbx", V16QI, V16QI, V16QI); // Vector
  ADD_KVX_BUILTIN (MAXBV, "maxbv", V32QI, V32QI, V32QI); // Vector
  ADD_KVX_BUILTIN (MAXHQ, "maxhq", V4HI, V4HI, V4HI); // Vector
  ADD_KVX_BUILTIN (MAXHO, "maxho", V8HI, V8HI, V8HI); // Vector
  ADD_KVX_BUILTIN (MAXHX, "maxhx", V16HI, V16HI, V16HI); // Vector
  ADD_KVX_BUILTIN (MAXW, "maxw", INT32, INT32, INT32); // Scalar
  ADD_KVX_BUILTIN (MAXWP, "maxwp", V2SI, V2SI, V2SI); // Vector
  ADD_KVX_BUILTIN (MAXWQ, "maxwq", V4SI, V4SI, V4SI); // Vector
  ADD_KVX_BUILTIN (MAXWO, "maxwo", V8SI, V8SI, V8SI); // Vector
  ADD_KVX_BUILTIN (MAXD, "maxd", INT64, INT64, INT64); // Scalar
  ADD_KVX_BUILTIN (MAXDP, "maxdp", V2DI, V2DI, V2DI); // Vector
  ADD_KVX_BUILTIN (MAXDQ, "maxdq", V4DI, V4DI, V4DI); // Vector

  ADD_KVX_BUILTIN (MINUBO, "minubo", V8QI, V8QI, V8QI); // Vector
  ADD_KVX_BUILTIN (MINUBX, "minubx", V16QI, V16QI, V16QI); // Vector
  ADD_KVX_BUILTIN (MINUBV, "minubv", V32QI, V32QI, V32QI); // Vector
  ADD_KVX_BUILTIN (MINUHQ, "minuhq", V4HI, V4HI, V4HI); // Vector
  ADD_KVX_BUILTIN (MINUHO, "minuho", V8HI, V8HI, V8HI); // Vector
  ADD_KVX_BUILTIN (MINUHX, "minuhx", V16HI, V16HI, V16HI); // Vector
  ADD_KVX_BUILTIN (MINUW, "minuw", INT32, INT32, INT32); // Scalar
  ADD_KVX_BUILTIN (MINUWP, "minuwp", V2SI, V2SI, V2SI); // Vector
  ADD_KVX_BUILTIN (MINUWQ, "minuwq", V4SI, V4SI, V4SI); // Vector
  ADD_KVX_BUILTIN (MINUWO, "minuwo", V8SI, V8SI, V8SI); // Vector
  ADD_KVX_BUILTIN (MINUD, "minud", INT64, INT64, INT64); // Scalar
  ADD_KVX_BUILTIN (MINUDP, "minudp", V2DI, V2DI, V2DI); // Vector
  ADD_KVX_BUILTIN (MINUDQ, "minudq", V4DI, V4DI, V4DI); // Vector

  ADD_KVX_BUILTIN (MAXUBO, "maxubo", V8QI, V8QI, V8QI); // Vector
  ADD_KVX_BUILTIN (MAXUBX, "maxubx", V16QI, V16QI, V16QI); // Vector
  ADD_KVX_BUILTIN (MAXUBV, "maxubv", V32QI, V32QI, V32QI); // Vector
  ADD_KVX_BUILTIN (MAXUHQ, "maxuhq", V4HI, V4HI, V4HI); // Vector
  ADD_KVX_BUILTIN (MAXUHO, "maxuho", V8HI, V8HI, V8HI); // Vector
  ADD_KVX_BUILTIN (MAXUHX, "maxuhx", V16HI, V16HI, V16HI); // Vector
  ADD_KVX_BUILTIN (MAXUW, "maxuw", INT32, INT32, INT32); // Scalar
  ADD_KVX_BUILTIN (MAXUWP, "maxuwp", V2SI, V2SI, V2SI); // Vector
  ADD_KVX_BUILTIN (MAXUWQ, "maxuwq", V4SI, V4SI, V4SI); // Vector
  ADD_KVX_BUILTIN (MAXUWO, "maxuwo", V8SI, V8SI, V8SI); // Vector
  ADD_KVX_BUILTIN (MAXUD, "maxud", INT64, INT64, INT64); // Scalar
  ADD_KVX_BUILTIN (MAXUDP, "maxudp", V2DI, V2DI, V2DI); // Vector
  ADD_KVX_BUILTIN (MAXUDQ, "maxudq", V4DI, V4DI, V4DI); // Vector

  ADD_KVX_BUILTIN (SHLBOS, "shlbos", V8QI, V8QI, UINT32, SHIFTLEFT); // Vector
  ADD_KVX_BUILTIN (SHLBXS, "shlbxs", V16QI, V16QI, UINT32, SHIFTLEFT); // Vector
  ADD_KVX_BUILTIN (SHLBVS, "shlbvs", V32QI, V32QI, UINT32, SHIFTLEFT); // Vector
  ADD_KVX_BUILTIN (SHLHQS, "shlhqs", V4HI, V4HI, UINT32, SHIFTLEFT); // Vector
  ADD_KVX_BUILTIN (SHLHOS, "shlhos", V8HI, V8HI, UINT32, SHIFTLEFT); // Vector
  ADD_KVX_BUILTIN (SHLHXS, "shlhxs", V16HI, V16HI, UINT32, SHIFTLEFT); // Vector
  ADD_KVX_BUILTIN (SHLW, "shlw", INT32, INT32, UINT32, SHIFTLEFT); // Scalar
  ADD_KVX_BUILTIN (SHLWPS, "shlwps", V2SI, V2SI, UINT32, SHIFTLEFT); // Vector
  ADD_KVX_BUILTIN (SHLWQS, "shlwqs", V4SI, V4SI, UINT32, SHIFTLEFT); // Vector
  ADD_KVX_BUILTIN (SHLWOS, "shlwos", V8SI, V8SI, UINT32, SHIFTLEFT); // Vector
  ADD_KVX_BUILTIN (SHLD, "shld", INT64, INT64, UINT32, SHIFTLEFT); // Scalar
  ADD_KVX_BUILTIN (SHLDPS, "shldps", V2DI, V2DI, UINT32, SHIFTLEFT); // Vector
  ADD_KVX_BUILTIN (SHLDQS, "shldqs", V4DI, V4DI, UINT32, SHIFTLEFT); // Vector

  ADD_KVX_BUILTIN (SHRBOS, "shrbos", V8QI, V8QI, UINT32, SHIFTRIGHT); // Vector
  ADD_KVX_BUILTIN (SHRBXS, "shrbxs", V16QI, V16QI, UINT32, SHIFTRIGHT); // Vector
  ADD_KVX_BUILTIN (SHRBVS, "shrbvs", V32QI, V32QI, UINT32, SHIFTRIGHT); // Vector
  ADD_KVX_BUILTIN (SHRHQS, "shrhqs", V4HI, V4HI, UINT32, SHIFTRIGHT); // Vector
  ADD_KVX_BUILTIN (SHRHOS, "shrhos", V8HI, V8HI, UINT32, SHIFTRIGHT); // Vector
  ADD_KVX_BUILTIN (SHRHXS, "shrhxs", V16HI, V16HI, UINT32, SHIFTRIGHT); // Vector
  ADD_KVX_BUILTIN (SHRW, "shrw", INT32, INT32, UINT32, SHIFTRIGHT); // Scalar
  ADD_KVX_BUILTIN (SHRWPS, "shrwps", V2SI, V2SI, UINT32, SHIFTRIGHT); // Vector
  ADD_KVX_BUILTIN (SHRWQS, "shrwqs", V4SI, V4SI, UINT32, SHIFTRIGHT); // Vector
  ADD_KVX_BUILTIN (SHRWOS, "shrwos", V8SI, V8SI, UINT32, SHIFTRIGHT); // Vector
  ADD_KVX_BUILTIN (SHRD, "shrd", INT64, INT64, UINT32, SHIFTRIGHT); // Scalar
  ADD_KVX_BUILTIN (SHRDPS, "shrdps", V2DI, V2DI, UINT32, SHIFTRIGHT); // Vector
  ADD_KVX_BUILTIN (SHRDQS, "shrdqs", V4DI, V4DI, UINT32, SHIFTRIGHT); // Vector

  ADD_KVX_BUILTIN (CLZW, "clzw", INT32, INT32); // Deprecated
  ADD_KVX_BUILTIN (CLZD, "clzd", INT64, INT64); // Deprecated
  ADD_KVX_BUILTIN (CTZW, "ctzw", INT32, INT32); // Deprecated
  ADD_KVX_BUILTIN (CTZD, "ctzd", INT64, INT64); // Deprecated
  ADD_KVX_BUILTIN (CBSW, "cbsw", INT32, INT32); // Deprecated
  ADD_KVX_BUILTIN (CBSD, "cbsd", INT64, INT64); // Deprecated

  ADD_KVX_BUILTIN (BITCNTW, "bitcntw", INT32, INT32, COUNTING); // Scalar
  ADD_KVX_BUILTIN (BITCNTWP, "bitcntwp", V2SI, V2SI, COUNTING); // Vector
  ADD_KVX_BUILTIN (BITCNTWQ, "bitcntwq", V4SI, V4SI, COUNTING); // Vector
  ADD_KVX_BUILTIN (BITCNTWO, "bitcntwo", V8SI, V8SI, COUNTING); // Vector
  ADD_KVX_BUILTIN (BITCNTD, "bitcntd", INT64, INT64, COUNTING); // Scalar
  ADD_KVX_BUILTIN (BITCNTDP, "bitcntdp", V2DI, V2DI, COUNTING); // Vector
  ADD_KVX_BUILTIN (BITCNTDQ, "bitcntdq", V4DI, V4DI, COUNTING); // Vector

  ADD_KVX_BUILTIN (WIDENBHO, "widenbho", V8HI, V8QI, WIDENINT); // Vector
  ADD_KVX_BUILTIN (WIDENBHX, "widenbhx", V16HI, V16QI, WIDENINT); // Vector
  ADD_KVX_BUILTIN (WIDENHWQ, "widenhwq", V4SI, V4HI, WIDENINT); // Vector
  ADD_KVX_BUILTIN (WIDENHWO, "widenhwo", V8SI, V8HI, WIDENINT); // Vector
  ADD_KVX_BUILTIN (WIDENWDP, "widenwdp", V2DI, V2SI, WIDENINT); // Vector
  ADD_KVX_BUILTIN (WIDENWDQ, "widenwdq", V4DI, V4SI, WIDENINT); // Vector

  ADD_KVX_BUILTIN (NARROWHBO, "narrowhbo", V8QI, V8HI, NARROWINT); // Vector
  ADD_KVX_BUILTIN (NARROWHBX, "narrowhbx", V16QI, V16HI, NARROWINT); // Vector
  ADD_KVX_BUILTIN (NARROWWHQ, "narrowwhq", V4HI, V4SI, NARROWINT); // Vector
  ADD_KVX_BUILTIN (NARROWWHO, "narrowwho", V8HI, V8SI, NARROWINT); // Vector
  ADD_KVX_BUILTIN (NARROWDWP, "narrowdwp", V2SI, V2DI, NARROWINT); // Vector
  ADD_KVX_BUILTIN (NARROWDWQ, "narrowdwq", V4SI, V4DI, NARROWINT); // Vector

  ADD_KVX_BUILTIN (SHIFTBO, "shiftbo", V8QI, V8QI, INT32, INT8); // Vector
  ADD_KVX_BUILTIN (SHIFTBX, "shiftbx", V16QI, V16QI, INT32, INT8); // Vector
  ADD_KVX_BUILTIN (SHIFTBV, "shiftbv", V32QI, V32QI, INT32, INT8); // Vector
  ADD_KVX_BUILTIN (SHIFTHQ, "shifthq", V4HI, V4HI, INT32, INT16); // Vector
  ADD_KVX_BUILTIN (SHIFTHO, "shiftho", V8HI, V8HI, INT32, INT16); // Vector
  ADD_KVX_BUILTIN (SHIFTHX, "shifthx", V16HI, V16HI, INT32, INT16); // Vector
  ADD_KVX_BUILTIN (SHIFTWP, "shiftwp", V2SI, V2SI, INT32, INT32); // Vector
  ADD_KVX_BUILTIN (SHIFTWQ, "shiftwq", V4SI, V4SI, INT32, INT32); // Vector
  ADD_KVX_BUILTIN (SHIFTWO, "shiftwo", V8SI, V8SI, INT32, INT32); // Vector
  ADD_KVX_BUILTIN (SHIFTDP, "shiftdp", V2DI, V2DI, INT32, INT64); // Vector
  ADD_KVX_BUILTIN (SHIFTDQ, "shiftdq", V4DI, V4DI, INT32, INT64); // Vector
  ADD_KVX_BUILTIN (SHIFTFHQ, "shiftfhq", V4HF, V4HF, INT32, FLOAT16); // Vector
  ADD_KVX_BUILTIN (SHIFTFHO, "shiftfho", V8HF, V8HF, INT32, FLOAT16); // Vector
  ADD_KVX_BUILTIN (SHIFTFHX, "shiftfhx", V16HF, V16HF, INT32, FLOAT16); // Vector
  ADD_KVX_BUILTIN (SHIFTFWP, "shiftfwp", V2SF, V2SF, INT32, FLOAT32); // Vector
  ADD_KVX_BUILTIN (SHIFTFWQ, "shiftfwq", V4SF, V4SF, INT32, FLOAT32); // Vector
  ADD_KVX_BUILTIN (SHIFTFWO, "shiftfwo", V8SF, V8SF, INT32, FLOAT32); // Vector
  ADD_KVX_BUILTIN (SHIFTFDP, "shiftfdp", V2DF, V2DF, INT32, FLOAT64); // Vector
  ADD_KVX_BUILTIN (SHIFTFDQ, "shiftfdq", V4DF, V4DF, INT32, FLOAT64); // Vector

  ADD_KVX_BUILTIN (AWAIT, "await", VOID); // Control
  ADD_KVX_BUILTIN (BARRIER, "barrier", VOID); // Control
  ADD_KVX_BUILTIN (ACSWAPW, "acswapw", UINT32, VPTR, UINT32, UINT32); // Atomic
  ADD_KVX_BUILTIN (ACSWAPD, "acswapd", UINT64, VPTR, UINT64, UINT64); // Atomic
  ADD_KVX_BUILTIN (ALADDD, "aladdd", UINT64, VPTR, UINT64); // Atomic
  ADD_KVX_BUILTIN (ALADDW, "aladdw", UINT32, VPTR, UINT32); // Atomic
  ADD_KVX_BUILTIN (ALADDD, "afaddd", UINT64, VPTR, UINT64); // Deprecated
  ADD_KVX_BUILTIN (ALADDW, "afaddw", UINT32, VPTR, UINT32); // Deprecated
  ADD_KVX_BUILTIN (ALCLRD, "alclrd", UINT64, VPTR); // Atomic
  ADD_KVX_BUILTIN (ALCLRW, "alclrw", UINT32, VPTR); // Atomic
  ADD_KVX_BUILTIN (DINVAL, "dinval", VOID); // Memory
  ADD_KVX_BUILTIN (DINVALL, "dinvall", VOID, CVPTR); // Memory
  ADD_KVX_BUILTIN (DTOUCHL, "dtouchl", VOID, CVPTR); // Memory
  ADD_KVX_BUILTIN (DZEROL, "dzerol", VOID, VPTR); // Deprecated
  ADD_KVX_BUILTIN (FENCE, "fence", VOID); // Memory

  ADD_KVX_BUILTIN (CATBX, "catbx", V16QI, V8QI, V8QI); // Vector
  ADD_KVX_BUILTIN (CATBV, "catbv", V32QI, V16QI, V16QI); // Vector
  ADD_KVX_BUILTIN (CATHO, "catho", V8HI, V4HI, V4HI); // Vector
  ADD_KVX_BUILTIN (CATHX, "cathx", V16HI, V8HI, V8HI); // Vector
  ADD_KVX_BUILTIN (CATWP, "catwp", V2SI, INT32, INT32); // Deprecated
  ADD_KVX_BUILTIN (CATWQ, "catwq", V4SI, V2SI, V2SI); // Vector
  ADD_KVX_BUILTIN (CATWO, "catwo", V8SI, V4SI, V4SI); // Vector
  ADD_KVX_BUILTIN (CATDP, "catdp", V2DI, INT64, INT64); // Deprecated
  ADD_KVX_BUILTIN (CATDQ, "catdq", V4DI, V2DI, V2DI); // Deprecated
  ADD_KVX_BUILTIN (CATFHO, "catfho", V8HF, V4HF, V4HF); // Deprecated
  ADD_KVX_BUILTIN (CATFHX, "catfhx", V16HF, V8HF, V8HF); // Deprecated
  ADD_KVX_BUILTIN (CATFWP, "catfwp", V2SF, FLOAT32, FLOAT32); // Deprecated
  ADD_KVX_BUILTIN (CATFWQ, "catfwq", V4SF, V2SF, V2SF); // Deprecated
  ADD_KVX_BUILTIN (CATFWO, "catfwo", V8SF, V4SF, V4SF); // Deprecated
  ADD_KVX_BUILTIN (CATFDP, "catfdp", V2DF, FLOAT64, FLOAT64); // Deprecated
  ADD_KVX_BUILTIN (CATFDQ, "catfdq", V4DF, V2DF, V2DF); // Deprecated

  ADD_KVX_BUILTIN (SELECTBO, "selectbo", V8QI, V8QI, V8QI, V8QI, SIMDCOND); // Vector
  ADD_KVX_BUILTIN (SELECTBX, "selectbx", V16QI, V16QI, V16QI, V16QI, SIMDCOND); // Vector
  ADD_KVX_BUILTIN (SELECTBV, "selectbv", V32QI, V32QI, V32QI, V32QI, SIMDCOND); // Vector
  ADD_KVX_BUILTIN (SELECTHQ, "selecthq", V4HI, V4HI, V4HI, V4HI, SIMDCOND); // Vector
  ADD_KVX_BUILTIN (SELECTHO, "selectho", V8HI, V8HI, V8HI, V8HI, SIMDCOND); // Vector
  ADD_KVX_BUILTIN (SELECTHX, "selecthx", V16HI, V16HI, V16HI, V16HI, SIMDCOND); // Vector
  ADD_KVX_BUILTIN (SELECTWP, "selectwp", V2SI, V2SI, V2SI, V2SI, SIMDCOND); // Vector
  ADD_KVX_BUILTIN (SELECTWQ, "selectwq", V4SI, V4SI, V4SI, V4SI, SIMDCOND); // Vector
  ADD_KVX_BUILTIN (SELECTWO, "selectwo", V8SI, V8SI, V8SI, V8SI, SIMDCOND); // Vector
  ADD_KVX_BUILTIN (SELECTDP, "selectdp", V2DI, V2DI, V2DI, V2DI, SIMDCOND); // Vector
  ADD_KVX_BUILTIN (SELECTDQ, "selectdq", V4DI, V4DI, V4DI, V4DI, SIMDCOND); // Vector
  ADD_KVX_BUILTIN (SELECTFHQ, "selectfhq", V4HF, V4HF, V4HF, V4HI, SIMDCOND); // Deprecated
  ADD_KVX_BUILTIN (SELECTFHO, "selectfho", V8HF, V8HF, V8HF, V8HI, SIMDCOND); // Deprecated
  ADD_KVX_BUILTIN (SELECTFHX, "selectfhx", V16HF, V16HF, V16HF, V16HI, SIMDCOND); // Deprecated
  ADD_KVX_BUILTIN (SELECTFWP, "selectfwp", V2SF, V2SF, V2SF, V2SI, SIMDCOND); // Deprecated
  ADD_KVX_BUILTIN (SELECTFWQ, "selectfwq", V4SF, V4SF, V4SF, V4SI, SIMDCOND); // Deprecated
  ADD_KVX_BUILTIN (SELECTFWO, "selectfwo", V8SF, V8SF, V8SF, V8SI, SIMDCOND); // Deprecated
  ADD_KVX_BUILTIN (SELECTFDP, "selectfdp", V2DF, V2DF, V2DF, V2DI, SIMDCOND); // Deprecated
  ADD_KVX_BUILTIN (SELECTFDQ, "selectfdq", V4DF, V4DF, V4DF, V4DI, SIMDCOND); // Deprecated

  ADD_KVX_BUILTIN (COPYSIGNH, "copysignh", FLOAT16, FLOAT16, FLOAT16); // Scalar
  ADD_KVX_BUILTIN (COPYSIGNHQ, "copysignhq", V4HF, V4HF, V4HF); // Vector
  ADD_KVX_BUILTIN (COPYSIGNHO, "copysignho", V8HF, V8HF, V8HF); // Vector
  ADD_KVX_BUILTIN (COPYSIGNHX, "copysignhx", V16HF, V16HF, V16HF); // Vector
  ADD_KVX_BUILTIN (COPYSIGNW, "copysignw", FLOAT32, FLOAT32, FLOAT32); // Scalar
  ADD_KVX_BUILTIN (COPYSIGNWP, "copysignwp", V2SF, V2SF, V2SF); // Vector
  ADD_KVX_BUILTIN (COPYSIGNWQ, "copysignwq", V4SF, V4SF, V4SF); // Vector
  ADD_KVX_BUILTIN (COPYSIGNWO, "copysignwo", V8SF, V8SF, V8SF); // Vector
  ADD_KVX_BUILTIN (COPYSIGND, "copysignd", FLOAT64, FLOAT64, FLOAT64); // Scalar
  ADD_KVX_BUILTIN (COPYSIGNDP, "copysigndp", V2DF, V2DF, V2DF); // Vector
  ADD_KVX_BUILTIN (COPYSIGNDQ, "copysigndq", V4DF, V4DF, V4DF); // Vector

  ADD_KVX_BUILTIN (FMINH, "fminh", FLOAT16, FLOAT16, FLOAT16); // Scalar
  ADD_KVX_BUILTIN (FMINHQ, "fminhq", V4HF, V4HF, V4HF); // Vector
  ADD_KVX_BUILTIN (FMINHO, "fminho", V8HF, V8HF, V8HF); // Vector
  ADD_KVX_BUILTIN (FMINHX, "fminhx", V16HF, V16HF, V16HF); // Vector
  ADD_KVX_BUILTIN (FMINW, "fminw", FLOAT32, FLOAT32, FLOAT32); // Scalar
  ADD_KVX_BUILTIN (FMINWP, "fminwp", V2SF, V2SF, V2SF); // Vector
  ADD_KVX_BUILTIN (FMINWQ, "fminwq", V4SF, V4SF, V4SF); // Vector
  ADD_KVX_BUILTIN (FMINWO, "fminwo", V8SF, V8SF, V8SF); // Vector
  ADD_KVX_BUILTIN (FMIND, "fmind", FLOAT64, FLOAT64, FLOAT64); // Scalar
  ADD_KVX_BUILTIN (FMINDP, "fmindp", V2DF, V2DF, V2DF); // Vector
  ADD_KVX_BUILTIN (FMINDQ, "fmindq", V4DF, V4DF, V4DF); // Vector

  ADD_KVX_BUILTIN (FMAXH, "fmaxh", FLOAT16, FLOAT16, FLOAT16); // Scalar
  ADD_KVX_BUILTIN (FMAXHQ, "fmaxhq", V4HF, V4HF, V4HF); // Vector
  ADD_KVX_BUILTIN (FMAXHO, "fmaxho", V8HF, V8HF, V8HF); // Vector
  ADD_KVX_BUILTIN (FMAXHX, "fmaxhx", V16HF, V16HF, V16HF); // Vector
  ADD_KVX_BUILTIN (FMAXW, "fmaxw", FLOAT32, FLOAT32, FLOAT32); // Scalar
  ADD_KVX_BUILTIN (FMAXWP, "fmaxwp", V2SF, V2SF, V2SF); // Vector
  ADD_KVX_BUILTIN (FMAXWQ, "fmaxwq", V4SF, V4SF, V4SF); // Vector
  ADD_KVX_BUILTIN (FMAXWO, "fmaxwo", V8SF, V8SF, V8SF); // Vector
  ADD_KVX_BUILTIN (FMAXD, "fmaxd", FLOAT64, FLOAT64, FLOAT64); // Scalar
  ADD_KVX_BUILTIN (FMAXDP, "fmaxdp", V2DF, V2DF, V2DF); // Vector
  ADD_KVX_BUILTIN (FMAXDQ, "fmaxdq", V4DF, V4DF, V4DF); // Vector

  ADD_KVX_BUILTIN (FNEGH, "fnegh", FLOAT16, FLOAT16); // Scalar
  ADD_KVX_BUILTIN (FNEGHQ, "fneghq", V4HF, V4HF); // Vector
  ADD_KVX_BUILTIN (FNEGHO, "fnegho", V8HF, V8HF); // Vector
  ADD_KVX_BUILTIN (FNEGHX, "fneghx", V16HF, V16HF); // Vector
  ADD_KVX_BUILTIN (FNEGW, "fnegw", FLOAT32, FLOAT32); // Scalar
  ADD_KVX_BUILTIN (FNEGWP, "fnegwp", V2SF, V2SF); // Vector
  ADD_KVX_BUILTIN (FNEGWQ, "fnegwq", V4SF, V4SF); // Vector
  ADD_KVX_BUILTIN (FNEGWO, "fnegwo", V8SF, V8SF); // Vector
  ADD_KVX_BUILTIN (FNEGD, "fnegd", FLOAT64, FLOAT64); // Scalar
  ADD_KVX_BUILTIN (FNEGDP, "fnegdp", V2DF, V2DF); // Vector
  ADD_KVX_BUILTIN (FNEGDQ, "fnegdq", V4DF, V4DF); // Vector

  ADD_KVX_BUILTIN (FABSH, "fabsh", FLOAT16, FLOAT16); // Scalar
  ADD_KVX_BUILTIN (FABSHQ, "fabshq", V4HF, V4HF); // Vector
  ADD_KVX_BUILTIN (FABSHO, "fabsho", V8HF, V8HF); // Vector
  ADD_KVX_BUILTIN (FABSHX, "fabshx", V16HF, V16HF); // Vector
  ADD_KVX_BUILTIN (FABSW, "fabsw", FLOAT32, FLOAT32); // Scalar
  ADD_KVX_BUILTIN (FABSWP, "fabswp", V2SF, V2SF); // Vector
  ADD_KVX_BUILTIN (FABSWQ, "fabswq", V4SF, V4SF); // Vector
  ADD_KVX_BUILTIN (FABSWO, "fabswo", V8SF, V8SF); // Vector
  ADD_KVX_BUILTIN (FABSD, "fabsd", FLOAT64, FLOAT64); // Scalar
  ADD_KVX_BUILTIN (FABSDP, "fabsdp", V2DF, V2DF); // Vector
  ADD_KVX_BUILTIN (FABSDQ, "fabsdq", V4DF, V4DF); // Vector

  ADD_KVX_BUILTIN (FRECW, "finvw", FLOAT32, FLOAT32, FLOATINGS); // Deprecated
  ADD_KVX_BUILTIN (FRECW, "frecw", FLOAT32, FLOAT32, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FRECWP, "frecwp", V2SF, V2SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FRECWQ, "frecwq", V4SF, V4SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FRECWO, "frecwo", V8SF, V8SF, FLOATINGS); // Vector

  ADD_KVX_BUILTIN (FRSRW, "fisrw", FLOAT32, FLOAT32, FLOATINGS); // Deprecated
  ADD_KVX_BUILTIN (FRSRW, "frsrw", FLOAT32, FLOAT32, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FRSRWP, "frsrwp", V2SF, V2SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FRSRWQ, "frsrwq", V4SF, V4SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FRSRWO, "frsrwo", V8SF, V8SF, FLOATINGS); // Vector

  ADD_KVX_BUILTIN (FADDH, "faddh", FLOAT16, FLOAT16, FLOAT16, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FADDHQ, "faddhq", V4HF, V4HF, V4HF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FADDHO, "faddho", V8HF, V8HF, V8HF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FADDHX, "faddhx", V16HF, V16HF, V16HF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FADDW, "faddw", FLOAT32, FLOAT32, FLOAT32, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FADDWP, "faddwp", V2SF, V2SF, V2SF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FADDWQ, "faddwq", V4SF, V4SF, V4SF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FADDWO, "faddwo", V8SF, V8SF, V8SF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FADDD, "faddd", FLOAT64, FLOAT64, FLOAT64, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FADDDP, "fadddp", V2DF, V2DF, V2DF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FADDDQ, "fadddq", V4DF, V4DF, V4DF, CONJUGATE); // Vector

  ADD_KVX_BUILTIN (FSBFH, "fsbfh", FLOAT16, FLOAT16, FLOAT16, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FSBFHQ, "fsbfhq", V4HF, V4HF, V4HF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FSBFHO, "fsbfho", V8HF, V8HF, V8HF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FSBFHX, "fsbfhx", V16HF, V16HF, V16HF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FSBFW, "fsbfw", FLOAT32, FLOAT32, FLOAT32, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FSBFWP, "fsbfwp", V2SF, V2SF, V2SF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FSBFWQ, "fsbfwq", V4SF, V4SF, V4SF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FSBFWO, "fsbfwo", V8SF, V8SF, V8SF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FSBFD, "fsbfd", FLOAT64, FLOAT64, FLOAT64, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FSBFDP, "fsbfdp", V2DF, V2DF, V2DF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FSBFDQ, "fsbfdq", V4DF, V4DF, V4DF, CONJUGATE); // Vector

  ADD_KVX_BUILTIN (FMULH, "fmulh", FLOAT16, FLOAT16, FLOAT16, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FMULHQ, "fmulhq", V4HF, V4HF, V4HF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FMULHO, "fmulho", V8HF, V8HF, V8HF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FMULHX, "fmulhx", V16HF, V16HF, V16HF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FMULW, "fmulw", FLOAT32, FLOAT32, FLOAT32, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FMULWP, "fmulwp", V2SF, V2SF, V2SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FMULWQ, "fmulwq", V4SF, V4SF, V4SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FMULWO, "fmulwo", V8SF, V8SF, V8SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FMULD, "fmuld", FLOAT64, FLOAT64, FLOAT64, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FMULDP, "fmuldp", V2DF, V2DF, V2DF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FMULDQ, "fmuldq", V4DF, V4DF, V4DF, FLOATINGS); // Vector

  ADD_KVX_BUILTIN (FMULXHW, "fmulxhw", FLOAT32, FLOAT16, FLOAT16, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FMULXHWQ, "fmulxhwq", V4SF, V4HF, V4HF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FMULXHWO, "fmulxhwo", V8SF, V8HF, V8HF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FMULXWD, "fmulxwd", FLOAT64, FLOAT32, FLOAT32, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FMULXWDP, "fmulxwdp", V2DF, V2SF, V2SF, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FMULXWDQ, "fmulxwdq", V4DF, V4SF, V4SF, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FMULWC, "fmulwc", V2SF, V2SF, V2SF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FMULWCP, "fmulwcp", V4SF, V4SF, V4SF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FMULWCQ, "fmulwcq", V8SF, V8SF, V8SF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FMULDC, "fmuldc", V2DF, V2DF, V2DF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FMULDCP, "fmuldcp", V4DF, V4DF, V4DF, CONJUGATE); // Vector

  ADD_KVX_BUILTIN (FFMAH, "ffmah", FLOAT16, FLOAT16, FLOAT16, FLOAT16, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FFMAHQ, "ffmahq", V4HF, V4HF, V4HF, V4HF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMAHO, "ffmaho", V8HF, V8HF, V8HF, V8HF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMAHX, "ffmahx", V16HF, V16HF, V16HF, V16HF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMAW, "ffmaw", FLOAT32, FLOAT32, FLOAT32, FLOAT32, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FFMAWP, "ffmawp", V2SF, V2SF, V2SF, V2SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMAWQ, "ffmawq", V4SF, V4SF, V4SF, V4SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMAWO, "ffmawo", V8SF, V8SF, V8SF, V8SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMAD, "ffmad", FLOAT64, FLOAT64, FLOAT64, FLOAT64, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FFMADP, "ffmadp", V2DF, V2DF, V2DF, V2DF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMADQ, "ffmadq", V4DF, V4DF, V4DF, V4DF, FLOATINGS); // Vector

  ADD_KVX_BUILTIN (FFMAXHW, "ffmaxhw", FLOAT32, FLOAT16, FLOAT16, FLOAT32, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FFMAXHWQ, "ffmaxhwq", V4SF, V4HF, V4HF, V4SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMAXHWO, "ffmaxhwo", V8SF, V8HF, V8HF, V8SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMAXWD, "ffmaxwd", FLOAT64, FLOAT32, FLOAT32, FLOAT64, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FFMAXWDP, "ffmaxwdp", V2DF, V2SF, V2SF, V2DF, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FFMAXWDQ, "ffmaxwdq", V4DF, V4SF, V4SF, V4DF, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FFMAWC, "ffmawc", V2SF, V2SF, V2SF, V2SF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FFMAWCP, "ffmawcp", V4SF, V4SF, V4SF, V4SF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FFMAWCQ, "ffmawcq", V8SF, V8SF, V8SF, V8SF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FFMADC, "ffmadc", V2DF, V2DF, V2DF, V2DF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FFMADCP, "ffmadcp", V4DF, V4DF, V4DF, V4DF, CONJUGATE); // Vector

  ADD_KVX_BUILTIN (FFMSH, "ffmsh", FLOAT16, FLOAT16, FLOAT16, FLOAT16, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FFMSHQ, "ffmshq", V4HF, V4HF, V4HF, V4HF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMSHO, "ffmsho", V8HF, V8HF, V8HF, V8HF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMSHX, "ffmshx", V16HF, V16HF, V16HF, V16HF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMSW, "ffmsw", FLOAT32, FLOAT32, FLOAT32, FLOAT32, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FFMSWP, "ffmswp", V2SF, V2SF, V2SF, V2SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMSWQ, "ffmswq", V4SF, V4SF, V4SF, V4SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMSWO, "ffmswo", V8SF, V8SF, V8SF, V8SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMSD, "ffmsd", FLOAT64, FLOAT64, FLOAT64, FLOAT64, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FFMSDP, "ffmsdp", V2DF, V2DF, V2DF, V2DF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMSDQ, "ffmsdq", V4DF, V4DF, V4DF, V4DF, FLOATINGS); // Vector

  ADD_KVX_BUILTIN (FFMSXHW, "ffmsxhw", FLOAT32, FLOAT16, FLOAT16, FLOAT32, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FFMSXHWQ, "ffmsxhwq", V4SF, V4HF, V4HF, V4SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMSXHWO, "ffmsxhwo", V8SF, V8HF, V8HF, V8SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMSXWD, "ffmsxwd", FLOAT64, FLOAT32, FLOAT32, FLOAT64, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FFMSXWDP, "ffmsxwdp", V2DF, V2SF, V2SF, V2DF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMSXWDQ, "ffmsxwdq", V4DF, V4SF, V4SF, V4DF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFMSWC, "ffmswc", V2SF, V2SF, V2SF, V2SF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FFMSWCP, "ffmswcp", V4SF, V4SF, V4SF, V4SF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FFMSWCQ, "ffmswcq", V8SF, V8SF, V8SF, V8SF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FFMSDC, "ffmsdc", V2DF, V2DF, V2DF, V2DF, CONJUGATE); // Vector
  ADD_KVX_BUILTIN (FFMSDCP, "ffmsdcp", V4DF, V4DF, V4DF, V4DF, CONJUGATE); // Vector

  ADD_KVX_BUILTIN (FMM212W, "fmm212w", V4SF, V2SF, V2SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FMM222W, "fmm222w", V4SF, V4SF, V4SF, TRANSPOSE); // Vector
  ADD_KVX_BUILTIN (FMMA212W, "fmma212w", V4SF, V2SF, V2SF, V4SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FMMA222W, "fmma222w", V4SF, V4SF, V4SF, V4SF, TRANSPOSE); // Vector
  ADD_KVX_BUILTIN (FMMS212W, "fmms212w", V4SF, V2SF, V2SF, V4SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FMMS222W, "fmms222w", V4SF, V4SF, V4SF, V4SF, TRANSPOSE); // Vector

  ADD_KVX_BUILTIN (FFDMAW, "ffdmaw", FLOAT32, V2SF, V2SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFDMAWP, "ffdmawp", V2SF, V4SF, V4SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFDMAWQ, "ffdmawq", V4SF, V8SF, V8SF, FLOATINGS); // Vector

  ADD_KVX_BUILTIN (FFDMSW, "ffdmsw", FLOAT32, V2SF, V2SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFDMSWP, "ffdmswp", V2SF, V4SF, V4SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFDMSWQ, "ffdmswq", V4SF, V8SF, V8SF, FLOATINGS); // Vector

  ADD_KVX_BUILTIN (FFDMDAW, "ffdmdaw", FLOAT32, V2SF, V2SF, FLOAT32, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFDMDAWP, "ffdmdawp", V2SF, V4SF, V4SF, V2SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFDMDAWQ, "ffdmdawq", V4SF, V8SF, V8SF, V4SF, FLOATINGS); // Vector

  ADD_KVX_BUILTIN (FFDMSAW, "ffdmsaw", FLOAT32, V2SF, V2SF, FLOAT32, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFDMSAWP, "ffdmsawp", V2SF, V4SF, V4SF, V2SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFDMSAWQ, "ffdmsawq", V4SF, V8SF, V8SF, V4SF, FLOATINGS); // Vector

  ADD_KVX_BUILTIN (FFDMDSW, "ffdmdsw", FLOAT32, V2SF, V2SF, FLOAT32, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFDMDSWP, "ffdmdswp", V2SF, V4SF, V4SF, V2SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFDMDSWQ, "ffdmdswq", V4SF, V8SF, V8SF, V4SF, FLOATINGS); // Vector

  ADD_KVX_BUILTIN (FFDMASW, "ffdmasw", FLOAT32, V2SF, V2SF, FLOAT32, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFDMASWP, "ffdmaswp", V2SF, V4SF, V4SF, V2SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FFDMASWQ, "ffdmaswq", V4SF, V8SF, V8SF, V4SF, FLOATINGS); // Vector

  ADD_KVX_BUILTIN (FLOATW, "floatw", FLOAT32, INT32, UINT8, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FLOATWP, "floatwp", V2SF, V2SI, UINT8, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FLOATWQ, "floatwq", V4SF, V4SI, UINT8, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FLOATWO, "floatwo", V8SF, V8SI, UINT8, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FLOATD, "floatd", FLOAT64, INT64, UINT8, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FLOATDP, "floatdp", V2DF, V2DI, UINT8, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FLOATDQ, "floatdq", V4DF, V4DI, UINT8, FLOATINGS); // Vector

  ADD_KVX_BUILTIN (FLOATUW, "floatuw", FLOAT32, INT32, UINT8, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FLOATUWP, "floatuwp", V2SF, V2SI, UINT8, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FLOATUWQ, "floatuwq", V4SF, V4SI, UINT8, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FLOATUWO, "floatuwo", V8SF, V8SI, UINT8, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FLOATUD, "floatud", FLOAT64, INT64, UINT8, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FLOATUDP, "floatudp", V2DF, V2DI, UINT8, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FLOATUDQ, "floatudq", V4DF, V4DI, UINT8, FLOATINGS); // Vector

  ADD_KVX_BUILTIN (FIXEDW, "fixedw", INT32, FLOAT32, UINT8, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FIXEDWP, "fixedwp", V2SI, V2SF, UINT8, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FIXEDWQ, "fixedwq", V4SI, V4SF, UINT8, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FIXEDWO, "fixedwo", V8SI, V8SF, UINT8, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FIXEDD, "fixedd", INT64, FLOAT64, UINT8, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FIXEDDP, "fixeddp", V2DI, V2DF, UINT8, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FIXEDDQ, "fixeddq", V4DI, V4DF, UINT8, FLOATINGS); // Vector

  ADD_KVX_BUILTIN (FIXEDUW, "fixeduw", INT32, FLOAT32, UINT8, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FIXEDUWP, "fixeduwp", V2SI, V2SF, UINT8, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FIXEDUWQ, "fixeduwq", V4SI, V4SF, UINT8, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FIXEDUWO, "fixeduwo", V8SI, V8SF, UINT8, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FIXEDUD, "fixedud", INT64, FLOAT64, UINT8, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FIXEDUDP, "fixedudp", V2DI, V2DF, UINT8, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FIXEDUDQ, "fixedudq", V4DI, V4DF, UINT8, FLOATINGS); // Vector

  ADD_KVX_BUILTIN (FWIDENHW, "fwidenhw", FLOAT32, FLOAT16, SILENT); // Scalar
  ADD_KVX_BUILTIN (FWIDENHWQ, "fwidenhwq", V4SF, V4HF, SILENT); // Vector
  ADD_KVX_BUILTIN (FWIDENHWO, "fwidenhwo", V8SF, V8HF, SILENT); // Vector
  ADD_KVX_BUILTIN (FWIDENWD, "fwidenwd", FLOAT64, FLOAT32, SILENT); // Scalar
  ADD_KVX_BUILTIN (FWIDENWDP, "fwidenwdp", V2DF, V2SF, SILENT); // Vector
  ADD_KVX_BUILTIN (FWIDENWDQ, "fwidenwdq", V4DF, V4SF, SILENT); // Vector

  ADD_KVX_BUILTIN (FNARROWWH, "fnarrowwh", FLOAT16, FLOAT32, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FNARROWWHQ, "fnarrowwhq", V4HF, V4SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FNARROWWHO, "fnarrowwho", V8HF, V8SF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FNARROWDW, "fnarrowdw", FLOAT32, FLOAT64, FLOATINGS); // Scalar
  ADD_KVX_BUILTIN (FNARROWDWP, "fnarrowdwp", V2SF, V2DF, FLOATINGS); // Vector
  ADD_KVX_BUILTIN (FNARROWDWQ, "fnarrowdwq", V4SF, V4DF, FLOATINGS); // Vector

  ADD_KVX_BUILTIN (FCONJWC, "fconjwc", V2SF, V2SF); // Vector
  ADD_KVX_BUILTIN (FCONJWCP, "fconjwcp", V4SF, V4SF); // Vector
  ADD_KVX_BUILTIN (FCONJWCQ, "fconjwcq", V8SF, V8SF); // Vector
  ADD_KVX_BUILTIN (FCONJDC, "fconjdc", V2DF, V2DF); // Vector
  ADD_KVX_BUILTIN (FCONJDCP, "fconjdcp", V4DF, V4DF); // Vector

  ADD_KVX_BUILTIN (FCDIVW, "fcdivw", FLOAT32, FLOAT32, FLOAT32, SILENT); // Scalar
  ADD_KVX_BUILTIN (FCDIVWP, "fcdivwp", V2SF, V2SF, V2SF, SILENT); // Vector
  ADD_KVX_BUILTIN (FCDIVWQ, "fcdivwq", V4SF, V4SF, V4SF, SILENT); // Vector
  ADD_KVX_BUILTIN (FCDIVWO, "fcdivwo", V8SF, V8SF, V8SF, SILENT); // Vector
  ADD_KVX_BUILTIN (FCDIVD, "fcdivd", FLOAT64, FLOAT64, FLOAT64, SILENT); // Scalar
  ADD_KVX_BUILTIN (FCDIVDP, "fcdivdp", V2DF, V2DF, V2DF, SILENT); // Vector
  ADD_KVX_BUILTIN (FCDIVDQ, "fcdivdq", V4DF, V4DF, V4DF, SILENT); // Vector

  ADD_KVX_BUILTIN (FSDIVW, "fsdivw", FLOAT32, FLOAT32, FLOAT32, SILENT); // Scalar
  ADD_KVX_BUILTIN (FSDIVWP, "fsdivwp", V2SF, V2SF, V2SF, SILENT); // Vector
  ADD_KVX_BUILTIN (FSDIVWQ, "fsdivwq", V4SF, V4SF, V4SF, SILENT); // Vector
  ADD_KVX_BUILTIN (FSDIVWO, "fsdivwo", V8SF, V8SF, V8SF, SILENT); // Vector
  ADD_KVX_BUILTIN (FSDIVD, "fsdivd", FLOAT64, FLOAT64, FLOAT64, SILENT); // Scalar
  ADD_KVX_BUILTIN (FSDIVDP, "fsdivdp", V2DF, V2DF, V2DF, SILENT); // Vector
  ADD_KVX_BUILTIN (FSDIVDQ, "fsdivdq", V4DF, V4DF, V4DF, SILENT); // Vector

  ADD_KVX_BUILTIN (FSRECW, "fsrecw", FLOAT32, FLOAT32, SILENT); // Scalar
  ADD_KVX_BUILTIN (FSRECWP, "fsrecwp", V2SF, V2SF, SILENT); // Vector
  ADD_KVX_BUILTIN (FSRECWQ, "fsrecwq", V4SF, V4SF, SILENT); // Vector
  ADD_KVX_BUILTIN (FSRECWO, "fsrecwo", V8SF, V8SF, SILENT); // Vector
  ADD_KVX_BUILTIN (FSRECD, "fsrecd", FLOAT64, FLOAT64, SILENT); // Scalar
  ADD_KVX_BUILTIN (FSRECDP, "fsrecdp", V2DF, V2DF, SILENT); // Vector
  ADD_KVX_BUILTIN (FSRECDQ, "fsrecdq", V4DF, V4DF, SILENT); // Vector

  ADD_KVX_BUILTIN (FSRSRW, "fsrsrw", FLOAT32, FLOAT32, SILENT); // Scalar
  ADD_KVX_BUILTIN (FSRSRWP, "fsrsrwp", V2SF, V2SF, SILENT); // Vector
  ADD_KVX_BUILTIN (FSRSRWQ, "fsrsrwq", V4SF, V4SF, SILENT); // Vector
  ADD_KVX_BUILTIN (FSRSRWO, "fsrsrwo", V8SF, V8SF, SILENT); // Vector
  ADD_KVX_BUILTIN (FSRSRD, "fsrsrd", FLOAT64, FLOAT64, SILENT); // Scalar
  ADD_KVX_BUILTIN (FSRSRDP, "fsrsrdp", V2DF, V2DF, SILENT); // Vector
  ADD_KVX_BUILTIN (FSRSRDQ, "fsrsrdq", V4DF, V4DF, SILENT); // Vector

  ADD_KVX_BUILTIN (GET, "get", UINT64, INT32); // Control
  ADD_KVX_BUILTIN (WFXL, "wfxl", VOID, UINT8, UINT64); // Control
  ADD_KVX_BUILTIN (WFXM, "wfxm", VOID, UINT8, UINT64); // Control
  ADD_KVX_BUILTIN (IINVAL, "iinval", VOID); // Memory
  ADD_KVX_BUILTIN (IINVALS, "iinvals", VOID, CVPTR); // Memory
  ADD_KVX_BUILTIN (LBSU, "lbsu", INT8, CVPTR); // Deprecated
  ADD_KVX_BUILTIN (LBZU, "lbzu", UINT8, CVPTR); // Deprecated
  ADD_KVX_BUILTIN (LHSU, "lhsu", INT16, CVPTR); // Deprecated
  ADD_KVX_BUILTIN (LHZU, "lhzu", UINT16, CVPTR); // Deprecated
  ADD_KVX_BUILTIN (LDU, "ldu", UINT64, CVPTR); // Deprecated
  ADD_KVX_BUILTIN (LWZU, "lwzu", UINT32, CVPTR); // Deprecated
  ADD_KVX_BUILTIN (SET, "set", VOID, INT32, UINT64); // Control
  ADD_KVX_BUILTIN (SLEEP, "sleep", VOID); // Control
  ADD_KVX_BUILTIN (STOP, "stop", VOID); // Control
  ADD_KVX_BUILTIN (SYNCGROUP, "syncgroup", VOID, UINT64); // Control
  ADD_KVX_BUILTIN (TLBDINVAL, "tlbdinval", VOID); // Memory
  ADD_KVX_BUILTIN (TLBIINVAL, "tlbiinval", VOID); // Memory
  ADD_KVX_BUILTIN (TLBPROBE, "tlbprobe", VOID); // Memory
  ADD_KVX_BUILTIN (TLBREAD, "tlbread", VOID); // Memory
  ADD_KVX_BUILTIN (TLBWRITE, "tlbwrite", VOID); // Memory
  ADD_KVX_BUILTIN (WAITIT, "waitit", UINT32, UINT32); // Control

  ADD_KVX_BUILTIN (SATD, "satd", INT64, INT64, UINT8); // Deprecated
  ADD_KVX_BUILTIN (SATUD, "satud", UINT64, INT64, UINT8); // Deprecated
  ADD_KVX_BUILTIN (STSUW, "stsuw", UINT32, UINT32, UINT32); // Scalar
  ADD_KVX_BUILTIN (STSUD, "stsud", UINT64, UINT64, UINT64); // Scalar
  ADD_KVX_BUILTIN (STSUDP, "stsudp", V2DI, V2DI, V2DI); // Scalar
  ADD_KVX_BUILTIN (SBMM8, "sbmm8", UINT64, UINT64, UINT64); // Scalar
  ADD_KVX_BUILTIN (SBMMT8, "sbmmt8", UINT64, UINT64, UINT64); // Scalar

  ADD_KVX_BUILTIN (LBZ, "lbz", INT64, CVPTR, VARIANT, BOOL); // Scalar
  ADD_KVX_BUILTIN (LBS, "lbs", INT64, CVPTR, VARIANT, BOOL); // Scalar
  ADD_KVX_BUILTIN (LHZ, "lhz", INT64, CVPTR, VARIANT, BOOL); // Scalar
  ADD_KVX_BUILTIN (LHS, "lhs", INT64, CVPTR, VARIANT, BOOL); // Scalar
  ADD_KVX_BUILTIN (LWZ, "lwz", INT64, CVPTR, VARIANT, BOOL); // Scalar
  ADD_KVX_BUILTIN (LWS, "lws", INT64, CVPTR, VARIANT, BOOL); // Scalar
  ADD_KVX_BUILTIN (LD, "ld", INT64, CVPTR, VARIANT, BOOL); // Scalar
  ADD_KVX_BUILTIN (LQ, "lq", INT128, CVPTR, VARIANT, BOOL); // Scalar
  ADD_KVX_BUILTIN (LHF, "lhf", FLOAT16, CVPTR, VARIANT, BOOL); // Scalar
  ADD_KVX_BUILTIN (LWF, "lwf", FLOAT32, CVPTR, VARIANT, BOOL); // Scalar
  ADD_KVX_BUILTIN (LDF, "ldf", FLOAT64, CVPTR, VARIANT, BOOL); // Scalar

  ADD_KVX_BUILTIN (LBO, "lbo", V8QI, CVPTR, VARIANT, BOOL); // Deprecated
  ADD_KVX_BUILTIN (LBX, "lbx", V16QI, CVPTR, VARIANT, BOOL); // Deprecated
  ADD_KVX_BUILTIN (LBV, "lbv", V32QI, CVPTR, VARIANT, BOOL); // Deprecated
  ADD_KVX_BUILTIN (LHQ, "lhq", V4HI, CVPTR, VARIANT, BOOL); // Deprecated
  ADD_KVX_BUILTIN (LHO, "lho", V8HI, CVPTR, VARIANT, BOOL); // Deprecated
  ADD_KVX_BUILTIN (LHX, "lhx", V16HI, CVPTR, VARIANT, BOOL); // Deprecated
  ADD_KVX_BUILTIN (LWP, "lwp", V2SI, CVPTR, VARIANT, BOOL); // Deprecated
  ADD_KVX_BUILTIN (LWQ, "lwq", V4SI, CVPTR, VARIANT, BOOL); // Deprecated
  ADD_KVX_BUILTIN (LWO, "lwo", V8SI, CVPTR, VARIANT, BOOL); // Deprecated
  ADD_KVX_BUILTIN (LDP, "ldp", V2DI, CVPTR, VARIANT, BOOL); // Deprecated
  ADD_KVX_BUILTIN (LDQ, "ldq", V4DI, CVPTR, VARIANT, BOOL); // Deprecated

  ADD_KVX_BUILTIN (SBO, "sbo", VOID, VPTR, V8QI, BOOL); // Deprecated
  ADD_KVX_BUILTIN (SBX, "sbx", VOID, VPTR, V16QI, BOOL); // Deprecated
  ADD_KVX_BUILTIN (SBV, "sbv", VOID, VPTR, V32QI, BOOL); // Deprecated
  ADD_KVX_BUILTIN (SHQ, "shq", VOID, VPTR, V4HI, BOOL); // Deprecated
  ADD_KVX_BUILTIN (SHX, "shx", VOID, VPTR, V16HI, BOOL); // Deprecated
  ADD_KVX_BUILTIN (SHO, "sho", VOID, VPTR, V8HI, BOOL); // Deprecated
  ADD_KVX_BUILTIN (SWP, "swp", VOID, VPTR, V2SI, BOOL); // Deprecated
  ADD_KVX_BUILTIN (SWQ, "swq", VOID, VPTR, V4SI, BOOL); // Deprecated
  ADD_KVX_BUILTIN (SWO, "swo", VOID, VPTR, V8SI, BOOL); // Deprecated
  ADD_KVX_BUILTIN (SDP, "sdp", VOID, VPTR, V2DI, BOOL); // Deprecated
  ADD_KVX_BUILTIN (SDQ, "sdq", VOID, VPTR, V4DI, BOOL); // Deprecated

  ADD_KVX_BUILTIN (LOADBZ, "loadbz", UINT64, CVPTR, VARIANT); // Scalar
  ADD_KVX_BUILTIN (LOADHZ, "loadhz", UINT64, CVPTR, VARIANT); // Scalar
  ADD_KVX_BUILTIN (LOADWZ, "loadwz", UINT64, CVPTR, VARIANT); // Scalar
  ADD_KVX_BUILTIN (LOADD, "loadd", UINT64, CVPTR, VARIANT); // Scalar
  ADD_KVX_BUILTIN (LOADQ, "loadq", UINT128, CVPTR, VARIANT); // Scalar
  ADD_KVX_BUILTIN (LOAD64, "load64", V8QI, CVPTR, VARIANT); // Vector
  ADD_KVX_BUILTIN (LOAD128, "load128", V16QI, CVPTR, VARIANT); // Vector
  ADD_KVX_BUILTIN (LOAD256, "load256", V32QI, CVPTR, VARIANT); // Vector
  ADD_KVX_BUILTIN (XLOAD256, "xload256", X256, CVPTR, VARIANT); // Coprocessor

  ADD_KVX_BUILTIN (LOADCBZ, "loadcbz", UINT64, CVPTR, UINT64, UINT64, LOADCOND); // Scalar
  ADD_KVX_BUILTIN (LOADCHZ, "loadchz", UINT64, CVPTR, UINT64, UINT64, LOADCOND); // Scalar
  ADD_KVX_BUILTIN (LOADCWZ, "loadcwz", UINT64, CVPTR, UINT64, UINT64, LOADCOND); // Scalar
  ADD_KVX_BUILTIN (LOADCD, "loadcd", UINT64, CVPTR, UINT64, UINT64, LOADCOND); // Scalar
  ADD_KVX_BUILTIN (LOADCQ, "loadcq", UINT128, CVPTR, UINT128, UINT64, LOADCOND); // Scalar
  ADD_KVX_BUILTIN (LOADC64, "loadc64", V8QI, CVPTR, V8QI, UINT64, LOADCOND); // Vector
  ADD_KVX_BUILTIN (LOADC128, "loadc128", V16QI, CVPTR, V16QI, UINT64, LOADCOND); // Vector
  ADD_KVX_BUILTIN (LOADC256, "loadc256", V32QI, CVPTR, V32QI, UINT64, LOADCOND); // Vector
  ADD_KVX_BUILTIN (XLOADC256, "xloadc256", X256, CVPTR, X256, UINT64, LOADCOND); // Coprocessor

  ADD_KVX_BUILTIN (STOREB, "storeb", VOID, UINT64, VPTR, VOLATILE); // Scalar
  ADD_KVX_BUILTIN (STOREH, "storeh", VOID, UINT64, VPTR, VOLATILE); // Scalar
  ADD_KVX_BUILTIN (STOREW, "storew", VOID, UINT64, VPTR, VOLATILE); // Scalar
  ADD_KVX_BUILTIN (STORED, "stored", VOID, UINT64, VPTR, VOLATILE); // Scalar
  ADD_KVX_BUILTIN (STOREQ, "storeq", VOID, UINT128, VPTR, VOLATILE); // Scalar
  ADD_KVX_BUILTIN (STORE64, "store64", VOID, V8QI, VPTR, VOLATILE); // Vector
  ADD_KVX_BUILTIN (STORE128, "store128", VOID, V16QI, VPTR, VOLATILE); // Vector
  ADD_KVX_BUILTIN (STORE256, "store256", VOID, V32QI, VPTR, VOLATILE); // Vector
  ADD_KVX_BUILTIN (XSTORE256, "xstore256", VOID, X256, VPTR, VOLATILE); // Coprocessor

  ADD_KVX_BUILTIN (STORECB, "storecb", VOID, UINT64, VPTR, UINT64, STORECOND); // Scalar
  ADD_KVX_BUILTIN (STORECH, "storech", VOID, UINT64, VPTR, UINT64, STORECOND); // Scalar
  ADD_KVX_BUILTIN (STORECW, "storecw", VOID, UINT64, VPTR, UINT64, STORECOND); // Scalar
  ADD_KVX_BUILTIN (STORECD, "storecd", VOID, UINT64, VPTR, UINT64, STORECOND); // Scalar
  ADD_KVX_BUILTIN (STORECQ, "storecq", VOID, UINT128, VPTR, UINT64, STORECOND); // Scalar
  ADD_KVX_BUILTIN (STOREC64, "storec64", VOID, V8QI, VPTR, UINT64, STORECOND); // Vector
  ADD_KVX_BUILTIN (STOREC128, "storec128", VOID, V16QI, VPTR, UINT64, STORECOND); // Vector
  ADD_KVX_BUILTIN (STOREC256, "storec256", VOID, V32QI, VPTR, UINT64, STORECOND); // Vector
  ADD_KVX_BUILTIN (XSTOREC256, "xstorec256", VOID, X256, VPTR, UINT64, STORECOND); // Coprocessor

  ADD_KVX_BUILTIN (XLOAD256Q0, "xload256q0", X1024, CVPTR, X1024, VARIANT); // Coprocessor
  ADD_KVX_BUILTIN (XLOAD256Q1, "xload256q1", X1024, CVPTR, X1024, VARIANT); // Coprocessor
  ADD_KVX_BUILTIN (XLOAD256Q2, "xload256q2", X1024, CVPTR, X1024, VARIANT); // Coprocessor
  ADD_KVX_BUILTIN (XLOAD256Q3, "xload256q3", X1024, CVPTR, X1024, VARIANT); // Coprocessor

  ADD_KVX_BUILTIN (XLOADC256Q0, "xloadc256q0", X1024, CVPTR, X1024, UINT64, LOADCOND); // Coprocessor
  ADD_KVX_BUILTIN (XLOADC256Q1, "xloadc256q1", X1024, CVPTR, X1024, UINT64, LOADCOND); // Coprocessor
  ADD_KVX_BUILTIN (XLOADC256Q2, "xloadc256q2", X1024, CVPTR, X1024, UINT64, LOADCOND); // Coprocessor
  ADD_KVX_BUILTIN (XLOADC256Q3, "xloadc256q3", X1024, CVPTR, X1024, UINT64, LOADCOND); // Coprocessor

  ADD_KVX_BUILTIN (XSWAP256, "xswap256", V32QI, _X256, V32QI); // Coprocessor
  ADD_KVX_BUILTIN (XMT44D, "xmt44d", X1024, X1024); // Coprocessor

  ADD_KVX_BUILTIN (XMMA484BW, "xmma484bw", X512, X256, X256, X512, XMATMUL); // Coprocessor

}

tree
kvx_builtin_decl (unsigned code, bool initialize_p ATTRIBUTE_UNUSED)
{
  if (code >= ARRAY_SIZE (builtin_fndecls))
    return error_mark_node;
  return builtin_fndecls[code];
}

static inline const char *
tree_string_constant (tree arg)
{
  tree offset_tree = 0;
  arg = string_constant (arg, &offset_tree, 0, 0);
  return arg ? TREE_STRING_POINTER (arg) : "";
}

static rtx
build_carry_arg (tree arg, const char *name)
{
  const char *modifier = tree_string_constant (arg);
  static const char *table[] = {
    "",  ".i",
  };
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_average_arg (tree arg, const char *name)
{
  const char *modifier = tree_string_constant (arg);
  static const char *table[] = {
    "", ".r",  ".u", ".ru",
  };
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_saturate_arg (tree arg, const char *name)
{
  const char *modifier = tree_string_constant (arg);
  static const char *table[] = {
    "", ".s",  ".us",
  };
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_signedsat_arg (tree arg, const char *name)
{
  const char *modifier = tree_string_constant (arg);
  static const char *table[] = {
    "", ".s",
  };
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_extendmul_arg (tree arg, const char *name)
{
  const char *modifier = tree_string_constant (arg);
  static const char *table[] = {
    "", ".u",  ".su",
  };
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_widenint_arg (tree arg, const char *name)
{
  const char *modifier = tree_string_constant (arg);
  static const char *table[] = {
    "", ".z", ".q",
  };
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_narrowint_arg (tree arg, const char *name)
{
  const char *modifier = tree_string_constant (arg);
  static const char *table[] = {
    "", ".q", ".s",  ".us",
  };
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_shiftleft_arg (tree arg, const char *name)
{
  const char *modifier = tree_string_constant (arg);
  static const char *table[] = {
    "", ".s",  ".us", ".r",
  };
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_shiftright_arg (tree arg, const char *name)
{
  const char *modifier = tree_string_constant (arg);
  static const char *table[] = {
    "", ".a",  ".as", ".r",
  };
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_counting_arg (tree arg, const char *name)
{
  const char *modifier = tree_string_constant (arg);
  static const char *table[] = {
    "", ".lz",  ".ls", ".tz",
  };
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_simdcond_arg (tree arg, const char *name, machine_mode imode)
{
  const char *modifier = tree_string_constant (arg);
  static const char *table[] = {
    ".nez", ".eqz", ".ltz", ".gez", ".lez", ".gtz", ".odd", ".even",
  };
  static const char *table2[] = {
    ".dnez", ".deqz", ".dltz", ".dgez", ".dlez", ".dgtz", ".odd", ".even",
  };
  // In case of empty string, assume .nez
  if (!modifier[0])
    modifier = ".nez";
  for (int i = 0; i < (int)(sizeof(table)/sizeof(*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return imode == DImode?
	  gen_rtx_CONST_STRING (VOIDmode, table2[i]):
	  gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_floatings_arg (tree arg, const char *name)
{
  const char *modifier = tree_string_constant (arg);
  static const char *table[] = {
    "", ".rn", ".ru", ".rd", ".rz",
    ".s", ".rn.s", ".ru.s", ".rd.s", ".rz.s",
  };
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_conjugate_arg (tree arg, const char *name)
{
  const char *modifier = tree_string_constant (arg);
  static const char *table[] = {
    "", ".rn", ".ru", ".rd", ".rz",
    ".s", ".rn.s", ".ru.s", ".rd.s", ".rz.s",
    ".c", ".c.rn", ".c.ru", ".c.rd", ".c.rz",
    ".c.s", ".c.rn.s", ".c.ru.s", ".c.rd.s", ".c.rz.s",
  };
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_transpose_arg (tree arg, const char *name)
{
  const char *modifier = tree_string_constant (arg);
  static const char *table[] = {
    "", ".rn", ".ru", ".rd", ".rz",
    ".s", ".rn.s", ".ru.s", ".rd.s", ".rz.s",
    ".tn", ".tn.rn", ".tn.ru", ".tn.rd", ".tn.rz",
    ".tn.s", ".tn.rn.s", ".tn.ru.s", ".tn.rd.s", ".tn.rz.s",
    ".nt", ".nt.rn", ".nt.ru", ".nt.rd", ".nt.rz",
    ".nt.s", ".nt.rn.s", ".nt.ru.s", ".nt.rd.s", ".nt.rz.s",
    ".tt", ".tt.rn", ".tt.ru", ".tt.rd", ".tt.rz",
    ".tt.s", ".tt.rn.s", ".tt.ru.s", ".tt.rd.s", ".tt.rz.s",
  };
  // Skip the leading ".nn" if any, it is the default.
  if (!strncmp(modifier, ".nn", 3))
    modifier += 3;
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_silent_arg (tree arg, const char *name)
{
  const char *modifier = tree_string_constant (arg);
  static const char *table[] = {
    "", ".s",
  };
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_variant_arg (tree arg, const char *name, int *volatile_p)
{
  const char *modifier = tree_string_constant (arg);
  *volatile_p = 0;
  if (*modifier && modifier[1] == 'v')
    {
      *volatile_p = 1;
      modifier += 2;
    }
  // If kv3-1 coprocessor builtin, modifier must include ".u" or ".us".
  if (KV3_1 && *name == 'x')
    if (modifier[0] == 0 || (modifier[0] == '.' && modifier[1] != 'u'))
      error ("__builtin_kvx_%s requires '.u' or '.us' in modifier.", name);
  static const char *table[] = {
    "", ".s", ".u", ".us",
  };
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_volatile_arg (tree arg, const char *name, int *volatile_p)
{
  const char *modifier = tree_string_constant (arg);
  *volatile_p = 0;
  if (*modifier && modifier[1] == 'v')
    {
      *volatile_p = 1;
      modifier += 2;
    }
  if (!*modifier)
    return 0;
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_loadcond_arg (tree arg, const char *name, int *volatile_p)
{
  const char *modifier = tree_string_constant (arg);
  *volatile_p = 0;
  if (*modifier && modifier[1] == 'v')
    {
      *volatile_p = 1;
      modifier += 2;
    }
  // If kv3-1 coprocessor builtin, modifier must include ".u" or ".us".
  if (KV3_1 && *name == 'x')
    if (modifier[0] == 0 || (modifier[0] == '.' && modifier[1] != 'u'))
      error ("__builtin_kvx_%s requires '.u' or '.us' in modifier.", name);
  static const char *table[] = {
    ".dnez", ".deqz", ".dltz", ".dgez", ".dlez", ".dgtz", ".odd",
    ".even", ".wnez", ".weqz", ".wltz", ".wgez", ".wlez", ".wgtz",
    ".s.dnez", ".s.deqz", ".s.dltz", ".s.dgez", ".s.dlez", ".s.dgtz", ".s.odd",
    ".s.even", ".s.wnez", ".s.weqz", ".s.wltz", ".s.wgez", ".s.wlez", ".s.wgtz",
    ".u.dnez", ".u.deqz", ".u.dltz", ".u.dgez", ".u.dlez", ".u.dgtz", ".u.odd",
    ".u.even", ".u.wnez", ".u.weqz", ".u.wltz", ".u.wgez", ".u.wlez", ".u.wgtz",
    ".us.dnez", ".us.deqz", ".us.dltz", ".us.dgez", ".us.dlez", ".us.dgtz", ".us.odd",
    ".us.even", ".us.wnez", ".us.weqz", ".us.wltz", ".us.wgez", ".us.wlez", ".us.wgtz",
  };
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_storecond_arg (tree arg, const char *name, int *volatile_p)
{
  const char *modifier = tree_string_constant (arg);
  *volatile_p = 0;
  if (*modifier && modifier[1] == 'v')
    {
      *volatile_p = 1;
      modifier += 2;
    }
  static const char *table[] = {
    ".dnez", ".deqz", ".dltz", ".dgez", ".dlez", ".dgtz", ".odd",
    ".even", ".wnez", ".weqz", ".wltz", ".wgez", ".wlez", ".wgtz",
  };
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
build_xmatmul_arg (tree arg, const char *name)
{
  const char *modifier = tree_string_constant (arg);
  static const char *table[] = {
    "", ".u",  ".su", ".us",
  };
  for (int i = 0; i < (int) (sizeof (table) / sizeof (*table)); i++)
    {
      if (!strcmp (modifier, table[i]))
	return gen_rtx_CONST_STRING (VOIDmode, table[i]);
    }
  error ("__builtin_kvx_%s modifier %s not recognized.", name, modifier);
  return 0;
}

static rtx
verify_const_bool_arg (rtx arg, const char *name, const char *where)
{
  if (GET_CODE (arg) == CONST_INT && GET_MODE (arg) == VOIDmode)
    {
      unsigned long long tmp = INTVAL (arg);
      if (tmp == 0LL || tmp == 1LL)
	return arg;
    }
  error ("__builtin_kvx_%s expects a boolean immediate in %s argument.", name,
	 where);
  return 0;
}

static rtx
verify_const_int_arg (rtx arg, int bits, const char *name, const char *where)
{
  if (GET_CODE (arg) == CONST_INT && GET_MODE (arg) == VOIDmode)
    {
      unsigned shift = 64 - bits;
      long long tmp = INTVAL (arg);
      signed long long stmp = tmp;
      if (tmp == (stmp << shift) >> shift)
	return arg;
    }
  error ("__builtin_kvx_%s expects a %d-bit signed immediate in %s argument.",
	 name, bits, where);
  return 0;
}

static rtx
verify_const_uint_arg (rtx arg, int bits, const char *name, const char *where)
{
  if (GET_CODE (arg) == CONST_INT && GET_MODE (arg) == VOIDmode)
    {
      unsigned shift = 64 - bits;
      long long tmp = INTVAL (arg);
      unsigned long long utmp = tmp;
      if (tmp == (utmp << shift) >> shift)
	return arg;
    }
  error ("__builtin_kvx_%s expects a %d-bit unsigned immediate in %s argument.",
	 name, bits, where);
  return 0;
}

static rtx
verify_const_field_arg (rtx arg, int bits, const char *name, const char *where)
{
  if (GET_CODE (arg) == CONST_INT && GET_MODE (arg) == VOIDmode)
    {
      unsigned shift = 64 - bits;
      long long tmp = INTVAL (arg);
      signed long long stmp = tmp;
      unsigned long long utmp = tmp;
      if (tmp == (stmp << shift) >> shift)
	return arg;
      if (tmp == (utmp << shift) >> shift)
	return arg;
    }
  error ("__builtin_kvx_%s expects a %d-bit signed or unsigned immediate in %s "
	 "argument.",
	 name, bits, where);
  return 0;
}

static int
verify_sfr_regno(int regno, const char *name, const char *where) {
  int gcc_regno = KV3_SFR_FIRST_REGNO + regno;
  if(gcc_regno  > KV3_SFR_LAST_REGNO) {
    error ("__builtin_kvx_%s passed %d as %s argument: expects a SFR register index between 0 and %d.",
	   name, regno, where, KV3_SFR_LAST_REGNO - KV3_SFR_FIRST_REGNO);
  }

  return gcc_regno;
}

static rtx
kvx_expand_builtin_get (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  arg1 = verify_const_uint_arg (arg1, 9, "get", "first");
  int regno = verify_sfr_regno(INTVAL (arg1), "get", "first");
  rtx sys_reg = gen_rtx_REG (DImode, regno);

  if (!target)
    target = gen_reg_rtx (DImode);
  else
    target = force_reg (DImode, target);

  if (regno == KV3_PCR_REGNO)
    emit_move_insn (target, sys_reg);
  else
    emit_insn (gen_kvx_get (target, sys_reg));

  return target;
}

static rtx
kvx_expand_builtin_set (rtx target ATTRIBUTE_UNUSED, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));
  arg1 = verify_const_uint_arg (arg1, 9, "set", "first");
  arg2 = force_reg (DImode, arg2);
  int regno = verify_sfr_regno(INTVAL (arg1), "set", "first");
  rtx sys_reg = gen_rtx_REG (DImode, regno);

  emit_insn (gen_kvx_set (sys_reg, arg2));

  return NULL_RTX;
}

static rtx
kvx_expand_builtin_wfxl (rtx target ATTRIBUTE_UNUSED, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));
  arg1 = verify_const_uint_arg (arg1, 9, "wfxl", "first");
  arg2 = force_reg (DImode, arg2);
  int regno = verify_sfr_regno(INTVAL (arg1), "wfxl", "first");
  rtx sys_reg = gen_rtx_REG (DImode, regno);

  emit_insn (gen_kvx_wfxl (sys_reg, arg2));

  return NULL_RTX;
}

static rtx
kvx_expand_builtin_wfxm (rtx target ATTRIBUTE_UNUSED, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));
  arg1 = verify_const_uint_arg (arg1, 9, "wfxm", "first");
  arg2 = force_reg (DImode, arg2);
  int regno = verify_sfr_regno(INTVAL (arg1), "wfxm", "first");
  rtx sys_reg = gen_rtx_REG (DImode, regno);

  emit_insn (gen_kvx_wfxm (sys_reg, arg2));

  return NULL_RTX;
}

static rtx
kvx_expand_builtin_waitit (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  arg1 = force_reg (SImode, arg1);

  if (!target)
    target = gen_reg_rtx (SImode);
  else
    target = force_reg (SImode, target);

  emit_insn (gen_kvx_waitit (target, arg1));

  return target;
}

static rtx
kvx_expand_builtin_sbmm8 (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));
  arg1 = force_reg (DImode, arg1);
  arg2 = force_reg (DImode, arg2);

  if (!target)
    target = gen_reg_rtx (DImode);
  else
    target = force_reg (DImode, target);

  emit_insn (gen_kvx_sbmm8 (target, arg1, arg2));

  return target;
}

static rtx
kvx_expand_builtin_sbmmt8 (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));
  arg1 = force_reg (DImode, arg1);
  arg2 = force_reg (DImode, arg2);

  if (!target)
    target = gen_reg_rtx (DImode);
  else
    target = force_reg (DImode, target);

  emit_insn (gen_kvx_sbmmt8 (target, arg1, arg2));

  return target;
}

static rtx
kvx_expand_builtin_await (rtx target ATTRIBUTE_UNUSED,
			  tree args ATTRIBUTE_UNUSED)
{
  emit_insn (gen_kvx_await ());

  return NULL_RTX;
}

static rtx
kvx_expand_builtin_sleep (rtx target ATTRIBUTE_UNUSED,
			  tree args ATTRIBUTE_UNUSED)
{
  emit_insn (gen_kvx_sleep ());

  return NULL_RTX;
}

static rtx
kvx_expand_builtin_stop (rtx target ATTRIBUTE_UNUSED,
			 tree args ATTRIBUTE_UNUSED)
{
  emit_insn (gen_kvx_stop ());

  return NULL_RTX;
}

static rtx
kvx_expand_builtin_syncgroup (rtx target ATTRIBUTE_UNUSED, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  arg1 = force_reg (DImode, arg1);

  emit_insn (gen_kvx_syncgroup (arg1));

  return NULL_RTX;
}

static rtx
kvx_expand_builtin_barrier (void)
{
  emit_insn (gen_kvx_barrier ());

  return NULL_RTX;
}

static rtx
kvx_expand_builtin_dinval (void)
{
  emit_insn (gen_kvx_dinval ());

  return NULL_RTX;
}

static rtx
kvx_expand_builtin_iinval (void)
{
  emit_insn (gen_kvx_iinval ());

  return NULL_RTX;
}

static rtx
kvx_expand_builtin_tlbdinval (void)
{
  emit_insn (gen_kvx_tlbdinval ());

  return NULL_RTX;
}

static rtx
kvx_expand_builtin_tlbiinval (void)
{
  emit_insn (gen_kvx_tlbiinval ());

  return NULL_RTX;
}

static rtx
kvx_expand_builtin_tlbprobe (void)
{
  emit_insn (gen_kvx_tlbprobe ());

  return NULL_RTX;
}

static rtx
kvx_expand_builtin_tlbread (void)
{
  emit_insn (gen_kvx_tlbread ());

  return NULL_RTX;
}

static rtx
kvx_expand_builtin_tlbwrite (void)
{
  emit_insn (gen_kvx_tlbwrite ());

  return NULL_RTX;
}

static rtx
kvx_expand_builtin_satd (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));
  arg1 = force_reg (DImode, arg1);
  arg2 = force_reg (SImode, arg2);

  if (!target)
    target = gen_reg_rtx (DImode);
  else
    target = force_reg (DImode, target);

  emit_insn (gen_satd (target, arg1, arg2));
  return target;
}

static rtx
kvx_expand_builtin_satud (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));
  arg1 = force_reg (DImode, arg1);
  arg2 = force_reg (SImode, arg2);

  if (!target)
    target = gen_reg_rtx (DImode);
  else
    target = force_reg (DImode, target);

  emit_insn (gen_satud (target, arg1, arg2));
  return target;
}

static rtx
kvx_builtin_helper_memref_ptr (rtx ptr, enum machine_mode mode)
{
  ptr = force_reg (Pmode, ptr);
  rtx mem_target = gen_rtx_MEM (mode, ptr);

  return mem_target;
}

/*
 * unpack the rtx arg ARGNUM and create a (mem:MODE ) using
 * the unpacked rtx as base address
 */
#define MEMREF(argnum, mode, varname)                                          \
  rtx varname;                                                                 \
  {                                                                            \
    rtx _tmp = expand_normal (CALL_EXPR_ARG (args, argnum));                   \
    rtx _mem_target = kvx_builtin_helper_memref_ptr (_tmp, mode);              \
    varname = _mem_target;                                                     \
  }

#define GETREG(argnum, mode, varname)                                          \
  rtx varname = expand_normal (CALL_EXPR_ARG (args, argnum));                  \
  varname = force_reg (mode, varname);

static rtx
kvx_expand_builtin_aladd (rtx target, tree args, enum machine_mode mode)
{
  MEMREF (0, mode, mem_target);
  GETREG (1, mode, addend_and_return);

  if (!target)
    target = gen_reg_rtx (mode);
  else
    target = force_reg (mode, target);

  switch (mode)
    {
    case E_DImode:
      emit_insn (gen_aladdd (target, mem_target, addend_and_return));
      break;
    case E_SImode:
      emit_insn (gen_aladdw (target, mem_target, addend_and_return));
      break;
    default:
      gcc_unreachable ();
    }

  return target;
}

static rtx
kvx_expand_builtin_acswap (rtx target, tree args, enum machine_mode mode)
{
  rtx ptr = expand_normal (CALL_EXPR_ARG (args, 0));

  if (!REG_P (ptr))
    ptr = force_reg (Pmode, ptr);

  rtx mem_ref = gen_rtx_MEM (mode, ptr);

  rtx new_val = expand_normal (CALL_EXPR_ARG (args, 1));
  rtx expect_val = expand_normal (CALL_EXPR_ARG (args, 2));

  rtx tmp = gen_reg_rtx (TImode);

  if (!target)
    target = gen_reg_rtx (mode);
  else
    target = force_reg (mode, target);

  emit_move_insn (gen_rtx_SUBREG (mode, tmp, 0), new_val);
  emit_move_insn (gen_rtx_SUBREG (mode, tmp, 8), expect_val);

  switch (mode)
    {
    case E_DImode:
      emit_insn (gen_acswapd (tmp, mem_ref));
      break;
    case E_SImode:
      emit_insn (gen_acswapw (tmp, mem_ref));
      break;
    default:
      gcc_unreachable ();
    }

  rtx result = gen_lowpart_SUBREG (mode, tmp);
  emit_move_insn (target, result);

  return target;
}

static rtx
kvx_expand_builtin_fence (void)
{
  emit_insn (gen_kvx_fence ());

  return NULL_RTX;
}

static rtx
kvx_expand_builtin_dinvall (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  arg1 = force_reg (Pmode, arg1);

  emit_insn (gen_kvx_dinvall (arg1));

  return target;
}

static rtx
kvx_expand_builtin_iinvals (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  arg1 = force_reg (Pmode, arg1);

  emit_insn (gen_kvx_iinvals (arg1));

  return target;
}

static rtx
kvx_expand_builtin_dtouchl (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  arg1 = force_reg (Pmode, arg1);

  emit_insn (gen_kvx_dtouchl (arg1));

  return target;
}

static rtx
kvx_expand_builtin_dzerol (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  arg1 = force_reg (Pmode, arg1);

  emit_insn (gen_kvx_dzerol (arg1));

  return target;
}

static rtx
kvx_expand_builtin_alclr (rtx target, tree args, enum machine_mode mode)
{
  rtx ptr = expand_normal (CALL_EXPR_ARG (args, 0));

  if (!REG_P (ptr))
    ptr = force_reg (Pmode, ptr);

  rtx mem_ref = gen_rtx_MEM (mode, ptr);

  if (!target)
    target = gen_reg_rtx (mode);
  if (!REG_P (target) || GET_MODE (target) != mode)
    {
      target = force_reg (mode, target);
    }

  switch (mode)
    {
    case E_DImode:
      emit_insn (gen_alclrd (target, mem_ref));
      break;
    case E_SImode:
      emit_insn (gen_alclrw (target, mem_ref));
      break;
    default:
      gcc_unreachable ();
    }

  return target;
}

#define KVX_EXPAND_BUILTIN_2_STANDARD(name, name2, tmode, smode)               \
  static rtx kvx_expand_builtin_##name (rtx target, tree args)                 \
  {                                                                            \
    rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));                        \
    arg1 = force_reg (smode, arg1);                                            \
    if (!target)                                                               \
      target = gen_reg_rtx (tmode);                                            \
    else                                                                       \
      target = force_reg (tmode, target);                                      \
    emit_insn (gen_##name2 (target, arg1));                                    \
    return target;                                                             \
  }

#define KVX_EXPAND_BUILTIN_2_MODIFIERS(validate, name, name2, tmode, smode)    \
  static rtx kvx_expand_builtin_##name (rtx target, tree args)                 \
  {                                                                            \
    rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));                        \
    rtx arg2 = build_##validate##_arg (CALL_EXPR_ARG (args, 1), #name);        \
    arg1 = force_reg (smode, arg1);                                            \
    if (!target)                                                               \
      target = gen_reg_rtx (tmode);                                            \
    else                                                                       \
      target = force_reg (tmode, target);                                      \
    emit_insn (gen_##name2 (target, arg1, arg2));                              \
    return target;                                                             \
  }
#define KVX_EXPAND_BUILTIN_2_SATURATE(name, tmode, smode)                      \
  KVX_EXPAND_BUILTIN_2_MODIFIERS(saturate, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_2_SIGNEDSAT(name, tmode, smode)                     \
  KVX_EXPAND_BUILTIN_2_MODIFIERS(signedsat, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_2_WIDENINT(name, tmode, smode)                      \
  KVX_EXPAND_BUILTIN_2_MODIFIERS(widenint, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_2_NARROWINT(name, tmode, smode)                     \
  KVX_EXPAND_BUILTIN_2_MODIFIERS(narrowint, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_2_COUNTING(name, tmode, smode)                      \
  KVX_EXPAND_BUILTIN_2_MODIFIERS(counting, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_2_FLOATINGS(name, tmode, smode)                     \
  KVX_EXPAND_BUILTIN_2_MODIFIERS(floatings, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_2_SILENT(name, tmode, smode)                        \
  KVX_EXPAND_BUILTIN_2_MODIFIERS(silent, name, kvx_##name, tmode, smode)

#define KVX_EXPAND_BUILTIN_3_STANDARD(name, name2, tmode, smode)               \
  static rtx kvx_expand_builtin_##name (rtx target, tree args)                 \
  {                                                                            \
    rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));                        \
    rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));                        \
    arg1 = force_reg (smode, arg1);                                            \
    arg2 = force_reg (smode, arg2);                                            \
    if (!target)                                                               \
      target = gen_reg_rtx (tmode);                                            \
    else                                                                       \
      target = force_reg (tmode, target);                                      \
    emit_insn (gen_##name2 (target, arg1, arg2));                              \
    return target;                                                             \
  }

#define KVX_EXPAND_BUILTIN_3_MODIFIERS(validate, name, name2, tmode, smode)    \
  static rtx kvx_expand_builtin_##name (rtx target, tree args)                 \
  {                                                                            \
    rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));                        \
    rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));                        \
    rtx arg3 = build_##validate##_arg (CALL_EXPR_ARG (args, 2), #name);        \
    arg1 = force_reg (smode, arg1);                                            \
    arg2 = force_reg (smode, arg2);                                            \
    if (!target)                                                               \
      target = gen_reg_rtx (tmode);                                            \
    else                                                                       \
      target = force_reg (tmode, target);                                      \
    emit_insn (gen_##name2 (target, arg1, arg2, arg3));                        \
    return target;                                                             \
  }
#define KVX_EXPAND_BUILTIN_3_CARRY(name, tmode, smode)                         \
  KVX_EXPAND_BUILTIN_3_MODIFIERS(carry, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_3_AVERAGE(name, tmode, smode)                       \
  KVX_EXPAND_BUILTIN_3_MODIFIERS(average, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_3_SATURATE(name, tmode, smode)                      \
  KVX_EXPAND_BUILTIN_3_MODIFIERS(saturate, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_3_SIGNEDSAT(name, tmode, smode)                     \
  KVX_EXPAND_BUILTIN_3_MODIFIERS(signedsat, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_3_EXTENDMUL(name, tmode, smode)                     \
  KVX_EXPAND_BUILTIN_3_MODIFIERS(extendmul, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_3_FLOATINGS(name, tmode, smode)                     \
  KVX_EXPAND_BUILTIN_3_MODIFIERS(floatings, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_3_CONJUGATE(name, tmode, smode)                     \
  KVX_EXPAND_BUILTIN_3_MODIFIERS(conjugate, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_3_TRANSPOSE(name, tmode, smode)                     \
  KVX_EXPAND_BUILTIN_3_MODIFIERS(transpose, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_3_SILENT(name, tmode, smode)                        \
  KVX_EXPAND_BUILTIN_3_MODIFIERS(silent, name, kvx_##name, tmode, smode)

#define KVX_EXPAND_BUILTIN_3_MODIFIERS_S(validate, name, name2, vmode, smode)  \
  static rtx kvx_expand_builtin_##name (rtx target, tree args)                 \
  {                                                                            \
    rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));                        \
    rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));                        \
    rtx arg3 = build_##validate##_arg (CALL_EXPR_ARG (args, 2), #name);        \
    arg1 = force_reg (vmode, arg1);                                            \
    arg2 = force_not_mem (arg2);                                               \
    if (!target)                                                               \
      target = gen_reg_rtx (vmode);                                            \
    else                                                                       \
      target = force_reg (vmode, target);                                      \
    emit_insn (gen_##name2 (target, arg1, arg2, arg3));                        \
    return target;                                                             \
  }
#define KVX_EXPAND_BUILTIN_3_SATURATE_S(name, tmode, smode)                    \
  KVX_EXPAND_BUILTIN_3_MODIFIERS_S(saturate, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_3_SHIFTLEFT(name, tmode, smode)                     \
  KVX_EXPAND_BUILTIN_3_MODIFIERS_S(shiftleft, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_3_SHIFTRIGHT(name, tmode, smode)                    \
  KVX_EXPAND_BUILTIN_3_MODIFIERS_S(shiftright, name, kvx_##name, tmode, smode)

#define KVX_EXPAND_BUILTIN_4_STANDARD(name, name2, tmode, smode)               \
  static rtx kvx_expand_builtin_##name (rtx target, tree args)                 \
  {                                                                            \
    rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));                        \
    rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));                        \
    rtx arg3 = expand_normal (CALL_EXPR_ARG (args, 2));                        \
    arg1 = force_reg (smode, arg1);                                            \
    arg2 = force_reg (smode, arg2);                                            \
    arg3 = force_reg (tmode, arg3);                                            \
    if (!target)                                                               \
      target = gen_reg_rtx (tmode);                                            \
    else                                                                       \
      target = force_reg (tmode, target);                                      \
    emit_insn (gen_##name2 (target, arg1, arg2, arg3));                        \
    return target;                                                             \
  }

#define KVX_EXPAND_BUILTIN_4_MODIFIERS(validate, name, name2, tmode, smode)    \
  static rtx kvx_expand_builtin_##name (rtx target, tree args)                 \
  {                                                                            \
    rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));                        \
    rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));                        \
    rtx arg3 = expand_normal (CALL_EXPR_ARG (args, 2));                        \
    rtx arg4 = build_##validate##_arg (CALL_EXPR_ARG (args, 3), #name);        \
    arg1 = force_reg (smode, arg1);                                            \
    arg2 = force_reg (smode, arg2);                                            \
    arg3 = force_reg (tmode, arg3);                                            \
    if (!target)                                                               \
      target = gen_reg_rtx (tmode);                                            \
    else                                                                       \
      target = force_reg (tmode, target);                                      \
    emit_insn (gen_##name2 (target, arg1, arg2, arg3, arg4));                  \
    return target;                                                             \
  }
#define KVX_EXPAND_BUILTIN_4_EXTENDMUL(name, tmode, smode)                     \
  KVX_EXPAND_BUILTIN_4_MODIFIERS(extendmul, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_4_FLOATINGS(name, tmode, smode)                     \
  KVX_EXPAND_BUILTIN_4_MODIFIERS(floatings, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_4_CONJUGATE(name, tmode, smode)                     \
  KVX_EXPAND_BUILTIN_4_MODIFIERS(conjugate, name, kvx_##name, tmode, smode)
#define KVX_EXPAND_BUILTIN_4_TRANSPOSE(name, tmode, smode)                     \
  KVX_EXPAND_BUILTIN_4_MODIFIERS(transpose, name, kvx_##name, tmode, smode)

#define KVX_EXPAND_BUILTIN_SHIFT(name, tmode, smode)                           \
  static rtx kvx_expand_builtin_##name (rtx target, tree args)                 \
  {                                                                            \
    int bits = __builtin_ctz (GET_MODE_NUNITS (tmode));                        \
    rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));                        \
    rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));                        \
    rtx arg3 = expand_normal (CALL_EXPR_ARG (args, 2));                        \
    arg1 = force_reg (tmode, arg1);                                            \
    arg2 = verify_const_uint_arg (arg2, bits, #name, "second");                \
    if (arg3 != CONST0_RTX (smode))                                            \
      arg3 = simplify_gen_subreg (smode, arg3, GET_MODE (arg3), 0);            \
    if (!target)                                                               \
      target = gen_reg_rtx (tmode);                                            \
    else                                                                       \
      target = force_reg (tmode, target);                                      \
    emit_insn (gen_kvx_##name (target, arg1, arg2, arg3));                     \
    return target;                                                             \
  }

#define KVX_EXPAND_BUILTIN_SELECT(name, tmode, cmode)                          \
  static rtx kvx_expand_builtin_##name (rtx target, tree args)                 \
  {                                                                            \
    machine_mode imode = GET_MODE_INNER (cmode);                               \
    rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));                        \
    rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));                        \
    rtx arg3 = expand_normal (CALL_EXPR_ARG (args, 2));                        \
    rtx arg4 = build_simdcond_arg (CALL_EXPR_ARG (args, 3), #name, imode);     \
    arg1 = force_reg (tmode, arg1);                                            \
    arg2 = force_reg (tmode, arg2);                                            \
    arg3 = force_reg (cmode, arg3);                                            \
    if (!target)                                                               \
      target = gen_reg_rtx (tmode);                                            \
    else                                                                       \
      target = force_reg (tmode, target);                                      \
    emit_insn (gen_kvx_##name (target, arg1, arg2, arg3, arg4));               \
    return target;                                                             \
  }

#define KVX_EXPAND_BUILTIN_FCONVERT(name, tmode, smode)                        \
  static rtx kvx_expand_builtin_##name (rtx target, tree args)                 \
  {                                                                            \
    rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));                        \
    rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));                        \
    rtx arg3 = build_floatings_arg (CALL_EXPR_ARG (args, 2), #name);           \
    arg2 = verify_const_uint_arg (arg2, 6, #name, "second");                   \
    if (!target)                                                               \
      target = gen_reg_rtx (tmode);                                            \
    else                                                                       \
      target = force_reg (tmode, target);                                      \
    arg1 = force_reg (smode, arg1);                                            \
    emit_insn (gen_kvx_##name (target, arg1, arg2, arg3));                     \
    return target;                                                             \
  }

KVX_EXPAND_BUILTIN_3_CARRY (addcd, DImode, DImode)
KVX_EXPAND_BUILTIN_3_CARRY (sbfcd, DImode, DImode)

KVX_EXPAND_BUILTIN_3_SATURATE (addbo, V8QImode, V8QImode)
KVX_EXPAND_BUILTIN_3_SATURATE (addbx, V16QImode, V16QImode)
KVX_EXPAND_BUILTIN_3_SATURATE (addbv, V32QImode, V32QImode)
KVX_EXPAND_BUILTIN_3_SATURATE (addhq, V4HImode, V4HImode)
KVX_EXPAND_BUILTIN_3_SATURATE (addho, V8HImode, V8HImode)
KVX_EXPAND_BUILTIN_3_SATURATE (addhx, V16HImode, V16HImode)
KVX_EXPAND_BUILTIN_3_SATURATE (addw, SImode, SImode)
KVX_EXPAND_BUILTIN_3_SATURATE (addwp, V2SImode, V2SImode)
KVX_EXPAND_BUILTIN_3_SATURATE (addwq, V4SImode, V4SImode)
KVX_EXPAND_BUILTIN_3_SATURATE (addwo, V8SImode, V8SImode)
KVX_EXPAND_BUILTIN_3_SATURATE (addd, DImode, DImode)
KVX_EXPAND_BUILTIN_3_SATURATE (adddp, V2DImode, V2DImode)
KVX_EXPAND_BUILTIN_3_SATURATE (adddq, V4DImode, V4DImode)

KVX_EXPAND_BUILTIN_3_SATURATE (sbfbo, V8QImode, V8QImode)
KVX_EXPAND_BUILTIN_3_SATURATE (sbfbx, V16QImode, V16QImode)
KVX_EXPAND_BUILTIN_3_SATURATE (sbfbv, V32QImode, V32QImode)
KVX_EXPAND_BUILTIN_3_SATURATE (sbfhq, V4HImode, V4HImode)
KVX_EXPAND_BUILTIN_3_SATURATE (sbfho, V8HImode, V8HImode)
KVX_EXPAND_BUILTIN_3_SATURATE (sbfhx, V16HImode, V16HImode)
KVX_EXPAND_BUILTIN_3_SATURATE (sbfw, SImode, SImode)
KVX_EXPAND_BUILTIN_3_SATURATE (sbfwp, V2SImode, V2SImode)
KVX_EXPAND_BUILTIN_3_SATURATE (sbfwq, V4SImode, V4SImode)
KVX_EXPAND_BUILTIN_3_SATURATE (sbfwo, V8SImode, V8SImode)
KVX_EXPAND_BUILTIN_3_SATURATE (sbfd, DImode, DImode)
KVX_EXPAND_BUILTIN_3_SATURATE (sbfdp, V2DImode, V2DImode)
KVX_EXPAND_BUILTIN_3_SATURATE (sbfdq, V4DImode, V4DImode)

KVX_EXPAND_BUILTIN_2_SIGNEDSAT (negbo, V8QImode, V8QImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (negbx, V16QImode, V16QImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (negbv, V32QImode, V32QImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (neghq, V4HImode, V4HImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (negho, V8HImode, V8HImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (neghx, V16HImode, V16HImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (negw, SImode, SImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (negwp, V2SImode, V2SImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (negwq, V4SImode, V4SImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (negwo, V8SImode, V8SImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (negd, DImode, DImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (negdp, V2DImode, V2DImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (negdq, V4DImode, V4DImode)

KVX_EXPAND_BUILTIN_2_SIGNEDSAT (absbo, V8QImode, V8QImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (absbx, V16QImode, V16QImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (absbv, V32QImode, V32QImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (abshq, V4HImode, V4HImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (absho, V8HImode, V8HImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (abshx, V16HImode, V16HImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (absw, SImode, SImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (abswp, V2SImode, V2SImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (abswq, V4SImode, V4SImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (abswo, V8SImode, V8SImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (absd, DImode, DImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (absdp, V2DImode, V2DImode)
KVX_EXPAND_BUILTIN_2_SIGNEDSAT (absdq, V4DImode, V4DImode)

KVX_EXPAND_BUILTIN_3_SIGNEDSAT (abdbo, V8QImode, V8QImode)
KVX_EXPAND_BUILTIN_3_SIGNEDSAT (abdbx, V16QImode, V16QImode)
KVX_EXPAND_BUILTIN_3_SIGNEDSAT (abdbv, V32QImode, V32QImode)
KVX_EXPAND_BUILTIN_3_SIGNEDSAT (abdhq, V4HImode, V4HImode)
KVX_EXPAND_BUILTIN_3_SIGNEDSAT (abdho, V8HImode, V8HImode)
KVX_EXPAND_BUILTIN_3_SIGNEDSAT (abdhx, V16HImode, V16HImode)
KVX_EXPAND_BUILTIN_3_SIGNEDSAT (abdw, SImode, SImode)
KVX_EXPAND_BUILTIN_3_SIGNEDSAT (abdwp, V2SImode, V2SImode)
KVX_EXPAND_BUILTIN_3_SIGNEDSAT (abdwq, V4SImode, V4SImode)
KVX_EXPAND_BUILTIN_3_SIGNEDSAT (abdwo, V8SImode, V8SImode)
KVX_EXPAND_BUILTIN_3_SIGNEDSAT (abdd, DImode, DImode)
KVX_EXPAND_BUILTIN_3_SIGNEDSAT (abddp, V2DImode, V2DImode)
KVX_EXPAND_BUILTIN_3_SIGNEDSAT (abddq, V4DImode, V4DImode)

KVX_EXPAND_BUILTIN_3_AVERAGE (avgbo, V8QImode, V8QImode)
KVX_EXPAND_BUILTIN_3_AVERAGE (avgbx, V16QImode, V16QImode)
KVX_EXPAND_BUILTIN_3_AVERAGE (avgbv, V32QImode, V32QImode)
KVX_EXPAND_BUILTIN_3_AVERAGE (avghq, V4HImode, V4HImode)
KVX_EXPAND_BUILTIN_3_AVERAGE (avgho, V8HImode, V8HImode)
KVX_EXPAND_BUILTIN_3_AVERAGE (avghx, V16HImode, V16HImode)
KVX_EXPAND_BUILTIN_3_AVERAGE (avgw, SImode, SImode)
KVX_EXPAND_BUILTIN_3_AVERAGE (avgwp, V2SImode, V2SImode)
KVX_EXPAND_BUILTIN_3_AVERAGE (avgwq, V4SImode, V4SImode)
KVX_EXPAND_BUILTIN_3_AVERAGE (avgwo, V8SImode, V8SImode)

KVX_EXPAND_BUILTIN_3_EXTENDMUL (mulxhwq, V4SImode, V4HImode)
KVX_EXPAND_BUILTIN_3_EXTENDMUL (mulxhwo, V8SImode, V8HImode)
KVX_EXPAND_BUILTIN_3_EXTENDMUL (mulxwdp, V2DImode, V2SImode)
KVX_EXPAND_BUILTIN_3_EXTENDMUL (mulxwdq, V4DImode, V4SImode)

KVX_EXPAND_BUILTIN_4_EXTENDMUL (maddxhwq, V4SImode, V4HImode)
KVX_EXPAND_BUILTIN_4_EXTENDMUL (maddxhwo, V8SImode, V8HImode)
KVX_EXPAND_BUILTIN_4_EXTENDMUL (maddxwdp, V2DImode, V2SImode)
KVX_EXPAND_BUILTIN_4_EXTENDMUL (maddxwdq, V4DImode, V4SImode)

KVX_EXPAND_BUILTIN_4_EXTENDMUL (msbfxhwq, V4SImode, V4HImode)
KVX_EXPAND_BUILTIN_4_EXTENDMUL (msbfxhwo, V8SImode, V8HImode)
KVX_EXPAND_BUILTIN_4_EXTENDMUL (msbfxwdp, V2DImode, V2SImode)
KVX_EXPAND_BUILTIN_4_EXTENDMUL (msbfxwdq, V4DImode, V4SImode)

KVX_EXPAND_BUILTIN_3_STANDARD (minbo, sminv8qi3, V8QImode, V8QImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minbx, sminv16qi3, V16QImode, V16QImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minbv, sminv32qi3, V32QImode, V32QImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minhq, sminv4hi3, V4HImode, V4HImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minho, sminv8hi3, V8HImode, V8HImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minhx, sminv16hi3, V16HImode, V16HImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minw, sminsi3, SImode, SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minwp, sminv2si3, V2SImode, V2SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minwq, sminv4si3, V4SImode, V4SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minwo, sminv8si3, V8SImode, V8SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (mind, smindi3, DImode, DImode)
KVX_EXPAND_BUILTIN_3_STANDARD (mindp, sminv2di3, V2DImode, V2DImode)
KVX_EXPAND_BUILTIN_3_STANDARD (mindq, sminv4di3, V4DImode, V4DImode)

KVX_EXPAND_BUILTIN_3_STANDARD (maxbo, smaxv8qi3, V8QImode, V8QImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxbx, smaxv16qi3, V16QImode, V16QImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxbv, smaxv32qi3, V32QImode, V32QImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxhq, smaxv4hi3, V4HImode, V4HImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxho, smaxv8hi3, V8HImode, V8HImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxhx, smaxv16hi3, V16HImode, V16HImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxw, smaxsi3, SImode, SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxwp, smaxv2si3, V2SImode, V2SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxwq, smaxv4si3, V4SImode, V4SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxwo, smaxv8si3, V8SImode, V8SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxd, smaxdi3, DImode, DImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxdp, smaxv2di3, V2DImode, V2DImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxdq, smaxv4di3, V4DImode, V4DImode)

KVX_EXPAND_BUILTIN_3_STANDARD (minubo, uminv8qi3, V8QImode, V8QImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minubx, uminv16qi3, V16QImode, V16QImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minubv, uminv32qi3, V32QImode, V32QImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minuhq, uminv4hi3, V4HImode, V4HImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minuho, uminv8hi3, V8HImode, V8HImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minuhx, uminv16hi3, V16HImode, V16HImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minuw, uminsi3, SImode, SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minuwp, uminv2si3, V2SImode, V2SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minuwq, uminv4si3, V4SImode, V4SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minuwo, uminv8si3, V8SImode, V8SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minud, umindi3, DImode, DImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minudp, uminv2di3, V2DImode, V2DImode)
KVX_EXPAND_BUILTIN_3_STANDARD (minudq, uminv4di3, V4DImode, V4DImode)

KVX_EXPAND_BUILTIN_3_STANDARD (maxubo, umaxv8qi3, V8QImode, V8QImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxubx, umaxv16qi3, V16QImode, V16QImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxubv, umaxv32qi3, V32QImode, V32QImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxuhq, umaxv4hi3, V4HImode, V4HImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxuho, umaxv8hi3, V8HImode, V8HImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxuhx, umaxv16hi3, V16HImode, V16HImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxuw, umaxsi3, SImode, SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxuwp, umaxv2si3, V2SImode, V2SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxuwq, umaxv4si3, V4SImode, V4SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxuwo, umaxv8si3, V8SImode, V8SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxud, umaxdi3, DImode, DImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxudp, umaxv2di3, V2DImode, V2DImode)
KVX_EXPAND_BUILTIN_3_STANDARD (maxudq, umaxv4di3, V4DImode, V4DImode)

KVX_EXPAND_BUILTIN_3_SHIFTLEFT (shlbos, V8QImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTLEFT (shlbxs, V16QImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTLEFT (shlbvs, V32QImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTLEFT (shlhqs, V4HImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTLEFT (shlhos, V8HImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTLEFT (shlhxs, V16HImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTLEFT (shlw, SImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTLEFT (shlwps, V2SImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTLEFT (shlwqs, V4SImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTLEFT (shlwos, V8SImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTLEFT (shld, DImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTLEFT (shldps, V2DImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTLEFT (shldqs, V4DImode, SImode)

KVX_EXPAND_BUILTIN_3_SHIFTRIGHT (shrbos, V8QImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTRIGHT (shrbxs, V16QImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTRIGHT (shrbvs, V32QImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTRIGHT (shrhqs, V4HImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTRIGHT (shrhos, V8HImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTRIGHT (shrhxs, V16HImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTRIGHT (shrw, SImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTRIGHT (shrwps, V2SImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTRIGHT (shrwqs, V4SImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTRIGHT (shrwos, V8SImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTRIGHT (shrd, DImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTRIGHT (shrdps, V2DImode, SImode)
KVX_EXPAND_BUILTIN_3_SHIFTRIGHT (shrdqs, V4DImode, SImode)

KVX_EXPAND_BUILTIN_2_STANDARD (clzw, clzsi2, SImode, SImode)
KVX_EXPAND_BUILTIN_2_STANDARD (clzd, clzdi2, DImode, DImode)
KVX_EXPAND_BUILTIN_2_STANDARD (ctzw, ctzsi2, SImode, SImode)
KVX_EXPAND_BUILTIN_2_STANDARD (ctzd, ctzdi2, DImode, DImode)
KVX_EXPAND_BUILTIN_2_STANDARD (cbsw, popcountsi2, SImode, SImode)
KVX_EXPAND_BUILTIN_2_STANDARD (cbsd, popcountdi2, DImode, DImode)

KVX_EXPAND_BUILTIN_2_COUNTING (bitcntw, SImode, SImode)
KVX_EXPAND_BUILTIN_2_COUNTING (bitcntwp, V2SImode, V2SImode)
KVX_EXPAND_BUILTIN_2_COUNTING (bitcntwq, V4SImode, V4SImode)
KVX_EXPAND_BUILTIN_2_COUNTING (bitcntwo, V8SImode, V8SImode)
KVX_EXPAND_BUILTIN_2_COUNTING (bitcntd, DImode, DImode)
KVX_EXPAND_BUILTIN_2_COUNTING (bitcntdp, V2DImode, V2DImode)
KVX_EXPAND_BUILTIN_2_COUNTING (bitcntdq, V4DImode, V4DImode)

KVX_EXPAND_BUILTIN_2_WIDENINT (widenbho, V8HImode, V8QImode)
KVX_EXPAND_BUILTIN_2_WIDENINT (widenbhx, V16HImode, V16QImode)
KVX_EXPAND_BUILTIN_2_WIDENINT (widenhwq, V4SImode, V4HImode)
KVX_EXPAND_BUILTIN_2_WIDENINT (widenhwo, V8SImode, V8HImode)
KVX_EXPAND_BUILTIN_2_WIDENINT (widenwdp, V2DImode, V2SImode)
KVX_EXPAND_BUILTIN_2_WIDENINT (widenwdq, V4DImode, V4SImode)

KVX_EXPAND_BUILTIN_2_NARROWINT (narrowhbo, V8QImode, V8HImode)
KVX_EXPAND_BUILTIN_2_NARROWINT (narrowhbx, V16QImode, V16HImode)
KVX_EXPAND_BUILTIN_2_NARROWINT (narrowwhq, V4HImode, V4SImode)
KVX_EXPAND_BUILTIN_2_NARROWINT (narrowwho, V8HImode, V8SImode)
KVX_EXPAND_BUILTIN_2_NARROWINT (narrowdwp, V2SImode, V2DImode)
KVX_EXPAND_BUILTIN_2_NARROWINT (narrowdwq, V4SImode, V4DImode)

KVX_EXPAND_BUILTIN_SHIFT (shiftbo, V8QImode, QImode)
KVX_EXPAND_BUILTIN_SHIFT (shiftbx, V16QImode, QImode)
KVX_EXPAND_BUILTIN_SHIFT (shiftbv, V32QImode, QImode)
KVX_EXPAND_BUILTIN_SHIFT (shifthq, V4HImode, HImode)
KVX_EXPAND_BUILTIN_SHIFT (shiftho, V8HImode, HImode)
KVX_EXPAND_BUILTIN_SHIFT (shifthx, V16HImode, HImode)
KVX_EXPAND_BUILTIN_SHIFT (shiftwp, V2SImode, SImode)
KVX_EXPAND_BUILTIN_SHIFT (shiftwq, V4SImode, SImode)
KVX_EXPAND_BUILTIN_SHIFT (shiftwo, V8SImode, SImode)
KVX_EXPAND_BUILTIN_SHIFT (shiftdp, V2DImode, DImode)
KVX_EXPAND_BUILTIN_SHIFT (shiftdq, V4DImode, DImode)
KVX_EXPAND_BUILTIN_SHIFT (shiftfhq, V4HFmode, HFmode)
KVX_EXPAND_BUILTIN_SHIFT (shiftfho, V8HFmode, HFmode)
KVX_EXPAND_BUILTIN_SHIFT (shiftfhx, V16HFmode, HFmode)
KVX_EXPAND_BUILTIN_SHIFT (shiftfwp, V2SFmode, SFmode)
KVX_EXPAND_BUILTIN_SHIFT (shiftfwq, V4SFmode, SFmode)
KVX_EXPAND_BUILTIN_SHIFT (shiftfwo, V8SFmode, SFmode)
KVX_EXPAND_BUILTIN_SHIFT (shiftfdp, V2DFmode, DFmode)
KVX_EXPAND_BUILTIN_SHIFT (shiftfdq, V4DFmode, DFmode)

KVX_EXPAND_BUILTIN_3_STANDARD (catbx, kvx_catbx, V16QImode, V8QImode)
KVX_EXPAND_BUILTIN_3_STANDARD (catbv, kvx_catbv, V32QImode, V16QImode)
KVX_EXPAND_BUILTIN_3_STANDARD (catho, kvx_catho, V8HImode, V4HImode)
KVX_EXPAND_BUILTIN_3_STANDARD (cathx, kvx_cathx, V16HImode, V8HImode)
KVX_EXPAND_BUILTIN_3_STANDARD (catwp, kvx_catwp, V2SImode, SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (catwq, kvx_catwq, V4SImode, V2SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (catwo, kvx_catwo, V8SImode, V4SImode)
KVX_EXPAND_BUILTIN_3_STANDARD (catdp, kvx_catdp, V2DImode, DImode)
KVX_EXPAND_BUILTIN_3_STANDARD (catdq, kvx_catdq, V4DImode, V2DImode)
KVX_EXPAND_BUILTIN_3_STANDARD (catfho, kvx_catfho, V8HFmode, V4HFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (catfhx, kvx_catfhx, V16HFmode, V8HFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (catfwp, kvx_catfwp, V2SFmode, SFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (catfwq, kvx_catfwq, V4SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (catfwo, kvx_catfwo, V8SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (catfdp, kvx_catfdp, V2DFmode, DFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (catfdq, kvx_catfdq, V4DFmode, V2DFmode)

KVX_EXPAND_BUILTIN_SELECT (selectbo, V8QImode, V8QImode)
KVX_EXPAND_BUILTIN_SELECT (selectbx, V16QImode, V16QImode)
KVX_EXPAND_BUILTIN_SELECT (selectbv, V32QImode, V32QImode)
KVX_EXPAND_BUILTIN_SELECT (selecthq, V4HImode, V4HImode)
KVX_EXPAND_BUILTIN_SELECT (selectho, V8HImode, V8HImode)
KVX_EXPAND_BUILTIN_SELECT (selecthx, V16HImode, V16HImode)
KVX_EXPAND_BUILTIN_SELECT (selectwp, V2SImode, V2SImode)
KVX_EXPAND_BUILTIN_SELECT (selectwq, V4SImode, V4SImode)
KVX_EXPAND_BUILTIN_SELECT (selectwo, V8SImode, V8SImode)
KVX_EXPAND_BUILTIN_SELECT (selectdp, V2DImode, V2DImode)
KVX_EXPAND_BUILTIN_SELECT (selectdq, V4DImode, V4DImode)
KVX_EXPAND_BUILTIN_SELECT (selectfhq, V4HFmode, V4HImode)
KVX_EXPAND_BUILTIN_SELECT (selectfho, V8HFmode, V8HImode)
KVX_EXPAND_BUILTIN_SELECT (selectfhx, V16HFmode, V16HImode)
KVX_EXPAND_BUILTIN_SELECT (selectfwp, V2SFmode, V2SImode)
KVX_EXPAND_BUILTIN_SELECT (selectfwq, V4SFmode, V4SImode)
KVX_EXPAND_BUILTIN_SELECT (selectfwo, V8SFmode, V8SImode)
KVX_EXPAND_BUILTIN_SELECT (selectfdp, V2DFmode, V2DImode)
KVX_EXPAND_BUILTIN_SELECT (selectfdq, V4DFmode, V4DImode)

KVX_EXPAND_BUILTIN_3_STANDARD (copysignh, copysignhf3, HFmode, HFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (copysignhq, copysignv4hf3, V4HFmode, V4HFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (copysignho, copysignv8hf3, V8HFmode, V8HFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (copysignhx, copysignv16hf3, V16HFmode, V16HFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (copysignw, copysignsf3, SFmode, SFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (copysignwp, copysignv2sf3, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (copysignwq, copysignv4sf3, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (copysignwo, copysignv8sf3, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (copysignd, copysigndf3, DFmode, DFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (copysigndp, copysignv2df3, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (copysigndq, copysignv4df3, V4DFmode, V4DFmode)

KVX_EXPAND_BUILTIN_3_STANDARD (fminh, fminhf3, HFmode, HFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fminhq, fminv4hf3, V4HFmode, V4HFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fminho, fminv8hf3, V8HFmode, V8HFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fminhx, fminv16hf3, V16HFmode, V16HFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fminw, fminsf3, SFmode, SFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fminwp, fminv2sf3, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fminwq, fminv4sf3, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fminwo, fminv8sf3, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fmind, fmindf3, DFmode, DFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fmindp, fminv2df3, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fmindq, fminv4df3, V4DFmode, V4DFmode)

KVX_EXPAND_BUILTIN_3_STANDARD (fmaxh, fmaxhf3, HFmode, HFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fmaxhq, fmaxv4hf3, V4HFmode, V4HFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fmaxho, fmaxv8hf3, V8HFmode, V8HFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fmaxhx, fmaxv16hf3, V16HFmode, V16HFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fmaxw, fmaxsf3, SFmode, SFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fmaxwp, fmaxv2sf3, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fmaxwq, fmaxv4sf3, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fmaxwo, fmaxv8sf3, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fmaxd, fmaxdf3, DFmode, DFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fmaxdp, fmaxv2df3, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_3_STANDARD (fmaxdq, fmaxv4df3, V4DFmode, V4DFmode)

KVX_EXPAND_BUILTIN_2_STANDARD (fnegh, neghf2, HFmode, HFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fneghq, negv4hf2, V4HFmode, V4HFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fnegho, negv8hf2, V8HFmode, V8HFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fneghx, negv16hf2, V16HFmode, V16HFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fnegw, negsf2, SFmode, SFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fnegwp, negv2sf2, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fnegwq, negv4sf2, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fnegwo, negv8sf2, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fnegd, negdf2, DFmode, DFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fnegdp, negv2df2, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fnegdq, negv4df2, V4DFmode, V4DFmode)

KVX_EXPAND_BUILTIN_2_STANDARD (fabsh, abshf2, HFmode, HFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fabshq, absv4hf2, V4HFmode, V4HFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fabsho, absv8hf2, V8HFmode, V8HFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fabshx, absv16hf2, V16HFmode, V16HFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fabsw, abssf2, SFmode, SFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fabswp, absv2sf2, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fabswq, absv4sf2, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fabswo, absv8sf2, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fabsd, absdf2, DFmode, DFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fabsdp, absv2df2, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fabsdq, absv4df2, V4DFmode, V4DFmode)

KVX_EXPAND_BUILTIN_2_FLOATINGS (frecw, SFmode, SFmode)
KVX_EXPAND_BUILTIN_2_FLOATINGS (frecwp, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_2_FLOATINGS (frecwq, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_2_FLOATINGS (frecwo, V8SFmode, V8SFmode)

KVX_EXPAND_BUILTIN_2_FLOATINGS (frsrw, SFmode, SFmode)
KVX_EXPAND_BUILTIN_2_FLOATINGS (frsrwp, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_2_FLOATINGS (frsrwq, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_2_FLOATINGS (frsrwo, V8SFmode, V8SFmode)

KVX_EXPAND_BUILTIN_3_FLOATINGS (faddh, HFmode, HFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (faddhq, V4HFmode, V4HFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (faddho, V8HFmode, V8HFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (faddhx, V16HFmode, V16HFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (faddw, SFmode, SFmode)
KVX_EXPAND_BUILTIN_3_CONJUGATE (faddwp, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_3_CONJUGATE (faddwq, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_3_CONJUGATE (faddwo, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (faddd, DFmode, DFmode)
KVX_EXPAND_BUILTIN_3_CONJUGATE (fadddp, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_3_CONJUGATE (fadddq, V4DFmode, V4DFmode)

KVX_EXPAND_BUILTIN_3_FLOATINGS (fsbfh, HFmode, HFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fsbfhq, V4HFmode, V4HFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fsbfho, V8HFmode, V8HFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fsbfhx, V16HFmode, V16HFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fsbfw, SFmode, SFmode)
KVX_EXPAND_BUILTIN_3_CONJUGATE (fsbfwp, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_3_CONJUGATE (fsbfwq, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_3_CONJUGATE (fsbfwo, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fsbfd, DFmode, DFmode)
KVX_EXPAND_BUILTIN_3_CONJUGATE (fsbfdp, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_3_CONJUGATE (fsbfdq, V4DFmode, V4DFmode)

KVX_EXPAND_BUILTIN_3_FLOATINGS (fmulh, HFmode, HFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fmulhq, V4HFmode, V4HFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fmulho, V8HFmode, V8HFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fmulhx, V16HFmode, V16HFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fmulw, SFmode, SFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fmulwp, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fmulwq, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fmulwo, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fmuld, DFmode, DFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fmuldp, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fmuldq, V4DFmode, V4DFmode)

KVX_EXPAND_BUILTIN_3_FLOATINGS (fmulxhw, SFmode, HFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fmulxhwq, V4SFmode, V4HFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fmulxhwo, V8SFmode, V8HFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fmulxwd, DFmode, SFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fmulxwdp, V2DFmode, V2SFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (fmulxwdq, V4DFmode, V4SFmode)
KVX_EXPAND_BUILTIN_3_CONJUGATE (fmulwc, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_3_CONJUGATE (fmulwcp, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_3_CONJUGATE (fmulwcq, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_3_CONJUGATE (fmuldc, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_3_CONJUGATE (fmuldcp, V4DFmode, V4DFmode)

KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmah, HFmode, HFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmahq, V4HFmode, V4HFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmaho, V8HFmode, V8HFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmahx, V16HFmode, V16HFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmaw, SFmode, SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmawp, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmawq, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmawo, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmad, DFmode, DFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmadp, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmadq, V4DFmode, V4DFmode)

KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmaxhw, SFmode, HFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmaxhwq, V4SFmode, V4HFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmaxhwo, V8SFmode, V8HFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmaxwd, DFmode, SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmaxwdp, V2DFmode, V2SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmaxwdq, V4DFmode, V4SFmode)
KVX_EXPAND_BUILTIN_4_CONJUGATE (ffmawc, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_4_CONJUGATE (ffmawcp, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_4_CONJUGATE (ffmawcq, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_4_CONJUGATE (ffmadc, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_4_CONJUGATE (ffmadcp, V4DFmode, V4DFmode)

KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmsh, HFmode, HFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmshq, V4HFmode, V4HFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmsho, V8HFmode, V8HFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmshx, V16HFmode, V16HFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmsw, SFmode, SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmswp, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmswq, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmswo, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmsd, DFmode, DFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmsdp, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmsdq, V4DFmode, V4DFmode)

KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmsxhw, SFmode, HFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmsxhwq, V4SFmode, V4HFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmsxhwo, V8SFmode, V8HFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmsxwd, DFmode, SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmsxwdp, V2DFmode, V2SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffmsxwdq, V4DFmode, V4SFmode)
KVX_EXPAND_BUILTIN_4_CONJUGATE (ffmswc, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_4_CONJUGATE (ffmswcp, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_4_CONJUGATE (ffmswcq, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_4_CONJUGATE (ffmsdc, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_4_CONJUGATE (ffmsdcp, V4DFmode, V4DFmode)

KVX_EXPAND_BUILTIN_3_FLOATINGS (fmm212w, V4SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_3_TRANSPOSE (fmm222w, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (fmma212w, V4SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_4_TRANSPOSE (fmma222w, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (fmms212w, V4SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_4_TRANSPOSE (fmms222w, V4SFmode, V4SFmode)

KVX_EXPAND_BUILTIN_3_FLOATINGS (ffdmaw, SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (ffdmawp, V2SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (ffdmawq, V4SFmode, V8SFmode)

KVX_EXPAND_BUILTIN_3_FLOATINGS (ffdmsw, SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (ffdmswp, V2SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_3_FLOATINGS (ffdmswq, V4SFmode, V8SFmode)

KVX_EXPAND_BUILTIN_4_FLOATINGS (ffdmdaw, SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffdmdawp, V2SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffdmdawq, V4SFmode, V8SFmode)

KVX_EXPAND_BUILTIN_4_FLOATINGS (ffdmsaw, SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffdmsawp, V2SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffdmsawq, V4SFmode, V8SFmode)

KVX_EXPAND_BUILTIN_4_FLOATINGS (ffdmdsw, SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffdmdswp, V2SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffdmdswq, V4SFmode, V8SFmode)

KVX_EXPAND_BUILTIN_4_FLOATINGS (ffdmasw, SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffdmaswp, V2SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_4_FLOATINGS (ffdmaswq, V4SFmode, V8SFmode)

KVX_EXPAND_BUILTIN_FCONVERT (floatw, SFmode, SImode)
KVX_EXPAND_BUILTIN_FCONVERT (floatwp, V2SFmode, V2SImode)
KVX_EXPAND_BUILTIN_FCONVERT (floatwq, V4SFmode, V4SImode)
KVX_EXPAND_BUILTIN_FCONVERT (floatwo, V8SFmode, V8SImode)
KVX_EXPAND_BUILTIN_FCONVERT (floatd, DFmode, DImode)
KVX_EXPAND_BUILTIN_FCONVERT (floatdp, V2DFmode, V2DImode)
KVX_EXPAND_BUILTIN_FCONVERT (floatdq, V4DFmode, V4DImode)

KVX_EXPAND_BUILTIN_FCONVERT (floatuw, SFmode, SImode)
KVX_EXPAND_BUILTIN_FCONVERT (floatuwp, V2SFmode, V2SImode)
KVX_EXPAND_BUILTIN_FCONVERT (floatuwq, V4SFmode, V4SImode)
KVX_EXPAND_BUILTIN_FCONVERT (floatuwo, V8SFmode, V8SImode)
KVX_EXPAND_BUILTIN_FCONVERT (floatud, DFmode, DImode)
KVX_EXPAND_BUILTIN_FCONVERT (floatudp, V2DFmode, V2DImode)
KVX_EXPAND_BUILTIN_FCONVERT (floatudq, V4DFmode, V4DImode)

KVX_EXPAND_BUILTIN_FCONVERT (fixedw, SImode, SFmode)
KVX_EXPAND_BUILTIN_FCONVERT (fixedwp, V2SImode, V2SFmode)
KVX_EXPAND_BUILTIN_FCONVERT (fixedwq, V4SImode, V4SFmode)
KVX_EXPAND_BUILTIN_FCONVERT (fixedwo, V8SImode, V8SFmode)
KVX_EXPAND_BUILTIN_FCONVERT (fixedd, DImode, DFmode)
KVX_EXPAND_BUILTIN_FCONVERT (fixeddp, V2DImode, V2DFmode)
KVX_EXPAND_BUILTIN_FCONVERT (fixeddq, V4DImode, V4DFmode)

KVX_EXPAND_BUILTIN_FCONVERT (fixeduw, SImode, SFmode)
KVX_EXPAND_BUILTIN_FCONVERT (fixeduwp, V2SImode, V2SFmode)
KVX_EXPAND_BUILTIN_FCONVERT (fixeduwq, V4SImode, V4SFmode)
KVX_EXPAND_BUILTIN_FCONVERT (fixeduwo, V8SImode, V8SFmode)
KVX_EXPAND_BUILTIN_FCONVERT (fixedud, DImode, DFmode)
KVX_EXPAND_BUILTIN_FCONVERT (fixedudp, V2DImode, V2DFmode)
KVX_EXPAND_BUILTIN_FCONVERT (fixedudq, V4DImode, V4DFmode)

KVX_EXPAND_BUILTIN_2_SILENT (fwidenhw, SFmode, HFmode)
KVX_EXPAND_BUILTIN_2_SILENT (fwidenhwq, V4SFmode, V4HFmode)
KVX_EXPAND_BUILTIN_2_SILENT (fwidenhwo, V8SFmode, V8HFmode)
KVX_EXPAND_BUILTIN_2_SILENT (fwidenwd, DFmode, SFmode)
KVX_EXPAND_BUILTIN_2_SILENT (fwidenwdp, V2DFmode, V2SFmode)
KVX_EXPAND_BUILTIN_2_SILENT (fwidenwdq, V4DFmode, V4SFmode)

KVX_EXPAND_BUILTIN_2_FLOATINGS (fnarrowwh, HFmode, SFmode)
KVX_EXPAND_BUILTIN_2_FLOATINGS (fnarrowwhq, V4HFmode, V4SFmode)
KVX_EXPAND_BUILTIN_2_FLOATINGS (fnarrowwho, V8HFmode, V8SFmode)
KVX_EXPAND_BUILTIN_2_FLOATINGS (fnarrowdw, SFmode, DFmode)
KVX_EXPAND_BUILTIN_2_FLOATINGS (fnarrowdwp, V2SFmode, V2DFmode)
KVX_EXPAND_BUILTIN_2_FLOATINGS (fnarrowdwq, V4SFmode, V4DFmode)

KVX_EXPAND_BUILTIN_2_STANDARD (fconjwc, kvx_fconjwc, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fconjwcp, kvx_fconjwcp, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fconjwcq, kvx_fconjwcq, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fconjdc, kvx_fconjdc, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_2_STANDARD (fconjdcp, kvx_fconjdcp, V4DFmode, V4DFmode)

KVX_EXPAND_BUILTIN_3_SILENT (fcdivw, SFmode, SFmode)
KVX_EXPAND_BUILTIN_3_SILENT (fcdivwp, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_3_SILENT (fcdivwq, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_3_SILENT (fcdivwo, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_3_SILENT (fcdivd, DFmode, DFmode)
KVX_EXPAND_BUILTIN_3_SILENT (fcdivdp, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_3_SILENT (fcdivdq, V4DFmode, V4DFmode)

KVX_EXPAND_BUILTIN_3_SILENT (fsdivw, SFmode, SFmode)
KVX_EXPAND_BUILTIN_3_SILENT (fsdivwp, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_3_SILENT (fsdivwq, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_3_SILENT (fsdivwo, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_3_SILENT (fsdivd, DFmode, DFmode)
KVX_EXPAND_BUILTIN_3_SILENT (fsdivdp, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_3_SILENT (fsdivdq, V4DFmode, V4DFmode)

KVX_EXPAND_BUILTIN_2_SILENT (fsrecw, SFmode, SFmode)
KVX_EXPAND_BUILTIN_2_SILENT (fsrecwp, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_2_SILENT (fsrecwq, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_2_SILENT (fsrecwo, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_2_SILENT (fsrecd, DFmode, DFmode)
KVX_EXPAND_BUILTIN_2_SILENT (fsrecdp, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_2_SILENT (fsrecdq, V4DFmode, V4DFmode)

KVX_EXPAND_BUILTIN_2_SILENT (fsrsrw, SFmode, SFmode)
KVX_EXPAND_BUILTIN_2_SILENT (fsrsrwp, V2SFmode, V2SFmode)
KVX_EXPAND_BUILTIN_2_SILENT (fsrsrwq, V4SFmode, V4SFmode)
KVX_EXPAND_BUILTIN_2_SILENT (fsrsrwo, V8SFmode, V8SFmode)
KVX_EXPAND_BUILTIN_2_SILENT (fsrsrd, DFmode, DFmode)
KVX_EXPAND_BUILTIN_2_SILENT (fsrsrdp, V2DFmode, V2DFmode)
KVX_EXPAND_BUILTIN_2_SILENT (fsrsrdq, V4DFmode, V4DFmode)

static rtx
kvx_expand_builtin_lbsu (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  arg1 = gen_rtx_MEM (QImode, force_reg (Pmode, arg1));

  if (!target)
    target = gen_reg_rtx (QImode);
  else
    target = force_reg (QImode, target);

  emit_insn (gen_lbsu (target, arg1));

  return target;
}

static rtx
kvx_expand_builtin_lbzu (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  arg1 = gen_rtx_MEM (QImode, force_reg (Pmode, arg1));

  if (!target)
    target = gen_reg_rtx (QImode);
  else
    target = force_reg (QImode, target);

  emit_insn (gen_lbzu (target, arg1));

  return target;
}

static rtx
kvx_expand_builtin_ldu (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  arg1 = gen_rtx_MEM (DImode, force_reg (Pmode, arg1));

  if (!target)
    target = gen_reg_rtx (DImode);
  else
    target = force_reg (DImode, target);

  emit_insn (gen_ldu (target, arg1));

  return target;
}

static rtx
kvx_expand_builtin_lhsu (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  arg1 = gen_rtx_MEM (HImode, force_reg (Pmode, arg1));

  if (!target)
    target = gen_reg_rtx (HImode);
  else
    target = force_reg (HImode, target);

  emit_insn (gen_lhsu (target, arg1));

  return target;
}

static rtx
kvx_expand_builtin_lhzu (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  arg1 = gen_rtx_MEM (HImode, force_reg (Pmode, arg1));

  if (!target)
    target = gen_reg_rtx (HImode);
  else
    target = force_reg (HImode, target);

  emit_insn (gen_lhzu (target, arg1));

  return target;
}

static rtx
kvx_expand_builtin_lwzu (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  arg1 = gen_rtx_MEM (SImode, force_reg (Pmode, arg1));

  if (!target)
    target = gen_reg_rtx (SImode);
  else
    target = force_reg (SImode, target);

  emit_insn (gen_lwzu (target, arg1));

  return target;
}

static rtx
kvx_expand_builtin_stsuw (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));
  arg1 = force_reg (SImode, arg1);
  arg2 = force_reg (SImode, arg2);

  if (!target)
    target = gen_reg_rtx (SImode);
  else
    target = force_reg (SImode, target);

  emit_insn (gen_kvx_stsuw (target, arg1, arg2));

  return target;
}

static rtx
kvx_expand_builtin_stsud (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));
  arg1 = force_reg (DImode, arg1);
  arg2 = force_reg (DImode, arg2);

  if (!target)
    target = gen_reg_rtx (DImode);
  else
    target = force_reg (DImode, target);

  emit_insn (gen_kvx_stsud (target, arg1, arg2));

  return target;
}

static rtx
kvx_expand_builtin_stsudp (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));
  arg1 = force_reg (V2DImode, arg1);
  arg2 = force_reg (V2DImode, arg2);

  if (!target)
    target = gen_reg_rtx (V2DImode);
  else
    target = force_reg (V2DImode, target);

  emit_insn (gen_kvx_stsudp (target, arg1, arg2));

  return target;
}

#define KVX_EXPAND_BUILTIN_LX(name, tmode, smode)                              \
  static rtx kvx_expand_builtin_##name (rtx target, tree args)                 \
  {                                                                            \
    int v = 0;                                                                 \
    rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));                        \
    rtx arg2 = build_variant_arg (CALL_EXPR_ARG (args, 1), #name, &v);         \
    rtx arg3 = expand_normal (CALL_EXPR_ARG (args, 2));                        \
    arg1 = gen_rtx_MEM (smode, force_reg (Pmode, arg1));                       \
    arg3 = verify_const_bool_arg (arg3, #name, "third");                       \
    MEM_VOLATILE_P (arg1) = v | (INTVAL (arg3) != 0);                          \
    if (!target)                                                               \
      target = gen_reg_rtx (tmode);                                            \
    else                                                                       \
      target = force_reg (tmode, target);                                      \
    emit_insn (gen_kvx_##name (target, arg1, arg2));                           \
    return target;                                                             \
  }

#define KVX_EXPAND_BUILTIN_SX(name, mode)                                      \
  static rtx kvx_expand_builtin_##name (rtx target, tree args)                 \
  {                                                                            \
    machine_mode tmode = mode;                                                 \
    rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));                        \
    rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));                        \
    rtx arg3 = expand_normal (CALL_EXPR_ARG (args, 2));                        \
    arg1 = gen_rtx_MEM (tmode, force_reg (Pmode, arg1));                       \
    arg2 = force_reg (tmode, arg2);                                            \
    arg3 = verify_const_bool_arg (arg3, #name, "third");                       \
    MEM_VOLATILE_P (arg1) = (INTVAL (arg3) != 0);                              \
    emit_insn (gen_kvx_##name (arg1, arg2));                                   \
    return target;                                                             \
  }

KVX_EXPAND_BUILTIN_LX (lbz, DImode, QImode)
KVX_EXPAND_BUILTIN_LX (lbs, DImode, QImode)
KVX_EXPAND_BUILTIN_LX (lhz, DImode, HImode)
KVX_EXPAND_BUILTIN_LX (lhs, DImode, HImode)
KVX_EXPAND_BUILTIN_LX (lwz, DImode, SImode)
KVX_EXPAND_BUILTIN_LX (lws, DImode, SImode)
KVX_EXPAND_BUILTIN_LX (ld, DImode, DImode)
KVX_EXPAND_BUILTIN_LX (lq, TImode, TImode)
KVX_EXPAND_BUILTIN_LX (lhf, HFmode, HFmode)
KVX_EXPAND_BUILTIN_LX (lwf, SFmode, SFmode)
KVX_EXPAND_BUILTIN_LX (ldf, DFmode, DFmode)

KVX_EXPAND_BUILTIN_LX (lbo, V8QImode, V8QImode)
KVX_EXPAND_BUILTIN_LX (lbx, V16QImode, V16QImode)
KVX_EXPAND_BUILTIN_LX (lbv, V32QImode, V32QImode)
KVX_EXPAND_BUILTIN_LX (lhq, V4HImode, V4HImode)
KVX_EXPAND_BUILTIN_LX (lho, V8HImode, V8HImode)
KVX_EXPAND_BUILTIN_LX (lhx, V16HImode, V16HImode)
KVX_EXPAND_BUILTIN_LX (lwp, V2SImode, V2SImode)
KVX_EXPAND_BUILTIN_LX (lwq, V4SImode, V4SImode)
KVX_EXPAND_BUILTIN_LX (lwo, V8SImode, V8SImode)
KVX_EXPAND_BUILTIN_LX (ldp, V2DImode, V2DImode)
KVX_EXPAND_BUILTIN_LX (ldq, V4DImode, V4DImode)

KVX_EXPAND_BUILTIN_SX (sbo, V8QImode)
KVX_EXPAND_BUILTIN_SX (sbx, V16QImode)
KVX_EXPAND_BUILTIN_SX (sbv, V32QImode)
KVX_EXPAND_BUILTIN_SX (shq, V4HImode)
KVX_EXPAND_BUILTIN_SX (sho, V8HImode)
KVX_EXPAND_BUILTIN_SX (shx, V16HImode)
KVX_EXPAND_BUILTIN_SX (swp, V2SImode)
KVX_EXPAND_BUILTIN_SX (swq, V4SImode)
KVX_EXPAND_BUILTIN_SX (swo, V8SImode)
KVX_EXPAND_BUILTIN_SX (sdp, V2DImode)
KVX_EXPAND_BUILTIN_SX (sdq, V4DImode)

#define KVX_EXPAND_BUILTIN_LOAD(name, tmode, mmode)                            \
  static rtx kvx_expand_builtin_##name (rtx target, tree args)                 \
  {                                                                            \
    int v = 0;                                                                 \
    rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));                        \
    rtx arg2 = build_variant_arg (CALL_EXPR_ARG (args, 1), #name, &v);         \
    arg1 = gen_rtx_MEM (mmode, force_reg (Pmode, arg1));                       \
    MEM_VOLATILE_P (arg1) = v;                                                 \
    if (!target)                                                               \
      target = gen_reg_rtx (tmode);                                            \
    else                                                                       \
      target = force_reg (tmode, target);                                      \
    emit_insn (gen_kvx_##name (target, arg1, arg2));                           \
    return target;                                                             \
  }

KVX_EXPAND_BUILTIN_LOAD (loadbz, DImode, QImode)
KVX_EXPAND_BUILTIN_LOAD (loadhz, DImode, HImode)
KVX_EXPAND_BUILTIN_LOAD (loadwz, DImode, SImode)
KVX_EXPAND_BUILTIN_LOAD (loadd, DImode, DImode)
KVX_EXPAND_BUILTIN_LOAD (loadq, TImode, TImode)
KVX_EXPAND_BUILTIN_LOAD (load64, V8QImode, V8QImode)
KVX_EXPAND_BUILTIN_LOAD (load128, V16QImode, V16QImode)
KVX_EXPAND_BUILTIN_LOAD (load256, V32QImode, V32QImode)
KVX_EXPAND_BUILTIN_LOAD (xload256, V1OImode, V1OImode)

#define KVX_EXPAND_BUILTIN_LOADC(name, tmode, mmode)                           \
  static rtx kvx_expand_builtin_##name (rtx target, tree args)                 \
  {                                                                            \
    int v = 0;                                                                 \
    rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));                        \
    rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));                        \
    rtx arg3 = expand_normal (CALL_EXPR_ARG (args, 2));                        \
    rtx arg4 = build_loadcond_arg (CALL_EXPR_ARG (args, 3), #name, &v);        \
    arg1 = gen_rtx_MEM (mmode, force_reg (Pmode, arg1));                       \
    arg2 = force_reg (tmode, arg2);                                            \
    arg3 = force_reg (DImode, arg3);                                           \
    MEM_VOLATILE_P (arg1) = v;                                                 \
    if (!target)                                                               \
      target = gen_reg_rtx (tmode);                                            \
    else                                                                       \
      target = force_reg (tmode, target);                                      \
    emit_insn (gen_kvx_##name (target, arg1, arg2, arg3, arg4));               \
    return target;                                                             \
  }

KVX_EXPAND_BUILTIN_LOADC (loadcbz, DImode, QImode)
KVX_EXPAND_BUILTIN_LOADC (loadchz, DImode, HImode)
KVX_EXPAND_BUILTIN_LOADC (loadcwz, DImode, SImode)
KVX_EXPAND_BUILTIN_LOADC (loadcd, DImode, DImode)
KVX_EXPAND_BUILTIN_LOADC (loadcq, TImode, TImode)
KVX_EXPAND_BUILTIN_LOADC (loadc64, V8QImode, V8QImode)
KVX_EXPAND_BUILTIN_LOADC (loadc128, V16QImode, V16QImode)
KVX_EXPAND_BUILTIN_LOADC (loadc256, V32QImode, V32QImode)
KVX_EXPAND_BUILTIN_LOADC (xloadc256, V1OImode, V1OImode)

#define KVX_EXPAND_BUILTIN_STORE(name, tmode, mmode)                           \
  static rtx kvx_expand_builtin_##name (rtx target, tree args)                 \
  {                                                                            \
    int v = 0;                                                                 \
    rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));                        \
    rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));                        \
    rtx arg3 = build_volatile_arg (CALL_EXPR_ARG (args, 2), #name, &v);        \
    arg1 = force_reg (tmode, arg1);                                            \
    arg2 = gen_rtx_MEM (mmode, force_reg (Pmode, arg2));                       \
    MEM_VOLATILE_P (arg2) = v;                                                 \
    emit_insn (gen_kvx_##name (arg1, arg2));                                   \
    return target;                                                             \
  }

KVX_EXPAND_BUILTIN_STORE (storeb, DImode, QImode)
KVX_EXPAND_BUILTIN_STORE (storeh, DImode, HImode)
KVX_EXPAND_BUILTIN_STORE (storew, DImode, SImode)
KVX_EXPAND_BUILTIN_STORE (stored, DImode, DImode)
KVX_EXPAND_BUILTIN_STORE (storeq, TImode, TImode)
KVX_EXPAND_BUILTIN_STORE (store64, V8QImode, V8QImode)
KVX_EXPAND_BUILTIN_STORE (store128, V16QImode, V16QImode)
KVX_EXPAND_BUILTIN_STORE (store256, V32QImode, V32QImode)
KVX_EXPAND_BUILTIN_STORE (xstore256, V1OImode, V1OImode)

#define KVX_EXPAND_BUILTIN_STOREC(name, tmode, mmode)                          \
  static rtx kvx_expand_builtin_##name (rtx target, tree args)                 \
  {                                                                            \
    int v = 0;                                                                 \
    rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));                        \
    rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));                        \
    rtx arg3 = expand_normal (CALL_EXPR_ARG (args, 2));                        \
    rtx arg4 = build_storecond_arg (CALL_EXPR_ARG (args, 3), #name, &v);       \
    arg1 = force_reg (tmode, arg1);                                            \
    arg2 = gen_rtx_MEM (mmode, force_reg (Pmode, arg2));                       \
    arg3 = force_reg (DImode, arg3);                                           \
    MEM_VOLATILE_P (arg2) = v;                                                 \
    emit_insn (gen_kvx_##name (arg1, arg2, arg3, arg4));                       \
    return target;                                                             \
  }

KVX_EXPAND_BUILTIN_STOREC (storecb, DImode, QImode)
KVX_EXPAND_BUILTIN_STOREC (storech, DImode, HImode)
KVX_EXPAND_BUILTIN_STOREC (storecw, DImode, SImode)
KVX_EXPAND_BUILTIN_STOREC (storecd, DImode, DImode)
KVX_EXPAND_BUILTIN_STOREC (storecq, TImode, TImode)
KVX_EXPAND_BUILTIN_STOREC (storec64, V8QImode, V8QImode)
KVX_EXPAND_BUILTIN_STOREC (storec128, V16QImode, V16QImode)
KVX_EXPAND_BUILTIN_STOREC (storec256, V32QImode, V32QImode)
KVX_EXPAND_BUILTIN_STOREC (xstorec256, V1OImode, V1OImode)

static rtx
kvx_expand_builtin_xload256q (rtx target, tree args, int quarter)
{
  int v = 0;
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));
  rtx arg3 = build_variant_arg (CALL_EXPR_ARG (args, 2), "xload256q", &v);
  rtx arg4 = GEN_INT (quarter);
  arg1 = gen_rtx_MEM (V1OImode, force_reg (Pmode, arg1));
  arg2 = force_reg (V4OImode, arg2);
  MEM_VOLATILE_P (arg1) = v;
  if (!target)
    target = gen_reg_rtx (V4OImode);
  else
    target = force_reg (V4OImode, target);
  emit_insn (gen_kvx_xload256q (target, arg1, arg2, arg3, arg4));
  return target;
}

static rtx
kvx_expand_builtin_xloadc256q (rtx target, tree args, int quarter)
{
  int v = 0;
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));
  rtx arg3 = expand_normal (CALL_EXPR_ARG (args, 2));
  rtx arg4 = build_loadcond_arg (CALL_EXPR_ARG (args, 3), "xloadc256q", &v);
  rtx arg5 = GEN_INT (quarter);
  arg1 = gen_rtx_MEM (V1OImode, force_reg (Pmode, arg1));
  arg2 = force_reg (V4OImode, arg2);
  arg3 = force_reg (DImode, arg3);
  MEM_VOLATILE_P (arg1) = v;
  if (!target)
    target = gen_reg_rtx (V4OImode);
  else
    target = force_reg (V4OImode, target);
  emit_insn (gen_kvx_xloadc256q (target, arg1, arg2, arg3, arg4, arg5));
  return target;
}

static rtx
kvx_expand_builtin_xswap256 (rtx target, tree args)
{
  machine_mode tmode = V1OImode;
  machine_mode smode = V32QImode;
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));
  arg1 = force_reg (Pmode, arg1);
  arg2 = force_reg (smode, arg2);
  if (!target)
    target = gen_reg_rtx (tmode);
  else
    target = force_reg (tmode, target);
  rtx mem = gen_rtx_MEM (tmode, arg1);
  emit_insn (gen_kvx_xswap256 (target, mem, arg2));
  return target;
}

static rtx
kvx_expand_builtin_xmt44d (rtx target, tree args)
{
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  arg1 = force_reg (V4OImode, arg1);
  if (!target)
    target = gen_reg_rtx (V4OImode);
  else
    target = force_reg (V4OImode, target);
  emit_insn (gen_kvx_xmt44d (target, arg1));
  return target;
}

static rtx
kvx_expand_builtin_xmma484bw (rtx target, tree args)
{
  machine_mode tmode = V2OImode;
  machine_mode smode = V1OImode;
  rtx arg1 = expand_normal (CALL_EXPR_ARG (args, 0));
  rtx arg2 = expand_normal (CALL_EXPR_ARG (args, 1));
  rtx arg3 = expand_normal (CALL_EXPR_ARG (args, 2));
  rtx arg4 = build_xmatmul_arg (CALL_EXPR_ARG (args, 3), "xmma484bw");
  arg1 = force_reg (smode, arg1);
  arg2 = force_reg (smode, arg2);
  arg3 = force_reg (tmode, arg3);
  if (!target)
    target = gen_reg_rtx (tmode);
  else
    target = force_reg (tmode, target);
  emit_insn (gen_kvx_xmma484bw (target, arg1, arg2, arg3, arg4));
  return target;
}

rtx
kvx_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,
		    enum machine_mode mode ATTRIBUTE_UNUSED,
		    int ignore ATTRIBUTE_UNUSED)
{
  tree fndecl = TREE_OPERAND (CALL_EXPR_FN (exp), 0);
  unsigned int fcode = DECL_FUNCTION_CODE (fndecl);

  switch (fcode)
    {
    case KVX_BUILTIN_ADDCD: return kvx_expand_builtin_addcd (target, exp);
    case KVX_BUILTIN_SBFCD: return kvx_expand_builtin_sbfcd (target, exp);

    case KVX_BUILTIN_ADDBO: return kvx_expand_builtin_addbo (target, exp);
    case KVX_BUILTIN_ADDBX: return kvx_expand_builtin_addbx (target, exp);
    case KVX_BUILTIN_ADDBV: return kvx_expand_builtin_addbv (target, exp);
    case KVX_BUILTIN_ADDHQ: return kvx_expand_builtin_addhq (target, exp);
    case KVX_BUILTIN_ADDHO: return kvx_expand_builtin_addho (target, exp);
    case KVX_BUILTIN_ADDHX: return kvx_expand_builtin_addhx (target, exp);
    case KVX_BUILTIN_ADDW: return kvx_expand_builtin_addw (target, exp);
    case KVX_BUILTIN_ADDWP: return kvx_expand_builtin_addwp (target, exp);
    case KVX_BUILTIN_ADDWQ: return kvx_expand_builtin_addwq (target, exp);
    case KVX_BUILTIN_ADDWO: return kvx_expand_builtin_addwo (target, exp);
    case KVX_BUILTIN_ADDD: return kvx_expand_builtin_addd (target, exp);
    case KVX_BUILTIN_ADDDP: return kvx_expand_builtin_adddp (target, exp);
    case KVX_BUILTIN_ADDDQ: return kvx_expand_builtin_adddq (target, exp);

    case KVX_BUILTIN_SBFBO: return kvx_expand_builtin_sbfbo (target, exp);
    case KVX_BUILTIN_SBFBX: return kvx_expand_builtin_sbfbx (target, exp);
    case KVX_BUILTIN_SBFBV: return kvx_expand_builtin_sbfbv (target, exp);
    case KVX_BUILTIN_SBFHQ: return kvx_expand_builtin_sbfhq (target, exp);
    case KVX_BUILTIN_SBFHO: return kvx_expand_builtin_sbfho (target, exp);
    case KVX_BUILTIN_SBFHX: return kvx_expand_builtin_sbfhx (target, exp);
    case KVX_BUILTIN_SBFW: return kvx_expand_builtin_sbfw (target, exp);
    case KVX_BUILTIN_SBFWP: return kvx_expand_builtin_sbfwp (target, exp);
    case KVX_BUILTIN_SBFWQ: return kvx_expand_builtin_sbfwq (target, exp);
    case KVX_BUILTIN_SBFWO: return kvx_expand_builtin_sbfwo (target, exp);
    case KVX_BUILTIN_SBFD: return kvx_expand_builtin_sbfd (target, exp);
    case KVX_BUILTIN_SBFDP: return kvx_expand_builtin_sbfdp (target, exp);
    case KVX_BUILTIN_SBFDQ: return kvx_expand_builtin_sbfdq (target, exp);

    case KVX_BUILTIN_NEGBO: return kvx_expand_builtin_negbo (target, exp);
    case KVX_BUILTIN_NEGBX: return kvx_expand_builtin_negbx (target, exp);
    case KVX_BUILTIN_NEGBV: return kvx_expand_builtin_negbv (target, exp);
    case KVX_BUILTIN_NEGHQ: return kvx_expand_builtin_neghq (target, exp);
    case KVX_BUILTIN_NEGHO: return kvx_expand_builtin_negho (target, exp);
    case KVX_BUILTIN_NEGHX: return kvx_expand_builtin_neghx (target, exp);
    case KVX_BUILTIN_NEGW: return kvx_expand_builtin_negw (target, exp);
    case KVX_BUILTIN_NEGWP: return kvx_expand_builtin_negwp (target, exp);
    case KVX_BUILTIN_NEGWQ: return kvx_expand_builtin_negwq (target, exp);
    case KVX_BUILTIN_NEGWO: return kvx_expand_builtin_negwo (target, exp);
    case KVX_BUILTIN_NEGD: return kvx_expand_builtin_negd (target, exp);
    case KVX_BUILTIN_NEGDP: return kvx_expand_builtin_negdp (target, exp);
    case KVX_BUILTIN_NEGDQ: return kvx_expand_builtin_negdq (target, exp);

    case KVX_BUILTIN_ABSBO: return kvx_expand_builtin_absbo (target, exp);
    case KVX_BUILTIN_ABSBX: return kvx_expand_builtin_absbx (target, exp);
    case KVX_BUILTIN_ABSBV: return kvx_expand_builtin_absbv (target, exp);
    case KVX_BUILTIN_ABSHQ: return kvx_expand_builtin_abshq (target, exp);
    case KVX_BUILTIN_ABSHO: return kvx_expand_builtin_absho (target, exp);
    case KVX_BUILTIN_ABSHX: return kvx_expand_builtin_abshx (target, exp);
    case KVX_BUILTIN_ABSW: return kvx_expand_builtin_absw (target, exp);
    case KVX_BUILTIN_ABSWP: return kvx_expand_builtin_abswp (target, exp);
    case KVX_BUILTIN_ABSWQ: return kvx_expand_builtin_abswq (target, exp);
    case KVX_BUILTIN_ABSWO: return kvx_expand_builtin_abswo (target, exp);
    case KVX_BUILTIN_ABSD: return kvx_expand_builtin_absd (target, exp);
    case KVX_BUILTIN_ABSDP: return kvx_expand_builtin_absdp (target, exp);
    case KVX_BUILTIN_ABSDQ: return kvx_expand_builtin_absdq (target, exp);

    case KVX_BUILTIN_ABDBO: return kvx_expand_builtin_abdbo (target, exp);
    case KVX_BUILTIN_ABDBX: return kvx_expand_builtin_abdbx (target, exp);
    case KVX_BUILTIN_ABDBV: return kvx_expand_builtin_abdbv (target, exp);
    case KVX_BUILTIN_ABDHQ: return kvx_expand_builtin_abdhq (target, exp);
    case KVX_BUILTIN_ABDHO: return kvx_expand_builtin_abdho (target, exp);
    case KVX_BUILTIN_ABDHX: return kvx_expand_builtin_abdhx (target, exp);
    case KVX_BUILTIN_ABDW: return kvx_expand_builtin_abdw (target, exp);
    case KVX_BUILTIN_ABDWP: return kvx_expand_builtin_abdwp (target, exp);
    case KVX_BUILTIN_ABDWQ: return kvx_expand_builtin_abdwq (target, exp);
    case KVX_BUILTIN_ABDWO: return kvx_expand_builtin_abdwo (target, exp);
    case KVX_BUILTIN_ABDD: return kvx_expand_builtin_abdd (target, exp);
    case KVX_BUILTIN_ABDDP: return kvx_expand_builtin_abddp (target, exp);
    case KVX_BUILTIN_ABDDQ: return kvx_expand_builtin_abddq (target, exp);

    case KVX_BUILTIN_AVGBO: return kvx_expand_builtin_avgbo (target, exp);
    case KVX_BUILTIN_AVGBX: return kvx_expand_builtin_avgbx (target, exp);
    case KVX_BUILTIN_AVGBV: return kvx_expand_builtin_avgbv (target, exp);
    case KVX_BUILTIN_AVGHQ: return kvx_expand_builtin_avghq (target, exp);
    case KVX_BUILTIN_AVGHO: return kvx_expand_builtin_avgho (target, exp);
    case KVX_BUILTIN_AVGHX: return kvx_expand_builtin_avghx (target, exp);
    case KVX_BUILTIN_AVGW: return kvx_expand_builtin_avgw (target, exp);
    case KVX_BUILTIN_AVGWP: return kvx_expand_builtin_avgwp (target, exp);
    case KVX_BUILTIN_AVGWQ: return kvx_expand_builtin_avgwq (target, exp);
    case KVX_BUILTIN_AVGWO: return kvx_expand_builtin_avgwo (target, exp);

    case KVX_BUILTIN_MULXHWQ: return kvx_expand_builtin_mulxhwq (target, exp);
    case KVX_BUILTIN_MULXHWO: return kvx_expand_builtin_mulxhwo (target, exp);
    case KVX_BUILTIN_MULXWDP: return kvx_expand_builtin_mulxwdp (target, exp);
    case KVX_BUILTIN_MULXWDQ: return kvx_expand_builtin_mulxwdq (target, exp);

    case KVX_BUILTIN_MADDXHWQ: return kvx_expand_builtin_maddxhwq (target, exp);
    case KVX_BUILTIN_MADDXHWO: return kvx_expand_builtin_maddxhwo (target, exp);
    case KVX_BUILTIN_MADDXWDP: return kvx_expand_builtin_maddxwdp (target, exp);
    case KVX_BUILTIN_MADDXWDQ: return kvx_expand_builtin_maddxwdq (target, exp);

    case KVX_BUILTIN_MSBFXHWQ: return kvx_expand_builtin_msbfxhwq (target, exp);
    case KVX_BUILTIN_MSBFXHWO: return kvx_expand_builtin_msbfxhwo (target, exp);
    case KVX_BUILTIN_MSBFXWDP: return kvx_expand_builtin_msbfxwdp (target, exp);
    case KVX_BUILTIN_MSBFXWDQ: return kvx_expand_builtin_msbfxwdq (target, exp);

    case KVX_BUILTIN_MINBO: return kvx_expand_builtin_minbo (target, exp);
    case KVX_BUILTIN_MINBX: return kvx_expand_builtin_minbx (target, exp);
    case KVX_BUILTIN_MINBV: return kvx_expand_builtin_minbv (target, exp);
    case KVX_BUILTIN_MINHQ: return kvx_expand_builtin_minhq (target, exp);
    case KVX_BUILTIN_MINHO: return kvx_expand_builtin_minho (target, exp);
    case KVX_BUILTIN_MINHX: return kvx_expand_builtin_minhx (target, exp);
    case KVX_BUILTIN_MINW: return kvx_expand_builtin_minw (target, exp);
    case KVX_BUILTIN_MINWP: return kvx_expand_builtin_minwp (target, exp);
    case KVX_BUILTIN_MINWQ: return kvx_expand_builtin_minwq (target, exp);
    case KVX_BUILTIN_MINWO: return kvx_expand_builtin_minwo (target, exp);
    case KVX_BUILTIN_MIND: return kvx_expand_builtin_mind (target, exp);
    case KVX_BUILTIN_MINDP: return kvx_expand_builtin_mindp (target, exp);
    case KVX_BUILTIN_MINDQ: return kvx_expand_builtin_mindq (target, exp);

    case KVX_BUILTIN_MAXBO: return kvx_expand_builtin_maxbo (target, exp);
    case KVX_BUILTIN_MAXBX: return kvx_expand_builtin_maxbx (target, exp);
    case KVX_BUILTIN_MAXBV: return kvx_expand_builtin_maxbv (target, exp);
    case KVX_BUILTIN_MAXHQ: return kvx_expand_builtin_maxhq (target, exp);
    case KVX_BUILTIN_MAXHO: return kvx_expand_builtin_maxho (target, exp);
    case KVX_BUILTIN_MAXHX: return kvx_expand_builtin_maxhx (target, exp);
    case KVX_BUILTIN_MAXW: return kvx_expand_builtin_maxw (target, exp);
    case KVX_BUILTIN_MAXWP: return kvx_expand_builtin_maxwp (target, exp);
    case KVX_BUILTIN_MAXWQ: return kvx_expand_builtin_maxwq (target, exp);
    case KVX_BUILTIN_MAXWO: return kvx_expand_builtin_maxwo (target, exp);
    case KVX_BUILTIN_MAXD: return kvx_expand_builtin_maxd (target, exp);
    case KVX_BUILTIN_MAXDP: return kvx_expand_builtin_maxdp (target, exp);
    case KVX_BUILTIN_MAXDQ: return kvx_expand_builtin_maxdq (target, exp);

    case KVX_BUILTIN_MINUBO: return kvx_expand_builtin_minubo (target, exp);
    case KVX_BUILTIN_MINUBX: return kvx_expand_builtin_minubx (target, exp);
    case KVX_BUILTIN_MINUBV: return kvx_expand_builtin_minubv (target, exp);
    case KVX_BUILTIN_MINUHQ: return kvx_expand_builtin_minuhq (target, exp);
    case KVX_BUILTIN_MINUHO: return kvx_expand_builtin_minuho (target, exp);
    case KVX_BUILTIN_MINUHX: return kvx_expand_builtin_minuhx (target, exp);
    case KVX_BUILTIN_MINUW: return kvx_expand_builtin_minuw (target, exp);
    case KVX_BUILTIN_MINUWP: return kvx_expand_builtin_minuwp (target, exp);
    case KVX_BUILTIN_MINUWQ: return kvx_expand_builtin_minuwq (target, exp);
    case KVX_BUILTIN_MINUWO: return kvx_expand_builtin_minuwo (target, exp);
    case KVX_BUILTIN_MINUD: return kvx_expand_builtin_minud (target, exp);
    case KVX_BUILTIN_MINUDP: return kvx_expand_builtin_minudp (target, exp);
    case KVX_BUILTIN_MINUDQ: return kvx_expand_builtin_minudq (target, exp);

    case KVX_BUILTIN_MAXUBO: return kvx_expand_builtin_maxubo (target, exp);
    case KVX_BUILTIN_MAXUBX: return kvx_expand_builtin_maxubx (target, exp);
    case KVX_BUILTIN_MAXUBV: return kvx_expand_builtin_maxubv (target, exp);
    case KVX_BUILTIN_MAXUHQ: return kvx_expand_builtin_maxuhq (target, exp);
    case KVX_BUILTIN_MAXUHO: return kvx_expand_builtin_maxuho (target, exp);
    case KVX_BUILTIN_MAXUHX: return kvx_expand_builtin_maxuhx (target, exp);
    case KVX_BUILTIN_MAXUW: return kvx_expand_builtin_maxuw (target, exp);
    case KVX_BUILTIN_MAXUWP: return kvx_expand_builtin_maxuwp (target, exp);
    case KVX_BUILTIN_MAXUWQ: return kvx_expand_builtin_maxuwq (target, exp);
    case KVX_BUILTIN_MAXUWO: return kvx_expand_builtin_maxuwo (target, exp);
    case KVX_BUILTIN_MAXUD: return kvx_expand_builtin_maxud (target, exp);
    case KVX_BUILTIN_MAXUDP: return kvx_expand_builtin_maxudp (target, exp);
    case KVX_BUILTIN_MAXUDQ: return kvx_expand_builtin_maxudq (target, exp);

    case KVX_BUILTIN_SHLBOS: return kvx_expand_builtin_shlbos (target, exp);
    case KVX_BUILTIN_SHLBXS: return kvx_expand_builtin_shlbxs (target, exp);
    case KVX_BUILTIN_SHLBVS: return kvx_expand_builtin_shlbvs (target, exp);
    case KVX_BUILTIN_SHLHQS: return kvx_expand_builtin_shlhqs (target, exp);
    case KVX_BUILTIN_SHLHOS: return kvx_expand_builtin_shlhos (target, exp);
    case KVX_BUILTIN_SHLHXS: return kvx_expand_builtin_shlhxs (target, exp);
    case KVX_BUILTIN_SHLW: return kvx_expand_builtin_shlw (target, exp);
    case KVX_BUILTIN_SHLWPS: return kvx_expand_builtin_shlwps (target, exp);
    case KVX_BUILTIN_SHLWQS: return kvx_expand_builtin_shlwqs (target, exp);
    case KVX_BUILTIN_SHLWOS: return kvx_expand_builtin_shlwos (target, exp);
    case KVX_BUILTIN_SHLD: return kvx_expand_builtin_shld (target, exp);
    case KVX_BUILTIN_SHLDPS: return kvx_expand_builtin_shldps (target, exp);
    case KVX_BUILTIN_SHLDQS: return kvx_expand_builtin_shldqs (target, exp);

    case KVX_BUILTIN_SHRBOS: return kvx_expand_builtin_shrbos (target, exp);
    case KVX_BUILTIN_SHRBXS: return kvx_expand_builtin_shrbxs (target, exp);
    case KVX_BUILTIN_SHRBVS: return kvx_expand_builtin_shrbvs (target, exp);
    case KVX_BUILTIN_SHRHQS: return kvx_expand_builtin_shrhqs (target, exp);
    case KVX_BUILTIN_SHRHOS: return kvx_expand_builtin_shrhos (target, exp);
    case KVX_BUILTIN_SHRHXS: return kvx_expand_builtin_shrhxs (target, exp);
    case KVX_BUILTIN_SHRW: return kvx_expand_builtin_shrw (target, exp);
    case KVX_BUILTIN_SHRWPS: return kvx_expand_builtin_shrwps (target, exp);
    case KVX_BUILTIN_SHRWQS: return kvx_expand_builtin_shrwqs (target, exp);
    case KVX_BUILTIN_SHRWOS: return kvx_expand_builtin_shrwos (target, exp);
    case KVX_BUILTIN_SHRD: return kvx_expand_builtin_shrd (target, exp);
    case KVX_BUILTIN_SHRDPS: return kvx_expand_builtin_shrdps (target, exp);
    case KVX_BUILTIN_SHRDQS: return kvx_expand_builtin_shrdqs (target, exp);

    case KVX_BUILTIN_CLZW: return kvx_expand_builtin_clzw (target, exp);
    case KVX_BUILTIN_CLZD: return kvx_expand_builtin_clzd (target, exp);
    case KVX_BUILTIN_CTZW: return kvx_expand_builtin_ctzw (target, exp);
    case KVX_BUILTIN_CTZD: return kvx_expand_builtin_ctzd (target, exp);
    case KVX_BUILTIN_CBSW: return kvx_expand_builtin_cbsw (target, exp);
    case KVX_BUILTIN_CBSD: return kvx_expand_builtin_cbsd (target, exp);

    case KVX_BUILTIN_BITCNTW: return kvx_expand_builtin_bitcntw (target, exp);
    case KVX_BUILTIN_BITCNTWP: return kvx_expand_builtin_bitcntwp (target, exp);
    case KVX_BUILTIN_BITCNTWQ: return kvx_expand_builtin_bitcntwq (target, exp);
    case KVX_BUILTIN_BITCNTWO: return kvx_expand_builtin_bitcntwo (target, exp);
    case KVX_BUILTIN_BITCNTD: return kvx_expand_builtin_bitcntd (target, exp);
    case KVX_BUILTIN_BITCNTDP: return kvx_expand_builtin_bitcntdp (target, exp);
    case KVX_BUILTIN_BITCNTDQ: return kvx_expand_builtin_bitcntdq (target, exp);

    case KVX_BUILTIN_WIDENBHO: return kvx_expand_builtin_widenbho (target, exp);
    case KVX_BUILTIN_WIDENBHX: return kvx_expand_builtin_widenbhx (target, exp);
    case KVX_BUILTIN_WIDENHWQ: return kvx_expand_builtin_widenhwq (target, exp);
    case KVX_BUILTIN_WIDENHWO: return kvx_expand_builtin_widenhwo (target, exp);
    case KVX_BUILTIN_WIDENWDP: return kvx_expand_builtin_widenwdp (target, exp);
    case KVX_BUILTIN_WIDENWDQ: return kvx_expand_builtin_widenwdq (target, exp);

    case KVX_BUILTIN_NARROWHBO: return kvx_expand_builtin_narrowhbo (target, exp);
    case KVX_BUILTIN_NARROWHBX: return kvx_expand_builtin_narrowhbx (target, exp);
    case KVX_BUILTIN_NARROWWHQ: return kvx_expand_builtin_narrowwhq (target, exp);
    case KVX_BUILTIN_NARROWWHO: return kvx_expand_builtin_narrowwho (target, exp);
    case KVX_BUILTIN_NARROWDWP: return kvx_expand_builtin_narrowdwp (target, exp);
    case KVX_BUILTIN_NARROWDWQ: return kvx_expand_builtin_narrowdwq (target, exp);

    case KVX_BUILTIN_SHIFTBO: return kvx_expand_builtin_shiftbo (target, exp);
    case KVX_BUILTIN_SHIFTBX: return kvx_expand_builtin_shiftbx (target, exp);
    case KVX_BUILTIN_SHIFTBV: return kvx_expand_builtin_shiftbv (target, exp);
    case KVX_BUILTIN_SHIFTHQ: return kvx_expand_builtin_shifthq (target, exp);
    case KVX_BUILTIN_SHIFTHO: return kvx_expand_builtin_shiftho (target, exp);
    case KVX_BUILTIN_SHIFTHX: return kvx_expand_builtin_shifthx (target, exp);
    case KVX_BUILTIN_SHIFTWP: return kvx_expand_builtin_shiftwp (target, exp);
    case KVX_BUILTIN_SHIFTWQ: return kvx_expand_builtin_shiftwq (target, exp);
    case KVX_BUILTIN_SHIFTWO: return kvx_expand_builtin_shiftwo (target, exp);
    case KVX_BUILTIN_SHIFTDP: return kvx_expand_builtin_shiftdp (target, exp);
    case KVX_BUILTIN_SHIFTDQ: return kvx_expand_builtin_shiftdq (target, exp);
    case KVX_BUILTIN_SHIFTFHQ: return kvx_expand_builtin_shiftfhq (target, exp);
    case KVX_BUILTIN_SHIFTFHO: return kvx_expand_builtin_shiftfho (target, exp);
    case KVX_BUILTIN_SHIFTFHX: return kvx_expand_builtin_shiftfhx (target, exp);
    case KVX_BUILTIN_SHIFTFWP: return kvx_expand_builtin_shiftfwp (target, exp);
    case KVX_BUILTIN_SHIFTFWQ: return kvx_expand_builtin_shiftfwq (target, exp);
    case KVX_BUILTIN_SHIFTFWO: return kvx_expand_builtin_shiftfwo (target, exp);
    case KVX_BUILTIN_SHIFTFDP: return kvx_expand_builtin_shiftfdp (target, exp);
    case KVX_BUILTIN_SHIFTFDQ: return kvx_expand_builtin_shiftfdq (target, exp);

    case KVX_BUILTIN_AWAIT: return kvx_expand_builtin_await (target, exp);
    case KVX_BUILTIN_BARRIER: return kvx_expand_builtin_barrier ();
    case KVX_BUILTIN_ACSWAPW: return kvx_expand_builtin_acswap (target, exp, SImode);
    case KVX_BUILTIN_ACSWAPD: return kvx_expand_builtin_acswap (target, exp, DImode);
    case KVX_BUILTIN_ALADDD: return kvx_expand_builtin_aladd (target, exp, DImode);
    case KVX_BUILTIN_ALADDW: return kvx_expand_builtin_aladd (target, exp, SImode);
    case KVX_BUILTIN_ALCLRD: return kvx_expand_builtin_alclr (target, exp, DImode);
    case KVX_BUILTIN_ALCLRW: return kvx_expand_builtin_alclr (target, exp, SImode);
    case KVX_BUILTIN_DINVAL: return kvx_expand_builtin_dinval ();
    case KVX_BUILTIN_DINVALL: return kvx_expand_builtin_dinvall (target, exp);
    case KVX_BUILTIN_DTOUCHL: return kvx_expand_builtin_dtouchl (target, exp);
    case KVX_BUILTIN_DZEROL: return kvx_expand_builtin_dzerol (target, exp);
    case KVX_BUILTIN_FENCE: return kvx_expand_builtin_fence ();

    case KVX_BUILTIN_CATBX: return kvx_expand_builtin_catbx (target, exp);
    case KVX_BUILTIN_CATBV: return kvx_expand_builtin_catbv (target, exp);
    case KVX_BUILTIN_CATHO: return kvx_expand_builtin_catho (target, exp);
    case KVX_BUILTIN_CATHX: return kvx_expand_builtin_cathx (target, exp);
    case KVX_BUILTIN_CATWP: return kvx_expand_builtin_catwp (target, exp);
    case KVX_BUILTIN_CATWQ: return kvx_expand_builtin_catwq (target, exp);
    case KVX_BUILTIN_CATWO: return kvx_expand_builtin_catwo (target, exp);
    case KVX_BUILTIN_CATDP: return kvx_expand_builtin_catdp (target, exp);
    case KVX_BUILTIN_CATDQ: return kvx_expand_builtin_catdq (target, exp);
    case KVX_BUILTIN_CATFHO: return kvx_expand_builtin_catfho (target, exp);
    case KVX_BUILTIN_CATFHX: return kvx_expand_builtin_catfhx (target, exp);
    case KVX_BUILTIN_CATFWP: return kvx_expand_builtin_catfwp (target, exp);
    case KVX_BUILTIN_CATFWQ: return kvx_expand_builtin_catfwq (target, exp);
    case KVX_BUILTIN_CATFWO: return kvx_expand_builtin_catfwo (target, exp);
    case KVX_BUILTIN_CATFDP: return kvx_expand_builtin_catfdp (target, exp);
    case KVX_BUILTIN_CATFDQ: return kvx_expand_builtin_catfdq (target, exp);

    case KVX_BUILTIN_SELECTBO: return kvx_expand_builtin_selectbo (target, exp);
    case KVX_BUILTIN_SELECTBX: return kvx_expand_builtin_selectbx (target, exp);
    case KVX_BUILTIN_SELECTBV: return kvx_expand_builtin_selectbv (target, exp);
    case KVX_BUILTIN_SELECTHQ: return kvx_expand_builtin_selecthq (target, exp);
    case KVX_BUILTIN_SELECTHO: return kvx_expand_builtin_selectho (target, exp);
    case KVX_BUILTIN_SELECTHX: return kvx_expand_builtin_selecthx (target, exp);
    case KVX_BUILTIN_SELECTWP: return kvx_expand_builtin_selectwp (target, exp);
    case KVX_BUILTIN_SELECTWQ: return kvx_expand_builtin_selectwq (target, exp);
    case KVX_BUILTIN_SELECTWO: return kvx_expand_builtin_selectwo (target, exp);
    case KVX_BUILTIN_SELECTDP: return kvx_expand_builtin_selectdp (target, exp);
    case KVX_BUILTIN_SELECTDQ: return kvx_expand_builtin_selectdq (target, exp);
    case KVX_BUILTIN_SELECTFHQ: return kvx_expand_builtin_selectfhq (target, exp);
    case KVX_BUILTIN_SELECTFHO: return kvx_expand_builtin_selectfho (target, exp);
    case KVX_BUILTIN_SELECTFHX: return kvx_expand_builtin_selectfhx (target, exp);
    case KVX_BUILTIN_SELECTFWP: return kvx_expand_builtin_selectfwp (target, exp);
    case KVX_BUILTIN_SELECTFWQ: return kvx_expand_builtin_selectfwq (target, exp);
    case KVX_BUILTIN_SELECTFWO: return kvx_expand_builtin_selectfwo (target, exp);
    case KVX_BUILTIN_SELECTFDP: return kvx_expand_builtin_selectfdp (target, exp);
    case KVX_BUILTIN_SELECTFDQ: return kvx_expand_builtin_selectfdq (target, exp);

    case KVX_BUILTIN_COPYSIGNH: return kvx_expand_builtin_copysignh (target, exp);
    case KVX_BUILTIN_COPYSIGNHQ: return kvx_expand_builtin_copysignhq (target, exp);
    case KVX_BUILTIN_COPYSIGNHO: return kvx_expand_builtin_copysignho (target, exp);
    case KVX_BUILTIN_COPYSIGNHX: return kvx_expand_builtin_copysignhx (target, exp);
    case KVX_BUILTIN_COPYSIGNW: return kvx_expand_builtin_copysignw (target, exp);
    case KVX_BUILTIN_COPYSIGNWP: return kvx_expand_builtin_copysignwp (target, exp);
    case KVX_BUILTIN_COPYSIGNWQ: return kvx_expand_builtin_copysignwq (target, exp);
    case KVX_BUILTIN_COPYSIGNWO: return kvx_expand_builtin_copysignwo (target, exp);
    case KVX_BUILTIN_COPYSIGND: return kvx_expand_builtin_copysignd (target, exp);
    case KVX_BUILTIN_COPYSIGNDP: return kvx_expand_builtin_copysigndp (target, exp);
    case KVX_BUILTIN_COPYSIGNDQ: return kvx_expand_builtin_copysigndq (target, exp);

    case KVX_BUILTIN_FMINH: return kvx_expand_builtin_fminh (target, exp);
    case KVX_BUILTIN_FMINHQ: return kvx_expand_builtin_fminhq (target, exp);
    case KVX_BUILTIN_FMINHO: return kvx_expand_builtin_fminho (target, exp);
    case KVX_BUILTIN_FMINHX: return kvx_expand_builtin_fminhx (target, exp);
    case KVX_BUILTIN_FMINW: return kvx_expand_builtin_fminw (target, exp);
    case KVX_BUILTIN_FMINWP: return kvx_expand_builtin_fminwp (target, exp);
    case KVX_BUILTIN_FMINWQ: return kvx_expand_builtin_fminwq (target, exp);
    case KVX_BUILTIN_FMINWO: return kvx_expand_builtin_fminwo (target, exp);
    case KVX_BUILTIN_FMIND: return kvx_expand_builtin_fmind (target, exp);
    case KVX_BUILTIN_FMINDP: return kvx_expand_builtin_fmindp (target, exp);
    case KVX_BUILTIN_FMINDQ: return kvx_expand_builtin_fmindq (target, exp);

    case KVX_BUILTIN_FMAXH: return kvx_expand_builtin_fmaxh (target, exp);
    case KVX_BUILTIN_FMAXHQ: return kvx_expand_builtin_fmaxhq (target, exp);
    case KVX_BUILTIN_FMAXHO: return kvx_expand_builtin_fmaxho (target, exp);
    case KVX_BUILTIN_FMAXHX: return kvx_expand_builtin_fmaxhx (target, exp);
    case KVX_BUILTIN_FMAXW: return kvx_expand_builtin_fmaxw (target, exp);
    case KVX_BUILTIN_FMAXWP: return kvx_expand_builtin_fmaxwp (target, exp);
    case KVX_BUILTIN_FMAXWQ: return kvx_expand_builtin_fmaxwq (target, exp);
    case KVX_BUILTIN_FMAXWO: return kvx_expand_builtin_fmaxwo (target, exp);
    case KVX_BUILTIN_FMAXD: return kvx_expand_builtin_fmaxd (target, exp);
    case KVX_BUILTIN_FMAXDP: return kvx_expand_builtin_fmaxdp (target, exp);
    case KVX_BUILTIN_FMAXDQ: return kvx_expand_builtin_fmaxdq (target, exp);

    case KVX_BUILTIN_FNEGH: return kvx_expand_builtin_fnegh (target, exp);
    case KVX_BUILTIN_FNEGHQ: return kvx_expand_builtin_fneghq (target, exp);
    case KVX_BUILTIN_FNEGHO: return kvx_expand_builtin_fnegho (target, exp);
    case KVX_BUILTIN_FNEGHX: return kvx_expand_builtin_fneghx (target, exp);
    case KVX_BUILTIN_FNEGW: return kvx_expand_builtin_fnegw (target, exp);
    case KVX_BUILTIN_FNEGWP: return kvx_expand_builtin_fnegwp (target, exp);
    case KVX_BUILTIN_FNEGWQ: return kvx_expand_builtin_fnegwq (target, exp);
    case KVX_BUILTIN_FNEGWO: return kvx_expand_builtin_fnegwo (target, exp);
    case KVX_BUILTIN_FNEGD: return kvx_expand_builtin_fnegd (target, exp);
    case KVX_BUILTIN_FNEGDP: return kvx_expand_builtin_fnegdp (target, exp);
    case KVX_BUILTIN_FNEGDQ: return kvx_expand_builtin_fnegdq (target, exp);

    case KVX_BUILTIN_FABSH: return kvx_expand_builtin_fabsh (target, exp);
    case KVX_BUILTIN_FABSHQ: return kvx_expand_builtin_fabshq (target, exp);
    case KVX_BUILTIN_FABSHO: return kvx_expand_builtin_fabsho (target, exp);
    case KVX_BUILTIN_FABSHX: return kvx_expand_builtin_fabshx (target, exp);
    case KVX_BUILTIN_FABSW: return kvx_expand_builtin_fabsw (target, exp);
    case KVX_BUILTIN_FABSWP: return kvx_expand_builtin_fabswp (target, exp);
    case KVX_BUILTIN_FABSWQ: return kvx_expand_builtin_fabswq (target, exp);
    case KVX_BUILTIN_FABSWO: return kvx_expand_builtin_fabswo (target, exp);
    case KVX_BUILTIN_FABSD: return kvx_expand_builtin_fabsd (target, exp);
    case KVX_BUILTIN_FABSDP: return kvx_expand_builtin_fabsdp (target, exp);
    case KVX_BUILTIN_FABSDQ: return kvx_expand_builtin_fabsdq (target, exp);

    case KVX_BUILTIN_FRECW: return kvx_expand_builtin_frecw (target, exp);
    case KVX_BUILTIN_FRECWP: return kvx_expand_builtin_frecwp (target, exp);
    case KVX_BUILTIN_FRECWQ: return kvx_expand_builtin_frecwq (target, exp);
    case KVX_BUILTIN_FRECWO: return kvx_expand_builtin_frecwo (target, exp);

    case KVX_BUILTIN_FRSRW: return kvx_expand_builtin_frsrw (target, exp);
    case KVX_BUILTIN_FRSRWP: return kvx_expand_builtin_frsrwp (target, exp);
    case KVX_BUILTIN_FRSRWQ: return kvx_expand_builtin_frsrwq (target, exp);
    case KVX_BUILTIN_FRSRWO: return kvx_expand_builtin_frsrwo (target, exp);

    case KVX_BUILTIN_FADDH: return kvx_expand_builtin_faddh (target, exp);
    case KVX_BUILTIN_FADDHQ: return kvx_expand_builtin_faddhq (target, exp);
    case KVX_BUILTIN_FADDHO: return kvx_expand_builtin_faddho (target, exp);
    case KVX_BUILTIN_FADDHX: return kvx_expand_builtin_faddhx (target, exp);
    case KVX_BUILTIN_FADDW: return kvx_expand_builtin_faddw (target, exp);
    case KVX_BUILTIN_FADDWP: return kvx_expand_builtin_faddwp (target, exp);
    case KVX_BUILTIN_FADDWQ: return kvx_expand_builtin_faddwq (target, exp);
    case KVX_BUILTIN_FADDWO: return kvx_expand_builtin_faddwo (target, exp);
    case KVX_BUILTIN_FADDD: return kvx_expand_builtin_faddd (target, exp);
    case KVX_BUILTIN_FADDDP: return kvx_expand_builtin_fadddp (target, exp);
    case KVX_BUILTIN_FADDDQ: return kvx_expand_builtin_fadddq (target, exp);

    case KVX_BUILTIN_FSBFH: return kvx_expand_builtin_fsbfh (target, exp);
    case KVX_BUILTIN_FSBFHQ: return kvx_expand_builtin_fsbfhq (target, exp);
    case KVX_BUILTIN_FSBFHO: return kvx_expand_builtin_fsbfho (target, exp);
    case KVX_BUILTIN_FSBFHX: return kvx_expand_builtin_fsbfhx (target, exp);
    case KVX_BUILTIN_FSBFW: return kvx_expand_builtin_fsbfw (target, exp);
    case KVX_BUILTIN_FSBFWP: return kvx_expand_builtin_fsbfwp (target, exp);
    case KVX_BUILTIN_FSBFWQ: return kvx_expand_builtin_fsbfwq (target, exp);
    case KVX_BUILTIN_FSBFWO: return kvx_expand_builtin_fsbfwo (target, exp);
    case KVX_BUILTIN_FSBFD: return kvx_expand_builtin_fsbfd (target, exp);
    case KVX_BUILTIN_FSBFDP: return kvx_expand_builtin_fsbfdp (target, exp);
    case KVX_BUILTIN_FSBFDQ: return kvx_expand_builtin_fsbfdq (target, exp);

    case KVX_BUILTIN_FMULH: return kvx_expand_builtin_fmulh (target, exp);
    case KVX_BUILTIN_FMULHQ: return kvx_expand_builtin_fmulhq (target, exp);
    case KVX_BUILTIN_FMULHO: return kvx_expand_builtin_fmulho (target, exp);
    case KVX_BUILTIN_FMULHX: return kvx_expand_builtin_fmulhx (target, exp);
    case KVX_BUILTIN_FMULW: return kvx_expand_builtin_fmulw (target, exp);
    case KVX_BUILTIN_FMULWP: return kvx_expand_builtin_fmulwp (target, exp);
    case KVX_BUILTIN_FMULWQ: return kvx_expand_builtin_fmulwq (target, exp);
    case KVX_BUILTIN_FMULWO: return kvx_expand_builtin_fmulwo (target, exp);
    case KVX_BUILTIN_FMULD: return kvx_expand_builtin_fmuld (target, exp);
    case KVX_BUILTIN_FMULDP: return kvx_expand_builtin_fmuldp (target, exp);
    case KVX_BUILTIN_FMULDQ: return kvx_expand_builtin_fmuldq (target, exp);

    case KVX_BUILTIN_FMULXHW: return kvx_expand_builtin_fmulxhw (target, exp);
    case KVX_BUILTIN_FMULXHWQ: return kvx_expand_builtin_fmulxhwq (target, exp);
    case KVX_BUILTIN_FMULXHWO: return kvx_expand_builtin_fmulxhwo (target, exp);
    case KVX_BUILTIN_FMULXWD: return kvx_expand_builtin_fmulxwd (target, exp);
    case KVX_BUILTIN_FMULXWDP: return kvx_expand_builtin_fmulxwdp (target, exp);
    case KVX_BUILTIN_FMULXWDQ: return kvx_expand_builtin_fmulxwdq (target, exp);
    case KVX_BUILTIN_FMULWC: return kvx_expand_builtin_fmulwc (target, exp);
    case KVX_BUILTIN_FMULWCP: return kvx_expand_builtin_fmulwcp (target, exp);
    case KVX_BUILTIN_FMULWCQ: return kvx_expand_builtin_fmulwcq (target, exp);
    case KVX_BUILTIN_FMULDC: return kvx_expand_builtin_fmuldc (target, exp);
    case KVX_BUILTIN_FMULDCP: return kvx_expand_builtin_fmuldcp (target, exp);

    case KVX_BUILTIN_FFMAH: return kvx_expand_builtin_ffmah (target, exp);
    case KVX_BUILTIN_FFMAHQ: return kvx_expand_builtin_ffmahq (target, exp);
    case KVX_BUILTIN_FFMAHO: return kvx_expand_builtin_ffmaho (target, exp);
    case KVX_BUILTIN_FFMAHX: return kvx_expand_builtin_ffmahx (target, exp);
    case KVX_BUILTIN_FFMAW: return kvx_expand_builtin_ffmaw (target, exp);
    case KVX_BUILTIN_FFMAWP: return kvx_expand_builtin_ffmawp (target, exp);
    case KVX_BUILTIN_FFMAWQ: return kvx_expand_builtin_ffmawq (target, exp);
    case KVX_BUILTIN_FFMAWO: return kvx_expand_builtin_ffmawo (target, exp);
    case KVX_BUILTIN_FFMAD: return kvx_expand_builtin_ffmad (target, exp);
    case KVX_BUILTIN_FFMADP: return kvx_expand_builtin_ffmadp (target, exp);
    case KVX_BUILTIN_FFMADQ: return kvx_expand_builtin_ffmadq (target, exp);

    case KVX_BUILTIN_FFMAXHW: return kvx_expand_builtin_ffmaxhw (target, exp);
    case KVX_BUILTIN_FFMAXHWQ: return kvx_expand_builtin_ffmaxhwq (target, exp);
    case KVX_BUILTIN_FFMAXHWO: return kvx_expand_builtin_ffmaxhwo (target, exp);
    case KVX_BUILTIN_FFMAXWD: return kvx_expand_builtin_ffmaxwd (target, exp);
    case KVX_BUILTIN_FFMAXWDP: return kvx_expand_builtin_ffmaxwdp (target, exp);
    case KVX_BUILTIN_FFMAXWDQ: return kvx_expand_builtin_ffmaxwdq (target, exp);
    case KVX_BUILTIN_FFMAWC: return kvx_expand_builtin_ffmawc (target, exp);
    case KVX_BUILTIN_FFMAWCP: return kvx_expand_builtin_ffmawcp (target, exp);
    case KVX_BUILTIN_FFMAWCQ: return kvx_expand_builtin_ffmawcq (target, exp);
    case KVX_BUILTIN_FFMADC: return kvx_expand_builtin_ffmadc (target, exp);
    case KVX_BUILTIN_FFMADCP: return kvx_expand_builtin_ffmadcp (target, exp);

    case KVX_BUILTIN_FFMSH: return kvx_expand_builtin_ffmsh (target, exp);
    case KVX_BUILTIN_FFMSHQ: return kvx_expand_builtin_ffmshq (target, exp);
    case KVX_BUILTIN_FFMSHO: return kvx_expand_builtin_ffmsho (target, exp);
    case KVX_BUILTIN_FFMSHX: return kvx_expand_builtin_ffmshx (target, exp);
    case KVX_BUILTIN_FFMSW: return kvx_expand_builtin_ffmsw (target, exp);
    case KVX_BUILTIN_FFMSWP: return kvx_expand_builtin_ffmswp (target, exp);
    case KVX_BUILTIN_FFMSWQ: return kvx_expand_builtin_ffmswq (target, exp);
    case KVX_BUILTIN_FFMSWO: return kvx_expand_builtin_ffmswo (target, exp);
    case KVX_BUILTIN_FFMSD: return kvx_expand_builtin_ffmsd (target, exp);
    case KVX_BUILTIN_FFMSDP: return kvx_expand_builtin_ffmsdp (target, exp);
    case KVX_BUILTIN_FFMSDQ: return kvx_expand_builtin_ffmsdq (target, exp);

    case KVX_BUILTIN_FFMSXHW: return kvx_expand_builtin_ffmsxhw (target, exp);
    case KVX_BUILTIN_FFMSXHWQ: return kvx_expand_builtin_ffmsxhwq (target, exp);
    case KVX_BUILTIN_FFMSXHWO: return kvx_expand_builtin_ffmsxhwo (target, exp);
    case KVX_BUILTIN_FFMSXWD: return kvx_expand_builtin_ffmsxwd (target, exp);
    case KVX_BUILTIN_FFMSXWDP: return kvx_expand_builtin_ffmsxwdp (target, exp);
    case KVX_BUILTIN_FFMSXWDQ: return kvx_expand_builtin_ffmsxwdq (target, exp);
    case KVX_BUILTIN_FFMSWC: return kvx_expand_builtin_ffmswc (target, exp);
    case KVX_BUILTIN_FFMSWCP: return kvx_expand_builtin_ffmswcp (target, exp);
    case KVX_BUILTIN_FFMSWCQ: return kvx_expand_builtin_ffmswcq (target, exp);
    case KVX_BUILTIN_FFMSDC: return kvx_expand_builtin_ffmsdc (target, exp);
    case KVX_BUILTIN_FFMSDCP: return kvx_expand_builtin_ffmsdcp (target, exp);

    case KVX_BUILTIN_FMM212W: return kvx_expand_builtin_fmm212w (target, exp);
    case KVX_BUILTIN_FMM222W: return kvx_expand_builtin_fmm222w (target, exp);
    case KVX_BUILTIN_FMMA212W: return kvx_expand_builtin_fmma212w (target, exp);
    case KVX_BUILTIN_FMMA222W: return kvx_expand_builtin_fmma222w (target, exp);
    case KVX_BUILTIN_FMMS212W: return kvx_expand_builtin_fmms212w (target, exp);
    case KVX_BUILTIN_FMMS222W: return kvx_expand_builtin_fmms222w (target, exp);

    case KVX_BUILTIN_FFDMAW: return kvx_expand_builtin_ffdmaw (target, exp);
    case KVX_BUILTIN_FFDMAWP: return kvx_expand_builtin_ffdmawp (target, exp);
    case KVX_BUILTIN_FFDMAWQ: return kvx_expand_builtin_ffdmawq (target, exp);

    case KVX_BUILTIN_FFDMSW: return kvx_expand_builtin_ffdmsw (target, exp);
    case KVX_BUILTIN_FFDMSWP: return kvx_expand_builtin_ffdmswp (target, exp);
    case KVX_BUILTIN_FFDMSWQ: return kvx_expand_builtin_ffdmswq (target, exp);

    case KVX_BUILTIN_FFDMDAW: return kvx_expand_builtin_ffdmdaw (target, exp);
    case KVX_BUILTIN_FFDMDAWP: return kvx_expand_builtin_ffdmdawp (target, exp);
    case KVX_BUILTIN_FFDMDAWQ: return kvx_expand_builtin_ffdmdawq (target, exp);

    case KVX_BUILTIN_FFDMSAW: return kvx_expand_builtin_ffdmsaw (target, exp);
    case KVX_BUILTIN_FFDMSAWP: return kvx_expand_builtin_ffdmsawp (target, exp);
    case KVX_BUILTIN_FFDMSAWQ: return kvx_expand_builtin_ffdmsawq (target, exp);

    case KVX_BUILTIN_FFDMDSW: return kvx_expand_builtin_ffdmdsw (target, exp);
    case KVX_BUILTIN_FFDMDSWP: return kvx_expand_builtin_ffdmdswp (target, exp);
    case KVX_BUILTIN_FFDMDSWQ: return kvx_expand_builtin_ffdmdswq (target, exp);

    case KVX_BUILTIN_FFDMASW: return kvx_expand_builtin_ffdmasw (target, exp);
    case KVX_BUILTIN_FFDMASWP: return kvx_expand_builtin_ffdmaswp (target, exp);
    case KVX_BUILTIN_FFDMASWQ: return kvx_expand_builtin_ffdmaswq (target, exp);

    case KVX_BUILTIN_FLOATW: return kvx_expand_builtin_floatw (target, exp);
    case KVX_BUILTIN_FLOATWP: return kvx_expand_builtin_floatwp (target, exp);
    case KVX_BUILTIN_FLOATWQ: return kvx_expand_builtin_floatwq (target, exp);
    case KVX_BUILTIN_FLOATWO: return kvx_expand_builtin_floatwo (target, exp);
    case KVX_BUILTIN_FLOATD: return kvx_expand_builtin_floatd (target, exp);
    case KVX_BUILTIN_FLOATDP: return kvx_expand_builtin_floatdp (target, exp);
    case KVX_BUILTIN_FLOATDQ: return kvx_expand_builtin_floatdq (target, exp);

    case KVX_BUILTIN_FLOATUW: return kvx_expand_builtin_floatuw (target, exp);
    case KVX_BUILTIN_FLOATUWP: return kvx_expand_builtin_floatuwp (target, exp);
    case KVX_BUILTIN_FLOATUWQ: return kvx_expand_builtin_floatuwq (target, exp);
    case KVX_BUILTIN_FLOATUWO: return kvx_expand_builtin_floatuwo (target, exp);
    case KVX_BUILTIN_FLOATUD: return kvx_expand_builtin_floatud (target, exp);
    case KVX_BUILTIN_FLOATUDP: return kvx_expand_builtin_floatudp (target, exp);
    case KVX_BUILTIN_FLOATUDQ: return kvx_expand_builtin_floatudq (target, exp);

    case KVX_BUILTIN_FIXEDW: return kvx_expand_builtin_fixedw (target, exp);
    case KVX_BUILTIN_FIXEDWP: return kvx_expand_builtin_fixedwp (target, exp);
    case KVX_BUILTIN_FIXEDWQ: return kvx_expand_builtin_fixedwq (target, exp);
    case KVX_BUILTIN_FIXEDWO: return kvx_expand_builtin_fixedwo (target, exp);
    case KVX_BUILTIN_FIXEDD: return kvx_expand_builtin_fixedd (target, exp);
    case KVX_BUILTIN_FIXEDDP: return kvx_expand_builtin_fixeddp (target, exp);
    case KVX_BUILTIN_FIXEDDQ: return kvx_expand_builtin_fixeddq (target, exp);

    case KVX_BUILTIN_FIXEDUW: return kvx_expand_builtin_fixeduw (target, exp);
    case KVX_BUILTIN_FIXEDUWP: return kvx_expand_builtin_fixeduwp (target, exp);
    case KVX_BUILTIN_FIXEDUWQ: return kvx_expand_builtin_fixeduwq (target, exp);
    case KVX_BUILTIN_FIXEDUWO: return kvx_expand_builtin_fixeduwo (target, exp);
    case KVX_BUILTIN_FIXEDUD: return kvx_expand_builtin_fixedud (target, exp);
    case KVX_BUILTIN_FIXEDUDP: return kvx_expand_builtin_fixedudp (target, exp);
    case KVX_BUILTIN_FIXEDUDQ: return kvx_expand_builtin_fixedudq (target, exp);

    case KVX_BUILTIN_FWIDENHW: return kvx_expand_builtin_fwidenhw (target, exp);
    case KVX_BUILTIN_FWIDENHWQ: return kvx_expand_builtin_fwidenhwq (target, exp);
    case KVX_BUILTIN_FWIDENHWO: return kvx_expand_builtin_fwidenhwo (target, exp);
    case KVX_BUILTIN_FWIDENWD: return kvx_expand_builtin_fwidenwd (target, exp);
    case KVX_BUILTIN_FWIDENWDP: return kvx_expand_builtin_fwidenwdp (target, exp);
    case KVX_BUILTIN_FWIDENWDQ: return kvx_expand_builtin_fwidenwdq (target, exp);

    case KVX_BUILTIN_FNARROWWH: return kvx_expand_builtin_fnarrowwh (target, exp);
    case KVX_BUILTIN_FNARROWWHQ: return kvx_expand_builtin_fnarrowwhq (target, exp);
    case KVX_BUILTIN_FNARROWWHO: return kvx_expand_builtin_fnarrowwho (target, exp);
    case KVX_BUILTIN_FNARROWDW: return kvx_expand_builtin_fnarrowdw (target, exp);
    case KVX_BUILTIN_FNARROWDWP: return kvx_expand_builtin_fnarrowdwp (target, exp);
    case KVX_BUILTIN_FNARROWDWQ: return kvx_expand_builtin_fnarrowdwq (target, exp);

    case KVX_BUILTIN_FCONJWC: return kvx_expand_builtin_fconjwc (target, exp);
    case KVX_BUILTIN_FCONJWCP: return kvx_expand_builtin_fconjwcp (target, exp);
    case KVX_BUILTIN_FCONJWCQ: return kvx_expand_builtin_fconjwcq (target, exp);
    case KVX_BUILTIN_FCONJDC: return kvx_expand_builtin_fconjdc (target, exp);
    case KVX_BUILTIN_FCONJDCP: return kvx_expand_builtin_fconjdcp (target, exp);

    case KVX_BUILTIN_FCDIVW: return kvx_expand_builtin_fcdivw (target, exp);
    case KVX_BUILTIN_FCDIVWP: return kvx_expand_builtin_fcdivwp (target, exp);
    case KVX_BUILTIN_FCDIVWQ: return kvx_expand_builtin_fcdivwq (target, exp);
    case KVX_BUILTIN_FCDIVWO: return kvx_expand_builtin_fcdivwo (target, exp);
    case KVX_BUILTIN_FCDIVD: return kvx_expand_builtin_fcdivd (target, exp);
    case KVX_BUILTIN_FCDIVDP: return kvx_expand_builtin_fcdivdp (target, exp);
    case KVX_BUILTIN_FCDIVDQ: return kvx_expand_builtin_fcdivdq (target, exp);

    case KVX_BUILTIN_FSDIVW: return kvx_expand_builtin_fsdivw (target, exp);
    case KVX_BUILTIN_FSDIVWP: return kvx_expand_builtin_fsdivwp (target, exp);
    case KVX_BUILTIN_FSDIVWQ: return kvx_expand_builtin_fsdivwq (target, exp);
    case KVX_BUILTIN_FSDIVWO: return kvx_expand_builtin_fsdivwo (target, exp);
    case KVX_BUILTIN_FSDIVD: return kvx_expand_builtin_fsdivd (target, exp);
    case KVX_BUILTIN_FSDIVDP: return kvx_expand_builtin_fsdivdp (target, exp);
    case KVX_BUILTIN_FSDIVDQ: return kvx_expand_builtin_fsdivdq (target, exp);

    case KVX_BUILTIN_FSRECW: return kvx_expand_builtin_fsrecw (target, exp);
    case KVX_BUILTIN_FSRECWP: return kvx_expand_builtin_fsrecwp (target, exp);
    case KVX_BUILTIN_FSRECWQ: return kvx_expand_builtin_fsrecwq (target, exp);
    case KVX_BUILTIN_FSRECWO: return kvx_expand_builtin_fsrecwo (target, exp);
    case KVX_BUILTIN_FSRECD: return kvx_expand_builtin_fsrecd (target, exp);
    case KVX_BUILTIN_FSRECDP: return kvx_expand_builtin_fsrecdp (target, exp);
    case KVX_BUILTIN_FSRECDQ: return kvx_expand_builtin_fsrecdq (target, exp);

    case KVX_BUILTIN_FSRSRW: return kvx_expand_builtin_fsrsrw (target, exp);
    case KVX_BUILTIN_FSRSRWP: return kvx_expand_builtin_fsrsrwp (target, exp);
    case KVX_BUILTIN_FSRSRWQ: return kvx_expand_builtin_fsrsrwq (target, exp);
    case KVX_BUILTIN_FSRSRWO: return kvx_expand_builtin_fsrsrwo (target, exp);
    case KVX_BUILTIN_FSRSRD: return kvx_expand_builtin_fsrsrd (target, exp);
    case KVX_BUILTIN_FSRSRDP: return kvx_expand_builtin_fsrsrdp (target, exp);
    case KVX_BUILTIN_FSRSRDQ: return kvx_expand_builtin_fsrsrdq (target, exp);

    case KVX_BUILTIN_GET: return kvx_expand_builtin_get (target, exp);
    case KVX_BUILTIN_WFXL: return kvx_expand_builtin_wfxl (target, exp);
    case KVX_BUILTIN_WFXM: return kvx_expand_builtin_wfxm (target, exp);
    case KVX_BUILTIN_IINVAL: return kvx_expand_builtin_iinval ();
    case KVX_BUILTIN_IINVALS: return kvx_expand_builtin_iinvals (target, exp);
    case KVX_BUILTIN_LBSU: return kvx_expand_builtin_lbsu (target, exp);
    case KVX_BUILTIN_LBZU: return kvx_expand_builtin_lbzu (target, exp);
    case KVX_BUILTIN_LDU: return kvx_expand_builtin_ldu (target, exp);
    case KVX_BUILTIN_LHSU: return kvx_expand_builtin_lhsu (target, exp);
    case KVX_BUILTIN_LHZU: return kvx_expand_builtin_lhzu (target, exp);
    case KVX_BUILTIN_LWZU: return kvx_expand_builtin_lwzu (target, exp);
    case KVX_BUILTIN_SET: return kvx_expand_builtin_set (target, exp);
    case KVX_BUILTIN_SLEEP: return kvx_expand_builtin_sleep (target, exp);
    case KVX_BUILTIN_STOP: return kvx_expand_builtin_stop (target, exp);
    case KVX_BUILTIN_SYNCGROUP: return kvx_expand_builtin_syncgroup (target, exp);
    case KVX_BUILTIN_TLBDINVAL: return kvx_expand_builtin_tlbdinval ();
    case KVX_BUILTIN_TLBIINVAL: return kvx_expand_builtin_tlbiinval ();
    case KVX_BUILTIN_TLBPROBE: return kvx_expand_builtin_tlbprobe ();
    case KVX_BUILTIN_TLBREAD: return kvx_expand_builtin_tlbread ();
    case KVX_BUILTIN_TLBWRITE: return kvx_expand_builtin_tlbwrite ();
    case KVX_BUILTIN_WAITIT: return kvx_expand_builtin_waitit (target, exp);

    case KVX_BUILTIN_SATD: return kvx_expand_builtin_satd (target, exp);
    case KVX_BUILTIN_SATUD: return kvx_expand_builtin_satud (target, exp);
    case KVX_BUILTIN_STSUW: return kvx_expand_builtin_stsuw (target, exp);
    case KVX_BUILTIN_STSUD: return kvx_expand_builtin_stsud (target, exp);
    case KVX_BUILTIN_STSUDP: return kvx_expand_builtin_stsudp (target, exp);
    case KVX_BUILTIN_SBMM8: return kvx_expand_builtin_sbmm8 (target, exp);
    case KVX_BUILTIN_SBMMT8: return kvx_expand_builtin_sbmmt8 (target, exp);

    case KVX_BUILTIN_LBZ: return kvx_expand_builtin_lbz (target, exp);
    case KVX_BUILTIN_LBS: return kvx_expand_builtin_lbs (target, exp);
    case KVX_BUILTIN_LHZ: return kvx_expand_builtin_lhz (target, exp);
    case KVX_BUILTIN_LHS: return kvx_expand_builtin_lhs (target, exp);
    case KVX_BUILTIN_LWZ: return kvx_expand_builtin_lwz (target, exp);
    case KVX_BUILTIN_LWS: return kvx_expand_builtin_lws (target, exp);
    case KVX_BUILTIN_LD: return kvx_expand_builtin_ld (target, exp);
    case KVX_BUILTIN_LQ: return kvx_expand_builtin_lq (target, exp);
    case KVX_BUILTIN_LHF: return kvx_expand_builtin_lhf (target, exp);
    case KVX_BUILTIN_LWF: return kvx_expand_builtin_lwf (target, exp);
    case KVX_BUILTIN_LDF: return kvx_expand_builtin_ldf (target, exp);

    case KVX_BUILTIN_LBO: return kvx_expand_builtin_lbo (target, exp);
    case KVX_BUILTIN_LBX: return kvx_expand_builtin_lbx (target, exp);
    case KVX_BUILTIN_LBV: return kvx_expand_builtin_lbv (target, exp);
    case KVX_BUILTIN_LHQ: return kvx_expand_builtin_lhq (target, exp);
    case KVX_BUILTIN_LHO: return kvx_expand_builtin_lho (target, exp);
    case KVX_BUILTIN_LHX: return kvx_expand_builtin_lhx (target, exp);
    case KVX_BUILTIN_LWP: return kvx_expand_builtin_lwp (target, exp);
    case KVX_BUILTIN_LWQ: return kvx_expand_builtin_lwq (target, exp);
    case KVX_BUILTIN_LWO: return kvx_expand_builtin_lwo (target, exp);
    case KVX_BUILTIN_LDP: return kvx_expand_builtin_ldp (target, exp);
    case KVX_BUILTIN_LDQ: return kvx_expand_builtin_ldq (target, exp);

    case KVX_BUILTIN_SBO: return kvx_expand_builtin_sbo (target, exp);
    case KVX_BUILTIN_SBX: return kvx_expand_builtin_sbx (target, exp);
    case KVX_BUILTIN_SBV: return kvx_expand_builtin_sbv (target, exp);
    case KVX_BUILTIN_SHQ: return kvx_expand_builtin_shq (target, exp);
    case KVX_BUILTIN_SHO: return kvx_expand_builtin_sho (target, exp);
    case KVX_BUILTIN_SHX: return kvx_expand_builtin_shx (target, exp);
    case KVX_BUILTIN_SWP: return kvx_expand_builtin_swp (target, exp);
    case KVX_BUILTIN_SWQ: return kvx_expand_builtin_swq (target, exp);
    case KVX_BUILTIN_SWO: return kvx_expand_builtin_swo (target, exp);
    case KVX_BUILTIN_SDP: return kvx_expand_builtin_sdp (target, exp);
    case KVX_BUILTIN_SDQ: return kvx_expand_builtin_sdq (target, exp);

    case KVX_BUILTIN_LOADBZ: return kvx_expand_builtin_loadbz (target, exp);
    case KVX_BUILTIN_LOADHZ: return kvx_expand_builtin_loadhz (target, exp);
    case KVX_BUILTIN_LOADWZ: return kvx_expand_builtin_loadwz (target, exp);
    case KVX_BUILTIN_LOADD: return kvx_expand_builtin_loadd (target, exp);
    case KVX_BUILTIN_LOADQ: return kvx_expand_builtin_loadq (target, exp);
    case KVX_BUILTIN_LOAD64: return kvx_expand_builtin_load64 (target, exp);
    case KVX_BUILTIN_LOAD128: return kvx_expand_builtin_load128 (target, exp);
    case KVX_BUILTIN_LOAD256: return kvx_expand_builtin_load256 (target, exp);
    case KVX_BUILTIN_XLOAD256: return kvx_expand_builtin_xload256 (target, exp);

    case KVX_BUILTIN_LOADCBZ: return kvx_expand_builtin_loadcbz (target, exp);
    case KVX_BUILTIN_LOADCHZ: return kvx_expand_builtin_loadchz (target, exp);
    case KVX_BUILTIN_LOADCWZ: return kvx_expand_builtin_loadcwz (target, exp);
    case KVX_BUILTIN_LOADCD: return kvx_expand_builtin_loadcd (target, exp);
    case KVX_BUILTIN_LOADCQ: return kvx_expand_builtin_loadcq (target, exp);
    case KVX_BUILTIN_LOADC64: return kvx_expand_builtin_loadc64 (target, exp);
    case KVX_BUILTIN_LOADC128: return kvx_expand_builtin_loadc128 (target, exp);
    case KVX_BUILTIN_LOADC256: return kvx_expand_builtin_loadc256 (target, exp);
    case KVX_BUILTIN_XLOADC256: return kvx_expand_builtin_xloadc256 (target, exp);

    case KVX_BUILTIN_STOREB: return kvx_expand_builtin_storeb (target, exp);
    case KVX_BUILTIN_STOREH: return kvx_expand_builtin_storeh (target, exp);
    case KVX_BUILTIN_STOREW: return kvx_expand_builtin_storew (target, exp);
    case KVX_BUILTIN_STORED: return kvx_expand_builtin_stored (target, exp);
    case KVX_BUILTIN_STOREQ: return kvx_expand_builtin_storeq (target, exp);
    case KVX_BUILTIN_STORE64: return kvx_expand_builtin_store64 (target, exp);
    case KVX_BUILTIN_STORE128: return kvx_expand_builtin_store128 (target, exp);
    case KVX_BUILTIN_STORE256: return kvx_expand_builtin_store256 (target, exp);
    case KVX_BUILTIN_XSTORE256: return kvx_expand_builtin_xstore256 (target, exp);

    case KVX_BUILTIN_STORECB: return kvx_expand_builtin_storecb (target, exp);
    case KVX_BUILTIN_STORECH: return kvx_expand_builtin_storech (target, exp);
    case KVX_BUILTIN_STORECW: return kvx_expand_builtin_storecw (target, exp);
    case KVX_BUILTIN_STORECD: return kvx_expand_builtin_storecd (target, exp);
    case KVX_BUILTIN_STORECQ: return kvx_expand_builtin_storecq (target, exp);
    case KVX_BUILTIN_STOREC64: return kvx_expand_builtin_storec64 (target, exp);
    case KVX_BUILTIN_STOREC128: return kvx_expand_builtin_storec128 (target, exp);
    case KVX_BUILTIN_STOREC256: return kvx_expand_builtin_storec256 (target, exp);
    case KVX_BUILTIN_XSTOREC256: return kvx_expand_builtin_xstorec256 (target, exp);

    case KVX_BUILTIN_XLOAD256Q0: return kvx_expand_builtin_xload256q (target, exp, 0);
    case KVX_BUILTIN_XLOAD256Q1: return kvx_expand_builtin_xload256q (target, exp, 1);
    case KVX_BUILTIN_XLOAD256Q2: return kvx_expand_builtin_xload256q (target, exp, 2);
    case KVX_BUILTIN_XLOAD256Q3: return kvx_expand_builtin_xload256q (target, exp, 3);

    case KVX_BUILTIN_XLOADC256Q0: return kvx_expand_builtin_xloadc256q (target, exp, 0);
    case KVX_BUILTIN_XLOADC256Q1: return kvx_expand_builtin_xloadc256q (target, exp, 1);
    case KVX_BUILTIN_XLOADC256Q2: return kvx_expand_builtin_xloadc256q (target, exp, 2);
    case KVX_BUILTIN_XLOADC256Q3: return kvx_expand_builtin_xloadc256q (target, exp, 3);

    case KVX_BUILTIN_XSWAP256: return kvx_expand_builtin_xswap256 (target, exp);
    case KVX_BUILTIN_XMT44D: return kvx_expand_builtin_xmt44d (target, exp);

    case KVX_BUILTIN_XMMA484BW: return kvx_expand_builtin_xmma484bw (target, exp);

    default:
      break;
    }
  internal_error ("bad builtin code");
  return NULL_RTX;
}


